% Processed Transcript: ../course_website/ModellingNeuralSystems/overheads/transcripts/Class8_raw.md
% Date: 2025-12-11

## Introduction to Simplified Neuronal Models

We will begin by discussing simplified models of neuronal excitability and their ability to fit experimental data, particularly concerning the current-frequency response. The question arises: if neuronal coding is linked to the timing of individual spikes, and we use a single-compartment conductance-based model, how does an Integrate-and-Fire (IAF) model compare in terms of subthreshold behavior and spike generation? Specifically, if the number of spikes generated by the same input current is similar, does this imply that the spike timing is accurately captured, or could a simplified model fail to capture the precise timing of spikes?

### Comparing Integrate-and-Fire with Conductance-Based Models

Consider the subthreshold dynamics of the membrane potential for an IAF model. The equation governing this behavior is:

$$
\tau_m \frac{dV}{dt} = -(V - V_L) + R_m I_{inj}
$$

This equation describes the passive subthreshold behavior, which is a component also present in conductance-based models. When comparing the subthreshold behavior of an IAF model to a more complex conductance-based model (like the Wang-Buzsáki model for a cortical interneuron, which is a Hodgkin-Huxley type model but with a specific choice for the activation gating variable to generate the spike), the subthreshold membrane potential dynamics can appear similar.

However, a critical difference emerges at the threshold. One might initially assume that if the neuron doesn't fire, the threshold potential was set too high. In reality, a key characteristic where simple leaky models fail is that the linear leak term ($V - V_L$) does not fully represent the behavior of a real neuron or a conductance-based model. In conductance-based models, voltage-dependent ion channels (like sodium and potassium channels) are not simply all-or-none switches. Their activation and inactivation gates have sigmoid activation curves, meaning they are not fully closed or open at polarized or hyperpolarized potentials.

### The Role of Voltage-Dependent Channels and Feedback

The Hodgkin-Huxley model, for instance, incorporates gating variables (m, h, n) that evolve over time according to differential equations. The activation of sodium channels, governed by the $m$ gate, is particularly crucial. The equation for the evolution of the $m$ gate is:

$$
\tau_m \frac{dm}{dt} = m_\infty(V) - m
$$

where $m_\infty(V)$ is a sigmoid function of the membrane potential $V$. This sigmoid nature means that as the potential approaches the threshold, the probability of channel opening increases. This leads to a positive feedback loop: as $V$ depolarizes, $m_\infty(V)$ increases, leading to more sodium channel opening, further depolarization of $V$, and consequently, an even larger increase in $m_\infty(V)$. This positive feedback is a hallmark of neuronal excitability and is what Hodgkin and Huxley described as a "regenerative" process.

The Integrate-and-Fire model, by contrast, typically lacks this intrinsic regenerative mechanism. As long as the membrane potential $V$ is strictly below the threshold $\theta$, the model behaves linearly. This means that the IAF model cannot capture the "attractor" or "point of no return" behavior observed at the threshold of real neurons. In a conductance-based model, one can approach the threshold very slowly, allowing inactivation variables (like the $h$ gate for sodium channels) to activate. This can lead to a state where the neuron is on the verge of firing but does not, because the sodium channels become inactivated. Conversely, the positive feedback from the sodium channel activation can rapidly drive the potential past the threshold, initiating an action potential.

### Limitations of the Integrate-and-Fire Model

The IAF model's simplicity, while offering analytical tractability, comes at the cost of not capturing these crucial nonlinear dynamics at the threshold. The linear leak term in the IAF model does not account for the voltage-dependent feedback mechanisms present in biological neurons. While the subthreshold behavior might be approximated, the precise initiation and timing of spikes, which depend on these nonlinearities, are not accurately represented.

### Towards More Realistic Simplified Models

To address these limitations, researchers have developed extensions to the basic IAF model. One approach is to modify the subthreshold dynamics to incorporate some form of nonlinearity. For example, the "Leaky Integrate-and-Fire" (LIF) model, while still simple, is a foundational model. More advanced versions include:

*   **Quadratic Integrate-and-Fire (QIF):** This model introduces a quadratic term in the subthreshold dynamics, allowing for a more realistic representation of the voltage-dependent behavior near the threshold. The equation might look something like:
    $$
    \tau_m \frac{dV}{dt} = -(V - V_L) + \alpha(V - V_{th})^2 + R_m I_{inj}
    $$
    where $\alpha$ is a parameter controlling the strength of the quadratic term and $V_{th}$ is a threshold potential.

*   **Exponential Integrate-and-Fire (EIF):** This model incorporates an exponential nonlinearity, which better approximates the behavior of voltage-gated sodium channels. A common form is:
    $$
    \tau_m \frac{dV}{dt} = -(V - V_L) + \Delta_T \exp\left(\frac{V - V_T}{\Delta_T}\right) + R_m I_{inj}
    $$
    Here, $\Delta_T$ is a parameter related to the sharpness of the spike initiation, and $V_T$ is a threshold potential. The exponential term captures the rapid increase in excitability as the membrane potential approaches the threshold.

These extended models, such as the QIF and EIF, aim to retain some degree of analytical solvability while incorporating more biophysically realistic nonlinearities. They can better capture the current-frequency relationship and the precise timing of action potentials compared to the basic LIF model. The choice between these models often involves a trade-off between analytical simplicity and biophysical accuracy.

### The Role of Noise and Stochasticity

In some contexts, particularly when dealing with stochastic inputs or intrinsic noise, the distinction between different simplified models might become less pronounced. The presence of noise can effectively "smooth out" some of the sharp nonlinearities, making even simpler models provide reasonable approximations. However, for precise spike timing and understanding the underlying mechanisms, the nonlinear dynamics near the threshold remain crucial.

### Reproducibility and Experimental Validation

A significant question in computational neuroscience is how well simplified models can reproduce experimental data, particularly the reliability of spike generation. Studies have shown that real neurons exhibit a degree of "jitter" or variability in their spike timing, even with identical stimuli. This intrinsic variability, sometimes referred to as "sloppiness," means that a perfect millisecond-level precision might not always be achievable or even biologically relevant.

When comparing the current-frequency (f-I) curves of different models and experimental data, simplified models like the QIF and EIF can often provide a good fit. The basic LIF model might be slightly less accurate, showing a steeper or different relationship between injected current and firing rate. The ability of these models to reproduce experimental f-I curves suggests that, at a macroscopic level, they capture essential aspects of neuronal excitability. However, the precise mechanisms underlying spike initiation and timing are better represented by models that incorporate voltage-dependent nonlinearities.

The question of whether a simplified model can accurately predict spike timing is complex. While the f-I curve provides a global measure of firing rate, it doesn't fully capture the temporal dynamics of individual spikes. The reliability of spike trains in real neurons, as demonstrated in experiments with repeated stimuli, can be limited. This intrinsic variability in biological systems means that even the most sophisticated models may not perfectly replicate experimental outcomes. Therefore, the choice of model often depends on the specific research question, balancing the need for biophysical realism with computational tractability.

## Comparing Integrate-and-Fire with Conductance-Based Models

This might explain why I am optimistic and say, "Okay, I'll disregard some of what you want." If you compare it, these are four simulations. The neuron, in this case, was not an experiment, but you can do it with an experiment: inject a particular waveform into the neuron's soma. Now, the waveform here is a realization of a stochastic process, but you can think of it as simply the same waveform that I inject into the real neuron or a model with a state space that I consider only from a numerical point of view. I do this for the exponential integrate-and-fire (EIF) model, the quadratic integrate-and-fire (QIF) model, and the leaky integrate-and-fire (LIF) model. If you don't look very closely, you might say, "Okay, I see the EIF here, which has these six spikes, and they are a bit more similar in timing to the QIF, which has more space, and here it perhaps fires only four instead of six, so this kind of doublet at the beginning is lost." The LIF model captures six, but perhaps they are spaced differently here compared to the data-space model. The difference is subtle. And here is the response head; can we also capture the timing of the parameters? It works better. If you change parameters, if you use various parameters, there is often good agreement on the timing as well, not just that there is a match in the subthreshold voltage excursions, not only is there a match in the current frequency but there is even a match on the timing.

### ADEX Model and Machine Learning Analogy

In the slide after this one, I don't recall where it was published, but it was in Nature, two authors, Wolfram Gester and Romain Brett, further studied the exponential integrate-and-fire model by attaching what we saw a couple of weeks ago, perhaps last week, which was voltage-dependent adaptation. They called it ADEX because it's exponential in terms of adaptation. Anyway, it doesn't matter. It's not just adaptation. They asked in the literature, they said, "In other fields, there are these competitions. Let's have a competition without money; whoever arrives first wins." This competition is typical of machine learning, where they say, "Here is the dataset, the training set, so anything goes. Here are images of kittens and dogs. Within two months, submit a machine learning algorithm that classifies and understands them best." If you know the literature, if someone has told you about recent progress in the last twenty years of machine learning, particularly some deep learning networks, and you hear about Hinton and the other Canadian, all the Canadians, two are Canadian, Yann LeCun, and another one I don't remember. They proposed another architecture with many intermediate layers, and in this competition, those who achieved 98% accuracy on the test set arrived. That is, I show you a dataset and tell you, "This is a cat," then this is the photo, and I tell you it's a cat; this is a dog, and I tell you it's a dog. But I don't show you other photos to measure your accuracy. This is a classic thing. The same concept was applied here. I give you the current that you gave me, and I give you the first, say, 30 seconds. I give you the spikes, so you see the response of the real neuron. Then I ask you to find, do whatever you want, you must capture the timing, the subthreshold behavior, and the number of spikes. The best one wins, and the adaptive exponential integrate-and-fire model is the one that works best. They didn't win anything, though. And the comparison is not made on the 30 seconds that were made available, for which you had both the input and the output, but on another part, another 10 seconds, where you had the input, but you had to say how it continued. This is typical, for example, perhaps you've heard of it in the world of finance, where the holy grail is to predict what will happen. I tell you, "This is the history of a stock's fluctuations in the stock market; tell me how it continues." In that case, you don't have the input; you have to say how it continues, and whoever predicts how it continues becomes a billionaire. In that case, the interesting thing is that if someone becomes a billionaire, they manage to capture the future, and in fact, they are introducing some component into the market dynamics, and therefore it might be that the market changes because someone is making a lot of money. It's not a coupling, but it's not my case; I am not that.

This concludes the section on integrate-and-fire models, which we will keep in mind because it is one of the components I will evoke when discussing even simpler models.

### Synaptic Input and Conductance Dynamics

Yes, yes, yes. It should be there. If I, excuse me, it should be there from a few weeks ago, yes, 5. It's definitely there, not that it's not autosynced. Okay, I must have modified 4, but 5 is there. On my GitHub site, whatever, "Modeling Neuro Systems," you see that picture there, "grid overhead." And if I do `git add`, okay, then I'll do it. Excuse me, one moment, one moment, one moment. There's November 27th. Why not, no? Yes, yes. Excuse me, I've just singularized it. It should now contain this other part as well, after the QIF. And I don't like this particular lecture because it's a topic I don't enjoy. Okay, but now, yes, okay. If you try now, excuse me, excuse me, truly, on the site, if that's indeed the case. So, for this part, I remind you there are the slides. I remind you that I did one of the concluding parts of last year's course where we were able to write the term due to a synaptic impulse. We had, in the case of chemical synapses, this "canale di manonegra" (channel of manonegra), also the way an external current, which could appear in the second member of the release of the particle, could have the same form. There was a maximum conductance, G-bar, synaptic, then there was a conductance for the recorded, I don't know if I called it xr or ok, with the decay of the neurotransmitter, or this represented the fraction of ligand-gated receptor channels in the open state, for example, described for simplicity by a two-state model. It's not the only one, but for example, it could be closed-open, where the kinetics of opening and closing are, in one case, a constant. If I find the channel open, there is one per second per quantity of time, and there is a probability, if you reason in probabilistic terms, or there is a closing rate that is given, it is fixed, and it is always the same. Whereas for opening, normally this rate is zero unless there is a ligand, and a transmitter in the cleft, in the synaptic space. Do you remember that T was a quantity that in reality probably has some very rapid change, a small delay, and this delay is due to vesicle fusion, the invasion of the spike throughout the presynaptic terminal, vesicle fusion, and the diffusion of a transmitter in this space, which is small, a few nanometers, but still not instantaneous. And we described it as a piecewise constant function, always zero, except for a millimolar for a duration of about one millisecond. This is because the simple differential equation, which was the solid, boring, the differential equation with constant coefficients of the first order, etc., could be solved by hand when this term T, which I remember being multiplicative, now C, we had written it as 1-O, so it was only a single linear differential equation, but it had non-constant coefficients unless this thing was piecewise constant, which meant that piecewise, I had an equation that I knew how to solve everything analytically. So, in particular, fundamentally, I arrived at this synaptic current and said, "Look, this synaptic current has a state variable OBT for a population of receptors, suppose AMPA, or another type of synaptic input for NMDA receptors, another synaptic input term for GABA receptors, where the difference was both in GABA and AMPA in the reversal potential, AMPA, GABA, and NMDA also in the kinetics, in that famous beta." I am continuing to write the synaptic because, in fact, even a short while ago, I re-scaled again the so-called frequency-current curve, of which I continue to be enamored, and now I will tell you why. So, in some way, I know that there is a dynamic even in the integrate-and-fire model, that the synaptic current term doesn't just appear like that; it's integrated, meaning it appears in the second member of the differential equations. It's not that, as I'm selling it to you for simplicity, if one has the frequency-current curve, it actually enters here and asks, "What is the frequency?" But I can think that this type of description is not so wrong. You will tell me, "No, watch out, because the frequency-current curve was made when the input was a constant, not when the input was something that only went down, like my motor current, you remember, etc." In particular, here it's even different because there's a proportional dependence on the membrane potential itself. So, if the neuron itself, during the arrival of a synaptic input, is, for example, firing, the synaptic current, this term, called the reversal potential, even changes polarity during a spike. So, it's not exactly the context where I have a neuron that is firing silently and I am the one who has a constant input that I study study after study, even analytically, as we did for integrate-and-fire, I change it and construct this curve. However, this curve is somehow representative of how an average amplitude, perhaps you'll say, some amplitude, this concept is now a bit clearer, how this converts a frequency. I am doing this because I want to understand if I can, by reasoning at the population level, no longer at the single neuron level, throw away the spikes. In fact, what I would like to do is throw away the neurons, leaving, as for the dynamics, throwing away the single molecules, keeping a collective observable, like temperature. I have a single temperature value for this entire room, as a first approximation. Certainly, I have one for a large volume, especially if the air molecules in the volume are homogeneous, they do the same thing. Perhaps they influence each other, they are not independent, but roughly I can describe them with a single descriptor. I would like to do the same thing. The key is to understand if, knowing that all neurons have this, all neurons of the same type, so if I have other neurons that have a steeper input-current curve, steeper, okay? But all those that are driven by the same class of input-output curve do essentially the same thing, yet they experience interactions, synaptic interactions. In statistical mechanics or thermodynamics, I am thinking that a single air molecule is indistinguishable from others. It is, but statistically they are all the same, they all have a certain response when the input, what would the input be in the case of air molecules? Collisions or adjacent molecules. If I somehow manage to abstract the concept of collisions and say, "I know how I respond to a single generic molecule, I know how I respond to a single generic neuron," perhaps I can say the problem shifts from characterizing the output of many neurons that agree that in a network, like molecules that have slightly different kinetic velocities, in a network of neurons, the neurons don't do exactly the same thing. But if I take the subpopulation of excitatory neurons, at least those that have some homogeneous connectivity, I mean those that, for example, receive input from the thalamus, if there are those that instead receive input from elsewhere, they don't respond like those that would have similar classes. Maybe I can think that there exists some average neuron, a "mean-mean" neuron, whose behavior can statistically represent the behavior of its peers, given that they are largely indistinguishable.

### Mean-Field Approach and Network Interactions

So, the fundamental question is, how do I understand, given that these are interacting entities, how do I study the interaction? The interaction is synaptic. In physics, this concept has been developed very well. Recently, a Nobel laureate, Giorgio Parisi, was in the news; it was talked about a lot. It's typical of spin models, where spin glasses or magnetic systems are physical systems that can exist, that are theoretical constructs but do exist. For example, magnetic systems of old hard disks, now everything is no longer magnetic, but in general, you've surely heard, perhaps even your computer has a magnetic disk. Those, for instance, if you drop them, they suffer mechanical trauma and break. Nearby points have a magnetization that can be either up or down. Here, it's slightly different because there's no firing or not firing, and the magnetization is given by the magnetic field that the neighbors, the first neighbors, have on that molecule. Here, you tell me, "No, expert, but here you're not thinking that, yes, it's true that air molecules influence each other with their neighbors, so the neighbors are a fairly local interaction. Spin glasses, magnetic models, there too the magnetic field perhaps decays, so a single element feels the interaction of its neighbors. In the case of neurons, who the heck says that interactions are local? It would be like assuming that a neuron only receives input from neurons that are nearby, 50-100 micrometers away. No, I have neurons that project from the other side of the cortex, from the other hemisphere. But for now, the idea is to say, can I understand what the input is? The field is not a magnetic field, but at least a field in average terms. What is the average field? That tells me, so knowing this mapping between output and input, it tells me what the neurons are experiencing. And this approach is a population approach called, precisely, mean-field. Mean-field because it's taken directly from physics, statistical physics, from magnetic systems. So, in theory, we talk about force fields, magnetic fields. Here, it's not a magnetic field. I'll show you now why this becomes very interesting, combined with the frequency-current curve. This was the synaptic current due to a population of postsynaptic receptors, because I am assuming that there is a neuron and that here there is, so here there is a synapse, here there is a population of channels, of ligand-gated channels, so there isn't just one, there are a million, and these millions are described deterministically, and for the moment, we talk about them deterministically, with this expression. It is the solution of these differential equations for a synaptic input that acts on this postsynaptic neuron. For example, I could say that this postsynaptic neuron, I'll call it with an index j. Suppose there are n neurons, 1, 2, 3, up to n. This is a presynaptic neuron, I can call it i. Let's say this is not a synapse, but I'll call it neuron j. Right, because in some way I can say a synapse is something that links two neurons, and the addition of two indices. Sooner or later, if I want to represent them, I have to think of having two indices. It could be that there is neuron i+1, and perhaps it doesn't have, at the end of the process, it doesn't have synaptic boutons, but perhaps it doesn't even care about this neuron j, and okay, fine. It might be that I need to specify somewhere a kind of connectivity map, what mathematicians in other contexts call an adjacency matrix. Matrix should make you think of linear algebra, where you had rows and columns, j, it's exactly the same thing. Well, in this case, the term on this possible matrix, which should link with a 1 or with 0 if there is a connection or not, a neuron of the i-th, a neuron of the j-th, is simply zero; there is no connection. But if this is a neuron j and it talks to others, I obviously need to understand how to combine all the synaptic impulses from other neurons. We have never done this; we do it now for the first time. So, okay, yes, this was the context where a single population of postsynaptic receptors behaved when the neurotransmitter concentration was piecewise constant, and if you remember, it was relatively a cosine wave for the shape of the postsynaptic potential of the synaptic current. What would this be? The synaptic conductance, the one measured experimentally, this dashed line, and the one in black is precisely the solution of this equation when both O infinity and Tau o are piecewise constant. If you remember, I said it was interesting to see that for free, with this Markovian, open-closed model, you had that this time constant, since t is constant, O is 0 or not 0. When it's 0, it's 1/beta; when it's not 0, it's something plus beta, but it's in the numerator, so it's a smaller quantity. It's as if the rising phase and the falling phase, for free, have different time constants, which you wouldn't have in a normal RC circuit if it were simply an RC. And this is exactly what is observed: the rise is much faster when T is non-zero, when there is a piece here, a term. Instead, the fall, which is given only by beta, by 1/beta, can be, suppose, 50 ms, 100 ms, so it effectively captures the experimental part of the dynamics of the temporal change of synaptic conductance. If you remember, I tried to simplify this discussion because I didn't like it. There were two things I didn't like: first, the fact that it was a multiplicative term, and the second thing I didn't like was that this thing, this T, was a rectangle, or in the case of a train of postsynaptic potentials of the j-th neuron, for each presynaptic spike, I would have a small rectangle. The small rectangles bother me; I prefer Dirac deltas because, apart from being a beautiful symbol, I know how to write it mathematically and formally. There are other deeper reasons, which we will see now. I can say that it is simply an impulsive function, concentrated only at one moment in time, and if I add or subtract a quantity to the independent variable, which is time, I am shifting the position of this Dirac delta horizontally to the right or left. Since Dirac deltas are zero everywhere except where the Dirac delta is, if I sum many of them, beyond the fact that this notation with the summation over k might be a triviality, I am simply saying that I want to generically represent a train of postsynaptic potentials. Each has a particular instant. Since each is zero everywhere, unless I am so unlucky, because there are two at exactly the same moment, but these are estimates because they all refer to the same neuron, so what does it mean if a neuron fires two spikes at the same moment? No, at most it fires one spike at a certain moment, or one fires. Since Dirac deltas are not zero everywhere, if I sum them, I am effectively superimposing them graphically, so it's easier for me to play with and write a mathematical expression with Dirac deltas. The other thing, so this is a kind of further approximation because you can say, "Great, the Dirac delta, but the Dirac delta reaches an infinite concentration in zero time, which means physically? It's not like that." We said that roughly, perhaps the small rectangle, now I'll stop, the small rectangle goes up very quickly, stays for a millisecond, a millimolar here, perhaps you can say the area of this is one millimolar per millisecond. But mathematically, it has the same effect. This was the example of the bank account that I told you about last time. If I have a Dirac delta and integrate both members here, I can manage, apart from this term for which, when I do the integral, the integral of this, I said that it has an integral over an interval of a continuous function over a measure-zero interval, and therefore it was zero. The other thing, and then I'll stop, I simply recall that this term here, which comes from the free kinetic scheme, but I don't like it very much because it's a multiplicative thing, the input multiplies O instead of having, from an engineering perspective, a system where there is a plus and something independent. This represented the saturation of the receptors, and if you remember, last year I said, "Yes, I understand that if most of the receptors, O is 50, 80, 90 percent, this term here is killing the effect of the actual presence of the transmitter," which means that if these receptors are already saturated, they are already all open, I can release as much as I want, but these things are like your people, and there are no free seats. So, from the perspective of that, O is more than 100 percent, it doesn't work. If I start to say, "Yes, but O is small, so I neglect it," then this term is effectively gone. In theory, O could even become very, very large, greater than one. So, this is the equation we will work with for today and for the next lessons. Let's take a 10-minute break, and then, if you wish, we'll finish by 4:45. Okay, but I cannot describe it as a list of spikes. Yes, I can describe it because maybe without using spikes, this is certainly what I wanted to do, and I am trying to prepare the spikes so as not to be too disruptive. So, it can be done by removing the spike part with the integrate-and-fire model. It can be done with a contact space model? No, because I have all the things that activate on the integrate-and-fire, subthreshold. You understand, because if there is the exponential, it becomes annoying. If I put on the hat of a mathematician, an expert in the theory of properties of stochastic processes, I am asking, given a differential equation of the usual type, an RC, a filter, if the input is a Gaussian stochastic process, what is the output? The output is also Gaussian, okay? And how can the mean be calculated, and how can the variance be calculated? So, if I have a clip or remove or don't have a spike at all, I can say what the process is. The input process is the synaptic activity; the output is also known. And this is why integrate-and-fire is pleasant because if one were, obviously, nobody is born an expert, if one were not an expert in probability theory of stochastic processes, the intervention would say, "But I already solved this a hundred years ago in a book on stochastic process theory, but I didn't know it would be useful that this could be a membrane potential subject to synaptic impulses that fluctuate." This is the very beautiful thing about this field, this hypothesis of the field, this mean-field modeling.

### Population Dynamics and Slow Sodium Inactivation

So, fundamentally, at the beginning, the bottom line is, I don't know. What we tried to do is, if I have a mathematical model, when does the mathematical model start to have this behavior with the curves bending, and when does it not? So, when do these curves, instead of merging, become flat and diverge, not merge, not exactly diverge? What we found is that if you take this with integrate-and-fire, it doesn't work because, here the line is for an integrate-and-fire, but it's an integrate-and-fire with patches where things like adaptation have been stuck on, but ugly things. We took the Hodgkin-Huxley type model, and instead of just putting M^3H for sodium currents, we also put a third state variable S for "slow," and it's like H but has an even slower activation kinetics because it's known in the literature that sodium channels also inactivate very slowly. It's not known if it's a single sodium channel with multiple conformational changes that have different time constants. The arc came as a kind of ball that blocks from the inside. Imagine there are two balls, but the other ball has a larger mass and takes more time to move. So, it starts moving, but it takes more time to... But then, once it blocks from the inside, it might take quite a bit longer to unblock. It's not known if it's like that or if there are more sodium channels... I think they are all the same, in reality, they are a population, so a subpopulation. It doesn't have H, but S is much slower.

## Population Dynamics and Slow Sodium Inactivation

The state variable S follows the same kinetic equation as H: $\frac{dS}{dt} = S_\infty - S / \tau_S$. The time constant $\tau_S$ can also be dependent on the potential, but it is significantly slower. This is sufficient to reproduce the observed curves. Therefore, our conclusion is that the neurons in the prefrontal cortex possess a population of sodium channels with distinct inactivation kinetics.

A classical physiologist might argue that while we haven't studied this in a noisy regime as you have, this behavior is more characteristic of a phasic rather than a tonic response. That is, if a constant current is applied, and given that fluctuations are privileged in a certain regime, the neuron might become fatigued by a constant input, which differs from adaptation. However, this was not a matter of adaptation, as frequency-current adaptation is present here, specifically in the initiation of spikes.

### Experimental Considerations and Speculations

These are just the data. When we wrote the article, I even received a prize from Ponzano Romano, a town near Rome. For reasons I don't know, many years ago they established an award for young researchers. Perhaps I was the only one to apply. I went to collect the award and the plaque, which is something I'm still very attached to. It reads: "For the discovery of a new class of pyramidal neurons." It's easy to assume that neurons in different parts of the cortex are qualitatively similar, but they can have quantitative differences. The fact that these are associative cortices might imply that signals are already processed differently. However, this is speculation, and I don't know. The experiment to test this would require a thousand years or ten PhD students to systematically slice the brain from many different parts or cell types and perform the same experiment. It may or may not be easy to find students willing to do this, as it represents a significant investment of time and money. In theory, this should open a new field of research, suggesting: "Pay attention, that firing rate is cool, but perhaps it has deeper characteristics that could be easily quantified in all cell types." Who knows how it works in the cerebellum, in the hippocampus, or in the visual cortex?

### Career Paths and Impact

Laura Sirio, an engineer who will be online on December 19th, completed her PhD in neuroscience and did a year or two of postdoctoral research. She then decided, "These things are interesting, but I want to have an impact on patient health." So, this type of research, which might take twenty years to yield results, could have an impact, but she wants to see patients now.

The person who could be said to have made this shift – you shouldn't tell the driver, but he should think about it – has already hinted that he shouldn't officially communicate. I explained that it makes no sense for you to be recorded from a political standpoint on the project.

### Presentation and Communication Skills

So, in my opinion, for the examination of the EFOMOFA, we choose our services from the center and look on the internet? Yes, I did some research. If I were good, I certainly wouldn't have used the Bittichia center and the CNB, but we would have taken a moment. In reality, if the person writes articles, looks at some articles, they understand that we cannot spend two months preparing this presentation. It's dedicated to the times you want, a week, if you have several articles that you see more or less, read some in detail, others less so. Where does it say we are giving this presentation? I would like you to practice the presentation as well, particularly because I am capable of giving a didactic lesson in a human university. In general, you are the protagonist, not the slides. So, nice decisions with the fonts, and anyway, they are something that is more important later, for your expression, but be careful, make the slides simple. I forgot, I'll send you some guides, but I don't have any idea to tell you, perhaps there were two or three major articles in *Natural Science* called "Cogli" or "Response Representations." Not necessarily in academia, but in general, you are the protagonist. People should look at you, and the slides are a support and an opportunity to get to the point, speak, and answer questions. Then we'll do it anyway. If you had a job interview, if it's a competition, you'll always do it together. I did it for a grant that was being judged or not, I did an interview and I did a pitch where we learned the layout in just 10 minutes. If you want, I'll show you the design, they are practically common. Okay, the part wasn't very active, because it was funding to create a strategy. And the person I told you about is the off-lay process of the drone, for all the things that are missing there, and she did the second half. If I show you the design, I'll show you the two, two, two, two, because they are shoes. There is one in which there is a page in a video that founds an IG and now there are no writings. I hope you can do the data and what I should try to be able to do is the quality of the slides, the quality of the performance, the presentation you give, and the answers to the questions. I don't think I have to repeat myself, maybe, but I don't think if everyone takes the same topic, if we all do it and are doing the same things. But I imagine that in a large subtitle, these attachments, I don't think you could see "no wait, let's choose a different group already, then in thirds certainly respectful of one side of the plus that is perfect for doing all the same identical thing. And the "Fat the mirrors rather than another, the cochlear prostheses or Silvestro Micera or Balint-Varcuti, you can range, okay, the aspect of sensory feedback is rather only of motor actuation. So, maybe don't touch, since it's a technical course, it's a technical degree course, maybe don't touch ethical or marketing aspects, in the fact that patients don't want to be seen, even if it's true, they don't want to be seen that it's a fake arm, they don't want to be seen that they are disabled, which are very important aspects that, okay, if you want, we can discuss them, they have been partly treated, but maybe your presentation should be more for the electro-tissue brain interface in prostheses for those people. An important feedback you could give me is appreciation, and if the balance between academics and entrepreneurs is okay, or they are not all academics but not all entrepreneurs, not for possibility. And then it was a good problem because the secretary of our department immediately realized that people were fixated on... It was January of last year to try to invite almost all the speakers this year. And it wasn't like that, they are all slow, and therefore... No, we don't know, because the four lessons took them a month out of four, and then they had a mandate that we put in place, that we are here in the field, we can well understand the secretariat. Then you have to ask Nicola Fiscali, Reni, but that was precisely the fact. We started with the video. Yes. I don't do it. Instead, the professor, for the internship, for those who would like to talk, in reality, he told me anyway, saying, professor, the problem is, I don't know, how everything unfolds, but for me, you have to design it, internship equal to Ezzi or not? No, with an internship... No. Eh, for you it's good. And practically no. Okay. But, more than anything, you should choose a professor, a tutor, who is currently training, who I had at home in the company or just with a professor following at the moment? No, no, just a professor following. Clearly, because it puts me in contact with the company, my company is in contact with the company. Otherwise, the company is followed. So if you have something in the area of a plant, which is why we are here, Robati should have some contacts, so you could ask him. So if he has contacts, he knows, so he can be the internal referent. But I believe it's only to have a legal point of view, a responsible person who can follow you. He is in the company where the professor says "yes, yes, he showed up every day, it was pleasant to work with him." And you are always balanced people, right? It's just a word next to you, so from Macera, from how long you've been here, anyway, this is a topic. While in the thesis, the new regulation inside, it could be a bit competent. Usually it's not necessary for them to follow you if you go somewhere, or even to a company, between the thesis, the project, and the theses. maybe there's something that broadly needs to be competent, in the sense that if you have problems in theory, you could knock on the door and say, "I'm not getting any ideas," if you go to do something and I choose you as a referent, and I don't know anything about materials, ethnic, pipettes, etc., maybe I can help you, but I don't think we're there again, as long as the question of these objects. Okay, so that was the conclusion of last year, in which the equation that actually describes the temporal dynamics of the population of synaptic receptors of a chemical synapse, in simplified terms, is devoid of saturation terms and has as input something that is related to the concentration of neurotransmitter in the synaptic cleft due to successive activations and releases, but it has become a spike train. And this is exactly what we discussed because the first-year lectures are in parallel, more or less, not quantitatively as I did with you, I told the same thing. Here it is shown that if one integrates, one obtains something very trivial. Immediately before a presynaptic impulse, you have a certain value, and after this, it jumps to a high value. So, I only do this if I ignore saturation and only in simple terms. These are techniques, and this, in fact, is one of the most interesting and powerful descriptions on which we focus. What I anticipate is that I would like at some point to be able to remove or simplify the Dirac delta train because, after all, even mathematically, objects that go to infinity are not truly simple. But now I'll tell you why. So, I'm telling you that these are called field descriptions, or exactly the words I cited before, and they are also called rate models. So, there are no more spikes. While before they were called Integrate and Fire, and they had to do with so-called spiking neural models, models of neurons that fire, or spiking neural networks. I believe the Italian translation is "impulsanti," which is an ugly word, or "impulsanti" or "impulsanti." Now, fundamentally, I'm thinking about something that can describe the firing rate. I use the same letter I used before. Before, I was talking about a single neuron; now I'm thinking about something that is a population of many neurons, all homogeneous, though. They are all, for example, excitatory, all those that say "in puntalati," meaning, I don't want to put them all together, but if I have a billion neurons and I can think that from the perspective of intrinsic properties, your colleague just said in the interval, but why do those of the gyrus and the pyramidal cells of the prefrontal cortex have a different firing rate compared to those of the subcortical cortex? Okay, I don't know, but they are certainly distinct. And well, in case they are distinct, I say it's another box, another population. I'm thinking, I distinguish them, and if by chance those have inputs from the same hemisphere, while there is literally another population, maybe they are spatially interspersed, and they receive inputs through the corpus callosum from the other hemisphere. But then I have to say, wait, they are not homogeneous. However, in this stupid case, I come up with three populations, not with a billion internal equations firing one for each neuron. And that's why it's a particularly powerful and interesting description. And the first thing I do is show you the equation. This equation here, this equation here is the equation to which the fraction of open receptor state is related. It is said that the synaptic current is given by a certain maximum value multiplied by this O, the fraction of time, and then there is the driving force. If you allow yourself a further approximation, this is called because of this term which is a conductance, so this is what we called $g_{bar}$. There is a maximum value that is a value between 0 and 1. This continues well, and this type of description is called conductance space, so they are based on conditions. Yes, but I can think that roughly, I think of integrate and fire, I think of leaky integrate and fire, in fact, it applies to all, but the moment of emission of action potentials, when the potential V reaches high values, unlike neurons with conductance space, but not so different from real neurons either, it doesn't spend much time at +20 mV, it does it for a fraction of a millisecond, and then goes back down. So, this term here doesn't have such a dramatic impact. Clearly, it has such a dramatic impact that last week I told you that it even changes the time constant, the input impedance, the input resistance of the neurons, so much so that when one adds a little bit of TTX, the system of states to which those receptors are permeable, then it generates a current. However, since we are in an approach of simplification, if V is not, assuming that this $I_{syn}$ is, for example, the synaptic current, is around 0.000 V, if V does not have particular excursions so dramatic, it always stays below the threshold. I might be tempted to say, and if I V, V is a state variable, it's a term that changes over time, but I could say, if I think of substituting the average value here, I take the temporal average. Does it really change much? It changes a bit, but it's thought that it doesn't matter that much to have reduced the dependence on the membrane potential from the synaptic current. A little while ago, I finished saying that if you record this synaptic current, you will see that every now and then, apart from the effect of excitatory or inhibitory postsynaptic potentials, this changes, it goes up and down, this part goes up rapidly and then decays exponentially. So, you see this, but even if the sound is, for example, a spike, or the lithium, or the quality, you see it because there is a difference from zero. But if this difference from zero is particularly pathological, you might think that even if this is not present, or rather, if this assumes the value of a number, a fixed number, in the end, it doesn't change much. And it has a merit: if I do this, it becomes, instead of being conductance-based, current-based, meaning I enter the idea that two neurons communicate by communicating a current, and you might be disappointed and say, "But all the things we discussed about conductances, for the moment, I'll put them aside." I'll put them aside because in this way, I might think that this term here and this term here can be combined into a single number, a single parameter, which is a number. What remains for me is that the synaptic current is O multiplied by a number. So, if I have a differential equation that O satisfies, and $\frac{dO}{dt}$ equals that, maybe I can write exactly the same equation by swapping the letter O with the letter $I_{syn}$. If you want to do it more correctly, you should say: once I've made this assumption, I apply the derivative both here and here. It's an equation, so if the equation holds, the same equation holds when applying the derivative to both sides. If the two sides are equal, it means their derivatives are also equal. On the left, you will have exactly the left part of these differential equations. On the right, since these are constants, they are outside the derivative term. So, if you had a differential equation that started with $\frac{dO}{dt}$, you take this whole thing and put it on the right, where you have O, you only have it here, and you write O as $I_{syn}$, apart from perhaps dividing by this parameter. So, the parameters don't worry me particularly. Here too, I see there's a beta, there's alpha, tmax, they are numbers, I could group them. So, for example, alpha times tmax I could call kappa. This quantity $g_{bar} \times (I_{syn} - V)$ is like saying I take, imagining it's fixed at -55 mV, 0 - 55 mV, for that number, and I can find it with parameters, but the functional dependence is now. I can think that O, or $I_{syn}$, or O is the same thing, but that's the state variable, that changes over time with these differential equations, or equivalently with this. You see, this is exactly the same formally. Beta I saved here, W if you want to be meticulous, and you'll probably catch some errors. For example, I see here that having written this term, so here the $\bar{g} \alpha t_{max}$ is missing, but this term is missing. Anyway, it's a number, I called it W. I still put it inside, in a case like this where I had many things that were multiplied because they multiplied a bit, and then because before, in the previous equation, it was $\alpha t_{max}$ times the impulse train, I wrote it as a single value, I wrote it as a parameter like W, because in fact that W also has the meaning of synaptic weight. I am using a notation that is very similar to that used in some contexts when talking about synaptic weights. These synaptic weights are typically indicated as W. In fact, you are used to seeing synaptic weight matrices, okay, for every pair of IJ you will have an element $W_{ij}$. Now we are not there yet, but now, more or less, are you in agreement up to this point? The next step is to say, this is the case where you have a postsynaptic potential. This is the current that a postsynaptic neuron receives due to synapses, due to a synapse coming from another neuron. So, it's one-to-one, and in fact, the synaptic current that this neuron is experiencing is due to the spike train of only that neuron. It's a bit annoying because the summations make you think that you are already thinking of a sum extended over many presynaptic neurons. No, this is a sum over time because the presynaptic neuron, the one whose axon you see, there is only its axon, there is probably to make you reason that it is only one communication channel, there will not be a single spike, it fires a spike train. This is also a game here. Here I don't write $t_k$ because I don't know how many spikes there are, so I leave it unspecified. I mean that these $t_k$ are the firing times of this axon. So, the notation might get complicated now and say, wait, if you put another synapse from another neuron that arrives, for example, here, another synapse from another neuron that arrives here, and you have to distinguish because it's not said that the two presynaptic neurons have exactly the same spikes, so you have to change indices, you have to do something. But we don't have to mess around, we don't have to solve these equations, it's just the form that matters. So, from this, and it will only be this that interests us, I repeat, I combine this equation here or its slightly simplified version with the firing rate curve, which I say receives the synaptic current as input. To get the synaptic current, I have to solve this equation, but to generate the frequency, I have the firing rate curve. So, I can imagine that there is this function called threshold-binarization, which has a minimum value and then starts to rise, perhaps saturates or bends, or doesn't bend if there is adaptation, etc., etc. But, so the color that I consider instantaneous, and now again I will show you exactly what I mean by this instantaneousness. So, let me use colors and put in blue or black, blue, green, and red, the spike trains of three different afferences. Ideally, we think they are three independent afferences. This neuron here will therefore have three synaptic terms, three synaptic currents. Each representing the evolution of the population of synaptic receptors that are here and are activated only by these spikes. These others are on another branch, fine, it's not crucial that they are on another branch, but it's a different synaptic bouton, physically, another release site of another axon. In fact, the green spikes are synchronous with the red ones, I edited them, so I'm thinking they are independent and they will have, therefore, here there is another population of postsynaptic synaptic receptors whose activation generates another current term, and so on for the blue ones. This is not where the fact is. I know that it satisfies its potential of city of which I am thinking of the right term of the charge balance equation. And, beyond the intrinsic terms, we could think that this is an exponential neuron, a quadratic neuron, a leaky neuron, linear B, sub-threshold. This is the situation, I have this independent sum. I can, however, and here I write each of the currents as the solution of a differential equation of this form. You see that here I have written, I have to be careful, clearly, to distinguish things, so here I called it synaptic current 1, synaptic current 2, and synaptic current 3. This is this differential equation, it is equal to beta, let's assume they are all synapses of the same type, let's say AMPA, because this is the kinetics of decay, of unbinding, so when the receptor separates from the receptor, and it's the reason why the current decreases exponentially. Surely it's the same for all. This might not be the same for all, because it might have a different $g_{bar}$, it might have a different $t_{max}$, it might have an inversion potential, no, if they are AMPA synapses, I have to imagine they are the same. So, in the general case, I call it $W_1$, and so I'm thinking that this neuron here has, well, it receives three axons, each of which with a synaptic bouton, one comes from neuron 1, one comes from neuron 2, and the third comes from neuron 3, so 1, 2, and 3. And in any case, beta remained the same, and I changed 1, 2, 3. The thing I changed is the index I was talking about before, the index of this summation, and I also specified, even if the notation is a bit ugly, that these spike states are not the same because you see that the blue and the red and the green are not the same. But I need it, I could write it like this because it helps you. At this point, I could say, but wait, here, at this point here, the sum of the three currents appears. It doesn't appear, but surely. If you accept that this error makes the sum, only the position appears. If the position appears, I could say, if I sum these three equations together, what do I get? But it's an equation that means I take all the terms on the left side of the equals or approximately equals, this approximately equals is an approximately equals from when we said we throw away saturation and from when we said that the neurotransmitter concentration profile in the synaptic cleft is no longer a rectangle but a curve, so I pull it back. You see there was an equals sign in the middle, and I said no, otherwise it seems like it has become equal, but that's the approximation approach. Everything without the equals sign I sum together, and everything without the equals sign I sum together. And perhaps you see where I'm going, because here I have the sum of three derivatives, but the derivative is a linear operation, so the sum of the derivatives is the derivative of the sum. Okay, why is this interesting to me? Because I'm starting to get obsessed, and here on the right side of the charge balance equations, I have the sum of the currents, only the sum appears. It's not that if I call this sum $I_{syn}$ large, without 1, 2, 3, $I$ large, and I find a differential equation that tells me how $\frac{dI_{large}}{dt}$ equals something, and on the left, it comes back to me, because the sum of the derivatives is the derivative of the sum of this $I_{large}$. Here on the right, you see I have minus beta, minus beta, minus beta, so I factor it out and I'm left with minus beta times the sum of these three terms, $I_{syn1}$, $I_{syn2}$, $I_{syn3}$.

## Population Dynamics and Slow Sodium Inactivation

This is the large synaptic current again. Now, with this, I have to sum them together. If I go back to the case, so this is, can you see this, Marika? So these terms here, since the times do not overlap, are not coincident, it's as if I were to think of physically moving, rigidly towards, so I'm going to sum them, these three trading spikes. If I do that, since I used Dirac deltas and since Dirac deltas are zero everywhere, I just need to be careful and say, look, here I have to maintain the sum of these three Dirac deltas, and so I do the sum of the sums. This sum here, in fact, is going over the index of the postsynaptic neurons. There were 3, 1, 2, 3, and these W's are outside the summations because they have an index M that varies from 1 to 3. So, in the end, I'm starting to convince myself that this W could even be a kind of matrix, but for now, it's a vector, a vector of three elements. While this other summation of deltas, which you see I've changed further, from the generic time index because it depends on both m and k, because if m equals 1, it means I'm thinking about the red times, but anyway, here it's not because if you see it wrong on your screen, if you have it, you'll understand it later. I swap them, and it's as if this situation here is to treat a single, unique afference that has many more spikes, but the two situations are indistinguishable because the spikes I had before were independent and have been summed. Summing means overlapping when talking about deltas, also because they are functions, as they say, with null support, meaning they are always zero between the two. So if I sum them, there's no build-up, I simply have more, and I have three times more. So, if in some way you could say, okay, this stuff makes me go to university, and the university pays Michele Giuliano once a month, but there are three of them, they overlap. This is like another Michele Giuliano on steroids, muscular, who gets paid three times a month. In the end, since the impact is not individual, but is, a single quantity appears here, it could be three Michele Giulianos or Michele Giulianos with steroids. Since it's a single quantity, there's no difference. But it's easier for me to reason with a single differential equation, regardless of the number of afferences from other neurons. I want to do this because instead of talking about whether a neuron, this neuron here, has a thousand other neurons as pyramidal neurons, or ten thousand, as in the case of human pyramidal neurons, so a thousand or ten thousand afferences, and I don't want to write a thousand or ten thousand differential equations of this type, but I want to write one that tells me that up to this point there is no further approximation due to this overlap of effects. This pleases me because it tells me the total, integrated behavior. Let's take another step. Now I'm not just thinking that there is a single neuron, I'm thinking that in fact there are many. The i-th neuron experiences a total current, this micro-gene, on steroids, but the i-th is for this one. Another neuron will have another current because the connectivity is different. But this one has a total synaptic current with the index i, where you have this minus beta i, exactly equal. Why do I say this? Perhaps you thought there was a network, and it's not that a single neuron receives many afferences, or a neuron that receives an afference, but this one says others. This one had one, and I must be able to distinguish them by calling their generic i-th one. And this would be the same for all because it's a population of homogeneous neurons. And what I did here, whereas before it was just a summation from 1 to 3, so this summation over j, forgive me, I made a mistake, this is i and this is j. But forgive me, I simply inverted the indices and lost the indices because I don't remember that by convention W_ij, the first index is the neuron of arrival and the second index is the neuron of departure. I always make this mistake because I'm inclined to look at things in a left-to-right order, so for me, logically, i is upstream and j is downstream, but no. There are mathematical conventions for which it is more convenient to choose the first as arrival and the second as departure, but it doesn't matter, you can forget it for now. Here, before, I had called it M and it went from 1 to 3. Here, in fact, it goes from 1 to 3. These are the 3 neurons that I call J. I should call them with numbers, but for simplicity, I call them J. Do you agree that I could do this sum not only over the neurons that are actually connected but over all neurons in the network, provided I bring along a fictitious additional number, C, which I think is a value that can be 0 or 1, and C_j is 1 if there is a synapse between neuron J and neuron I. I'm not saying how strong it is; W_ij tells me that, but I have an additional term that tells me if that term exists or not. I mentioned it before, this value here can exist, so it's not K+1 but J+25. This value here, for any presynaptic rule, is not connected to that, but mathematically it's true that this summation, and therefore it's not an i-th, should only explore these three presynaptic neurons. I make it explore all of them, even this one that is not connected. In that case, this variable C_ij is 0. So I'm left with a single expression that tells me what the synaptic current is for a generic neuron in the network. I'm bringing along a matrix; this is a matrix because it's a binary matrix, called an adjacency matrix, and it tells me if, at row i, column j, I find a 1, it means neuron j projects to neuron i, otherwise not. So this is a structural term that tells me the topology of the network, and W_ij is a quantity that, if it's not this with this, this will have the value you want, anyway, it's not full of zeros, so it's greater than zero, for example, but it doesn't matter which one because if all of them are the same, they all have the same efficacy, given that C prevents me from erroneously counting the contribution of a neuron like this one, which was said to be a synapse, but it... it either insists on no one or insists on someone else. This one, who knows who it insists on. It certainly doesn't have a recurrent synapse that goes bidirectionally, that also goes to orient on whom. Yes? But you were talking to me over there, that in the case of minor synapses, its... And the same thing, only the concept is, if these were all synaptic, they were all of the same type, this is the total synaptic current that a generic neuron receives. I must, with its point, say, this is the total excitatory synaptic current, due to the AMPA receptor. I could specify it this way, I should do it, to say, this neuron also receives inhibitory synaptic terms, no problem, or another equation in which this synaptic current value I call it differently. I would call this AMPA synaptic, and then one I call GABA synaptic. I'm thinking that the neurons become generic. I can think of a neuron, so I imagine it's a fat neuron that receives AMPA, NMDA, GABA input, theoretically GABA, GABAB, or whatever it is. Again, instead of talking about a billion differential equations, here at most I'm thinking of a way to have as many differential equations as there are types of receptors. In reality, the thing could be more complicated because I could think of different presynaptic populations, but for now, so this, rightly, I must specify that it refers only, for example, to the excitatory component. Yes. To say what W is? W is a term that analytically we obtained by multiplying alpha, tmax, gbar, and this quantity here. So it's something that has a link to biophysical variables that at some point, by dint of being simplified or approximated, have translated into quantities that have even multiplied together. I recall that alpha was the proportionality term of the closed-open kinetic scheme, it was alpha times tmax, tmax was a time constant, gbar was the maximum conductance, this was what remained of the new, and perhaps. They are all terms that, by writing those mathematical equations, where for the first time I started to say, forgive me, this is an approximation because I threw saturation out the window and put the dI_REC term, they were found as factors of a product. Instead of carrying them around, I called them with a single term, W, for simplicity of notation. No, it's a number that you can see as a unit of measure. You have to pay attention to the unit of measure of the area, but you could say that this is ultimately a kind of current, it's a current value, because this is a current value, gbar times this time constant was a current value or a dimensionless value between those two neurons, the presynaptic j and the postsynaptic i. This ensures that the synaptic efficacy, that alpha, that tmax, that gbar are specific to that synapse. In fact, in theory, they could be different. Even I, who am neuron i, could project to neuron 1 with a synapse, always excitatory, a weak synapse, and then to neuron 27 with a strong synapse. I don't have to write that down somewhere. More physically, from the active point of view, the neuron, for example, 27 has many more postsynaptic receptors, while neuron 1 has fewer, which are its own, which sense my signal better or worse. My signal, which could be repeated by me, by that tmax, tbox, if you really remember, is the amount of neurotransmitter released, and it could also be subject to synaptic plasticity. So in theory, that synapse has a lot of vesicles, it's not weak, it releases little. Instead, 27 has a large synaptic terminal, and when I talk about releasing a lot, everything goes in the direction of saying, I don't know, in the most general case, I think these synaptic coupling values can be different, specific. What you are probably thinking of is the following: if this value is small or large in a feedforward network, it doesn't matter to anyone. In fact, I'm thinking of a neuron that receives many input connections, and whether this connection is practically negligible compared to this other part. Yes, maybe I, in the synaptic current, will fire spikes predominantly correlated in time with the activation of that one. Perfect. But it doesn't matter. What you probably have an intuition for is in a recurrent network, where the structure of the network has recurrence. Excuse me, but I made a mistake, because we have to finish at quarter past four. Right? Okay. Because I still have twenty minutes, but let's not do twenty minutes, let's do less. Excuse me, when there is a recurrent network, in theory, if I change one value, I'm not changing the value of the other connections that are, imagine they are fixed, they are given, but damn, if I change the electrical activity of the entire network. And this is a problem I'll mention shortly, because at this point, for this type of form, it seems that the spike trains come from the outside. And the fact that these parameters, even the connectivity parameters, are large or small, in the case of 0-1 connectivity, okay, if you look at the synaptic current, what does it do? In reality, the synaptic current certainly influences its presynaptic neurons, so these firing times contain, probably, the spikes that depend on how much the synaptic current was a moment ago, but because obviously this is the most critical, most delicate point, because in that case, the next step of simplification I want to make, I can't do it, I can't do it because it's wrong. People do it anyway and verify that things work well, meaning comparing a microscopic integrate-and-fire simulation with a simplified one, and things match. And I'll tell you why, perhaps. But if I only consider the connectivity on the channels, what happens at the level of the synaptic terminal? In the neurobiological description I gave you last year, the postsynaptic channels are in the membrane of the postsynaptic terminal and are in the part that faces the presynaptic terminal. Okay, but there will be a, there will be an example, this might have some spatial extension, for example, how would a synapse have, a somatic synapse? So this is a somatic synapse, it could be a lower-dendritic synapse, but I consider them all together because I'm saying that the postsynaptic neuron is a point neuron. As soon as I introduce space, this discussion obviously falls apart, unless you say, okay, I concede that, I don't like that it's a single point, unique, but I think you should at least do two compartments, as I briefly mentioned last year, which was necessary to understand extracellular potentials, with a bit of a role, nothing is given anywhere, at least when there is spatial extension, it doesn't make sense. Here, however, I am effectively ignoring the extracellular aspect, I am thinking that even if this synapse is on the dendrite, this is an excellent point you made. There might be attenuation from the dendrite to the soma, so perhaps the W I have to put in is a W that is attenuated by the electrotonic distance between where the synapse is and the soma. But still, this is a non-trivial but approximate way, not approximate but subject to criticism, but it's reasonable from a certain point of view, which says it's possible to reduce a very compartmental model to a point model, if the dendrite is passive, yes, provided, of course, you scale and attenuate a lot the synapses that are very distant compared to the direct ones, thinking about its history, and therefore in theory they are so close to inducing a postsynaptic potential error that they cannot be placed here with the same weight. Okay, they could be weighted algebraically differently, and the real objection could be, but an algebraic change is not enough for me, because last year I told you that it doesn't just change the amplitude of the PSCs, it also changes the shape, they become stretched. So in theory, eta is a remarkable abstraction, a bit of a stretch, because that's why I'm trying to anchor them to the mathematical part. If you somehow study the brain and say that from one step to the next things more or less make sense, then you can review this situation of tau and its meaning, and I can understand where it fails, which are the objections you are making. Yes, but I don't need to simulate, because if I simulate, it means I am actually generating or storing the entire state of a simulation of a billion integrate-and-fire neurons with their synapses. This is a way to abstract and say, wait, perhaps instead of doing a simulation with a million differential equations, I can do a simulation with one differential equation, maybe two if there's the inhibitory component. AMPA and NMDA, but there are works, including by colleagues, including myself, done with NMDA, AMPA, and GABA A. But in theory, I would like an entire population to be described by this equation alone. The thing that bothers me is that I still have spikes, and I don't know when these spikes happen. I imagine they can be described, but I don't have them. This is a structural thing that I can know. You give me a network, a simulation, I can write the code you made, or you give me a piece of brain, I could theoretically see what the connections are like, so I can know this. This here I could say, in your simulation, I deduce it from the product of these parameters, maybe if you have compartmental models, I try to weigh it well with the attenuation, etc., etc., but these I don't have, I have to do it by simulation to generate them. It's not that there's a way to replace this with a number. What number could it be? It could be, but for now, it doesn't make sense for you. This is the activity. This situation here says, then the total synaptic current that this neuron is experiencing, it's experiencing it because the presynaptic activity is active, there are spikes, these spikes are happening with a certain temporal correlation. I can even say they are happening with a certain frequency. And you tell me, no, each one could have its own frequency of 10 Hz, and this one is firing once per second, this other one is perhaps silent. And then I say, okay, and if I don't average in space, can I call it presynaptic frequency, F_large? And you tell me, but it's like the bank account story, meaning this is a point process, it's a Poisson process, a stochastic process, so it's actually a stochastic process, not a deterministic thing. Okay, but if I could, under some conditions, replace this spike train with a number that is the average frequency, averaged over space, because after all, this is a summation that extends over space, then I have an equation without spikes that links the presynaptic firing activity to the postsynaptic activity. And if I add the frequency-current curve, the frequency-current curve converts the synaptic current into the postsynaptic firing rate. So I could say, I'm done, I have an equation, I have two, depending on whether I have inhibition, I'll show you, you see it's simple, in which a single equation, a differential equation with a relationship that tells me F given I_synaptic, if I solve it, I can predict what a network does. And the cool thing is that it works even if the connectivity is recurrent. Unless they are all connected to all, but that's a special case. The current would become the average neuron? Average. Correct. Now, before I finish, in these five minutes, I'll show you that I'm doing exactly the averaging operation. And now I'll do it, let's say, for you, from Marco Di Rose. I'm not saying, so I invoke the expected value operator, and surely you are studying in depth with one of these partitions. I simply say that there is a fourth operator, which is the average, and I will indicate it with angle brackets, so as in physics, the average of a quantity is done. Average of this equation with these hypotheses, which are those I started to mention: all neurons have common intrinsic parameters, I'm thinking of tau, I'm thinking of the frequency-current curve. Then, obviously, if it's not like that, but I can separate them into two classes, then let's focus on one of those two classes. Each one does not have identical intrinsic parameters, so from the postsynaptic point of view, each one... this is where your colleague would start to get angry, each neuron fires independently of the others. If a network is recurrent, if a network is feedforward, okay, I accept it, but if a network is recurrent, no. However, if I can assume this independence, this spike train becomes simply a stochastic process that doesn't depend on anything, it depends on some parameters, so it doesn't depend on me, the postsynaptic one. I fire for the economy, not because of what happens downstream. Otherwise, there's something self-consistent, and we can manage it, but we'll manage it in a moment. And each neuron, this is the statistical part, of which I give you some very simple elements, fires as an irregular stochastic process. It must be irregular, otherwise these things don't work. So in theory, if it were a uniform pacemaker, things would work well, but it's done in a statistical context because I want to apply a statistical operator, an average, and I say that all neurons fire with an average frequency that I call F. If these are the operations, I can effectively say that the neurons are indistinguishable. The only thing that matters is the field they are receiving, this synaptic current, which can be shared, not individually. Before, each one had the index i, so synaptic current 1, or synaptic current 25, they are different, but perhaps their average is the same. So, taking this equation and applying the average value, the average of the derivative is the derivative of the average. The average of a quantity multiplied by a deterministic number, a scaling factor, is the scaling factor times the average. The really complicated thing is now the average of this term here. The average of a sum is the sum of the averages, I can, I can exchange the operators. And here you see there's a product, there's this times this. Our colleague would say here, "Strasmo," because you can't think... I can think that this matrix, which is 0, 0, 1, can be described as a set of random variables that have a certain probability of being 0 or 1. So if I can calculate the average, I can calculate the variance. It would be a Bernoulli random variable, which we might see next time. And you can say, watch out, because you cannot average a product; the average of a product is not the product of the averages if the quantities are statistically dependent. If they are independent, as we assumed, then yes. So if there is a particularly connected network, but the firing is independent, in a feedforward case, whether there is intense connectivity or not, it doesn't matter. The activity comes from downstream and propagates without feedback. But it is only in that case that I can average the product, the product of the averages. So first I swap, and then I swap the average of the sum with the sum of the averages of this term here. And now I have to average this quantity times this quantity times this quantity. With the hypotheses I made, the average of the product is the product of the averages. Otherwise, obviously, it's that objection saying: you can't do that. That is, if the connectivity of a network changes the occurrence of spikes, even the frequency, if it's a very, very connected network, the connectivity will be very high, and vice versa. If the synapses are particularly intense or particularly weak, if the network is recurrent, it's clear that these terms are not independent. Perhaps these two are independent, meaning the fact that two neurons are connected might have nothing to do with whether the synapse is intense or not. Okay, a necessary condition, if two neurons are not connected, I don't know what the value of the synaptic weight means. So, to make it short, and I'll conclude here, for now it doesn't make sense. I'll show you a case where this emerges, which is the case of, let's analyze next week, the case of that slide where you had many, many afferences, and at some point it became a Gaussian process. Before, it looked like many little impulses going up, but when there were many, many, many overlapping, it practically became a continuous stochastic process. For now, this average of the product is the product of the averages, where this small c is what is called the average probability of connection, of connectivity. This is one plus a small number, it's the average of this set of numbers. Forget that it's a matrix, it will be n by n numbers. I average according to the probability distribution, I average, and I get a value. The average, and this is the most annoying part, is, this is over Dirac deltas. Okay, this is not a common integral, it's an integral that then multiplies by the probability distribution density. This thing here can be written with the average frequency, and if I do that, you see it has become an easy differential equation, let's say, without Dirac deltas anymore. Something I could start studying, and next time we'll do it. I'll try to record an intermediate lesson, trying to ensure that even if you don't watch it, because now we meet both Thursday and Monday, right?

## Population Dynamics and Slow Sodium Inactivation

So, don't end up with two and a half hours of me talking. Try to do something in parallel, but you could simply think about this: think about it, if I have this differential equation, can I study what happens at steady state? At steady state, last year when I had equations like this, I said if it's the temporal steady state, it means that the quantities do not depend on time, which means this thing is equal to zero. When is that thing equal to zero? What does it mean? It means that a network has an equilibrium, and we'll see this next time. Sorry if I've abused a few extra minutes. This is a tough part, and I'm presenting it to you phenomenologically. So, on one hand, you might be happy and say that I didn't do the integrals of the density and probability distribution functions. Or, you might say this is gratuitous; I don't understand it; it's imposed on me. But you decide if you are happy or not. Alright, see you next week. Welcome back.

