Ok, allora, sarebbe più bello se potessi scrivere, ma evitiamo di fare cose troppo complicate. Volevo cercare di fare una breve introduzione su quello che è stato il contenuto dei due video di questa extra class che sostituisce la lezione del venerdì di un paio di settimane fa, quando sono rimasto bloccato all'estero. In quella sola lezione vi ho fatto vedere come, ad un certo punto, e l'ho preso come caso isolato, quindi anche se voi non l'avete ancora guardato, studiato o approfondito particolarmente, in qualche modo è riferito a come trattare questa equazione dall'alto, data questa equazione se, indipendentemente dal significato, se con alcune ipotesi relative a questo termine, questo è quello che ho chiamato processo di Stein, non so esattamente che sia Stein, è possibile estrarre delle informazioni statistiche su questo termine qui e di fatto sostituirlo in quella che viene chiamata approssimazione di diffusione con un processo che non è puntuale, non è un point process, che ha un cosiddetto shock noise, chiamato anche, ma è invece un processo stocastico continuo, che è un termine, per esempio, un rumore bianco, che voi in qualche modo potreste sostituire qui. Perché questo ha senso, perché questa ha importanza? Perché questa equazione qui, di cui adesso riprendo brevemente, la ridiscuto brevissimamente, è l'equazione della corrente sinaptica totale che un neurone generico di una rete riceve. Unitamente alla curva frequenza corrente, o in generale alla dinamica con cui poi gli spike vengono generati, data una certa corrente, questa equazione e quella del modello o la curva frequenza corrente, se volete invece la dinamica, per esempio con un internet and file, ma potrebbe essere anche una dinamica di un modello con data space, potrebbero dirci tutto su come, in una certa accrossinazione, la accrossinazione di campo medio, una rete evolve, studiando come un singolo generico evolve quando riceve una corrente. Scritta così, questa è una corrente particolare, specifica, è quella totale che riceve il neurone iesimo e quindi ha tutte le caratteristiche in particolare della cosiddetta matrice di connettività, della efficacia sinaptica e della precisa attivazione delle fibre afferenti che arrivano a quel neurone iesimo. Infatti questa somma è su tutti i neuroni geiesimi che sono presinattici rispetto a questo neurone iesimo. Anche quelli che non sono connessi avranno questo valore di questa matrice, 0. Invece, in quell'altro approccio statistico, io fondamentalmente riesco a qui scrivere una quantità che è un processo stocastico continuo, diffusivo, che mi è più facile perché qui, come detto, nonostante il mio interesse e passione per le delvehier, sono delle brutte bestie. E quando invece avete qui un processo stocastico a valori continui e tempo continuo, senza impulsi, semplicemente istante per istante e una variabile aleatoria, magari gaussiana, che mi piace per altre proprietà, forse le cose vanno meglio. In questi due video, in questa lezione, extra o che sostituisce quella precedente vi ho dimostrato come o qual è il processo che dovete mettere qui ed è un processo di nuovo diffusivo, continuo e un rumore bianco alla fine con media e varianza note media e varianza che sono date dalle caratteristiche di questo termine qui della statistica di questi istanti qui abbiamo fondamentalmente due strade La prima è, tu mi hai dato media e varianza e mi hai detto che il processo qui è gaussiano, quindi per una variabile allenatore gaussiana non ho bisogno di altro, mi basta media e varianza. Se vi date media e varianza è determinata la densità di distribuzione di probabilità di quella varia, è determinata, cosa che potrebbe non essere per altre distribuzioni. Quindi io potrei usare media e varianza. in questi discorsi in cui voglio approssimare quello che è il campo medio, lo dicevo la settimana scorsa, il campo medio si intende il campo di forze, perché questa trattazione viene dalla fisica degli spin magnetici o dei vetri di spin, in cui il campo di forze, il campo di ingresso per una unità di una rete, di un sistema complesso, è descritta in termini medi. In realtà vi ho detto, io ho media e varianza. Quindi perché sono la media? quindi a un certo punto, quando l'altra volta, la settimana scorsa, ho fatto i singoli step per passare da questa equazione alla sua approssimazione di campo medio, cioè ho applicato l'operatore valore atteso per calcolare la media di questa corrente. Voi potreste dirmi, aspetta, tu ci hai fatto una testa così in video e hai detto che hai anche la varianza. Ok, quello si chiama campo medio esteso, esteso anche alla varianza. Per il momento, per la trattazione odierna, in modo da rendere la lezione in più online, in video, in parte slegata, dico che per il momento mi basta descrivere il campo medio, non il campo medio esteso. Il vantaggio di questa descrizione più semplificata è che adesso fra un po' posso analizzare quello che viene fuori con dei grafici, non devo farvi vedere nulla di numerico. Quindi per farla breve, questa era la conclusione della settimana scorsa, e alla luce di questi due video extra, è solamente una parte della descrizione, una parte che dice come cambia il valore medio della corrente, ma in teoria potrei scrivere come varia la varianza della corrente, per questa corrispondenza fra processo puntuale, con point process distribuito come Poisson, come invece in termini più valenti come approssimazioni di diffusione, come processo stocastico più valente diffusivo sotto certe ipotesi. Ma qui noi prendiamo soltanto la media e l'unica differenza che c'è con la trattazione che ho fatto online e che qui mancherebbe la tau, mancherebbe la costante di tempo che è data dall'inverso di beta. Scritta così comunque è ugualmente rappresentativa e ripeto, sto soltanto considerando il termine di media. Allora, ricapitolo che cosa ho fatto. Sto pensando, sto immaginando di avere una rete complicata come volete. per il momento in realtà mi sto immaginando una rete in cui non ci siano connessioni riverberanti e ricorrenti ma nella realtà le cose funzionano anche quando questa ipotesi è violata e anziché descrivere e simulare tutti e singoli neuroni supponete che siano qualche milione, qualche miliardo ogni singolo neurone ha una sua variabile di stato supponete che vivono singoli con un'integra spara e supponete che abbia una matrice di connettività, per esempio sufficientemente sparsa, quindi io stia facendo microscopicamente tutto dal punto di vista della forza bruta per simulare istante per istante, risolvere le equazioni differenziali, per esempio una o due equazioni differenziali per ciascun neurone, più quella che mi dice qual è la corrente sinaptica totale, per tutti è qualche milione di unità. Invece di fare così, passo a una descrizione approssimata, media, in cui dico, no no, io scrivo soltanto questa equazione. E l'equazione che è un neurone generico, visto che sono tutti indistinguibili, per ipotesi, sperimenta e per semplicità ignoro il contributo che dovrebbe essere incluso di varianza. Quindi quello che mi resta è passo da una situazione con qualche milione di equazioni differenziali a una situazione in cui ho un'equazione soltanto, questa equazione differenziale qua. E poi ho un'ulteriore condizione che mi dice come questo campo medio, questa corrente media, viene convertita in spike al secondo, in frequenza, cioè la curva frequenza corrente. Quindi queste erano le ipotesi. Tutti i neuroni hanno parametri intrinseci identici. Se così non fosse, semplicemente lo mettiamo tutti i neuroni in uno stesso blob, userò questa espressione, ma utilizziamo una seconda ipotesi, che tutti i neuroni sparano in modo indipendente dagli altri e potreste essere in forte disaccordo se la rete è una rete che ha delle condizioni ricorrenti, perché se sono ricorrenti c'è un qualche tipo di feedback, è impossibile che il file non si influenzi a vicenda. Tuttavia, anche allentando la stretta su questa condizione rigorosa, le cose continuano a funzionare e ciascun neurone spara in modo irregolare. Se non ho questa ipotesi, le cose non funzionano dal punto di vista della trattazione dei video online in cui per la natura stessa di quella trattazione ho bisogno di considerare processi stocastici e quindi variabili aleatorie, cose che sono disordinate, così io che possa dire uso gli strumenti della teoria delle probabilità. In questo caso, questa rete di neuroni è arbitrariamente complicata. In questo caso qua vedete che non ci sono connessioni ricorrenti. Ovviamente è un cartoon, è una cosa molto stupida. Sono sei neuroni e non c'è una connettività da qualche parte, un feedback a nessuno. Quindi qui più o meno i neuroni stanno sparando in modo quasi indipendente. Anche se il firing di questo neurone qui è ovviamente influenzato dal firing dei neuroni presinattici. quindi questa è una condizione che a rigore non è perfettamente verificata ma nella pratica questo metodo di approssimazione, questa teoria del campo medio funziona funziona ovviamente meglio quando la teoria viene estesa al caso della varianza e anziché risolvere, in questo caso sono sei neuroni quindi avere sei equazioni differenziali nel caso di un integra e spara Magari le equazioni sono 12, perché per ciascuno c'è, per esempio, l'adattamento frequente dipendente, poi per ciascuno c'è una differenziale che dice come cambia la corrente sinaptica per quel neurone. Io qua dico no, ok, descrivo soltanto con un'unica equazione il campo medio che un neurone generico di questo blob, di questa rete, sperimenta. Il che è molto potente perché di fatto qui sto dicendo che mi serve solo questa equazione e la curva frequenza corrente. cioè una non linearità statica, una qualche funzione data, nell'integra Spar, addirittura l'abbiamo calcolata analiticamente, che mi dice qual è il valore della frequenza f di uscita quando la corrente di ingresso sinattica è data. Questa equazione differenziale mi dice come varia la corrente sinattica media al variare della frequenza presinattica. automaticamente con questo, non è un sistema di due equazioni, è questa coppia di condizioni, mi suggerisce che possa descrivere in modo compatto con quello che viene chiamato firing rate, quindi non ci sono più spike, l'unica cosa che descrive l'attività della rete è F, F può cambiare nel tempo perché la corrente sinaptica cambia nel tempo, e quindi si passa con questo modo che vi ho raccontato come riduzione della descrizione precedente alla classifica di modelli che si chiamano firing rate. Per esempio nel libro di Eppert o in altri libri, la trattazione è questi sono i modelli con Duff and Stains, questi sono i modelli integre spara e questi sono i modelli firing rate. Non c'è necessariamente una derivazione da uno all'altro. Fra i conduct and space e gli integrated and fire, vi ho cercato di far sviluppare l'intuito che continuasse comunque a valere l'equazione di bilancio della carica, C, D, V, T, bla, bla, e semplicemente avessi buttato via le correnti soldi e potassio. In qualche modo potreste dire, ok, però il valore di C resta lo stesso, il valore di G-leak restano gli stessi. Anche qui in questo caso ho cercato di derivare, se avete questa popolazione di neuroni connessi sinapticamente, il modello marcoviano a due stati aperto e chiuso, di fatto con alcune approssimazioni non ho più la saturazione e gli impulsi di neurotrasmettitore avvengono come delle delte di Dirac, posso ridurmi con questa ipotesi, applicando l'operatore media, a questo tipo di modelli. Quindi in altri libri invece, questa è la nostra descrizione, il finding rate di una popolazione è descritto da un'equazione differenziale, o comunque da una quantità che poi metto dentro una non linearità istantanea, che mi dice com'è il finding rate di questo blob, quando per esempio cambio qualcosa nell'attività presinaptica, o nell'attività del numero di neuroni, nella connettività media, nell'efficacia sinaptica media, oppure addirittura nella cinetica di chiusura. Quindi se sono recettori AMPA, se sono recettori NMDA, se sono recettori GABA, cambierai il numero e in teoria potrei studiare cosa succede. A me piace questo modo di collegare l'uno all'altro, che fa pensare alla riduzione e a che cosa ho buttato fuori dalla finestra. Qui è evidente che non ho più gli spike, addirittura più evidente non ho neppure più i singoli neuroni. Vediamo che cosa imparo da questa trattazione. Inizio molto bene, noi facciamo un modello a campo medio, poi rimuoviamo gli spike e continuiamo a fare un modello di faring rate. Il modello di fine rate si ottiene togliendo gli spike in questa equazione della corrente sinaptica. Quindi se vuole è più importante la descrizione della corrente sinaptica più che dell'integration fire. Il modello di neurone è diventato soltanto questa descrizione input-output. se mi dai una corrente sinaptica io ti rispondo con un certo numero di spike al secondo. E alcune delle vostre visioni sarebbero coerenti dicendo ma queste espressioni qui della curva frequenza corrente l'abbiamo derivata nel caso in cui la frequenza di sparo era regolare, non irregolare. Sì, questa è una cosa per non appesantire troppo la trattazione, non rendervi la vita troppo complicata. In realtà la curva a frequenza corrente, che era il motivo per cui nelle tranche sperimentali, nell'esperimento che vi ho descritto una scorsa e due settimane fa, l'Integra e Spara riusciva a predire non solo la curva, ma la curva con colori diversi, perché davo in pasto a un'espressione che si chiama curva a frequenza corrente, si chiama funzione di trasferimento, sia la media che la varianza. In realtà media varianza e tempo di correlazione. Qui sto facendo una cosa più semplice e lo sto mettendo in effetti in relazione a quello che abbiamo fatto assieme. Sì, l'abbiamo derivato solo per frequenza regolare, per frequenza uniforme. Qui sto dicendo che grosso modo funziona allo stesso modo. Se volete fare le cose per bene dovete avere sia un'equazione per la media, sia un'equazione... Questa è un ritardo, non mi vuole, mi riesco e mi sento. Quindi questa equazione della media, dovete averne un'altra equazione che vi dice come cambia nel tempo la varianza, e questa equazione, questa funzione che dice qual è la frequenza, deve avere una dipendenza, dovete calcolarla, e si sa analiticamente per alcuni neuroni, per l'integra e spara, l'ichi, quadratico e esponenziale, si ha questa forma ma è complicata ed è dipendente dalla media e dalla varianza noi però per facilità per il momento gestiamo soltanto questa condizione in cui abbiamo solo la media quindi è teoria di campo medio non teoria di campo medio esteso è storicamente una di quelle che è stata per la prima volta negli anni 70 proposta L'approccio è molto interessante e vi chiedo adesso di assumere per la parte frequente, un approccio un pochino più sportivo. La semplificazione che adesso faccio è, non mi importa se la curva frequenza corrente di quel particolare integra spara, per esempio, coinvolgeva una espressione che aveva a che fare con il logaritmo, forse vi ricordate, sto a spanne dicendo ok, è qualcosa che ha un comportamento threshold linear cioè sotto una certa soglia di firing rate in uscita è nullo e sopra ha un qualche comportamento lineare alla fine questo l'abbiamo addirittura derivato analiticamente come condizione estrema quando la corrente di ingresso è molto elevata io ho anche insistito sull'effetto del tempo di reflutarità assoluto che in qualche modo piega, fa saturare la curva a frequenza corrente. In generale adesso per questa trattazione che faccio in modo grafico, per semplicità, in modo tale da rendere molto intuitiva le descrizioni che facciamo, penso che questa funzione frequenza corrente sia descritta da una funzione threshold linear. Magari aggiungo a questa funzione threshold linear una saturazione e vi farò riflettere sul perché questa cosa della saturazione diventa importante. Quindi mi sto mettendo nell'ordine di idee tipica dei modelli di firing rate in cui la gente dice questa è l'equazione dinamica del campo medio e questa è la funzione di trasferimento ingresso-uscita e la prendo threshold linear oppure sigmoidale oppure a gradino. Vi faccio notare che questa esatta trattazione a questo livello è la stessa che avete, se qualcuno di voi lo ha mai studiato, nel machine learning con il modello elementarissimo del percettrone. Quindi questi che vengono anche chiamati rate models o firing rate models, Nel caso di un circuito feed forward, sono esattamente la stessa matematica, o molto simile a quella del percettrone, dove avete un'unità che nel nostro caso... ...di neuroni... ingresso uscita e esiste una qualche corrente minima sotto la quale il neurone non spara sopra la quale i neuroni sparano e questa condizione in un caso molto semplice è che se la corrente è sotto la frequenza è nulla se la corrente è sopra questa soglia i neuroni sparano. C'è un'interpretazione geometrica molto interessante di cui sicuramente avete sentito parlare, se no ditemelo, ma la rivediamo assieme, in cui in una rete, il feed forward, se l'ingresso sinaptico è dovuto al termine generato da altre due popolazioni presinaptiche, che le vedete indicate qui, questi due altri blob, ciascun blob spara una frequenza diversa, F1 per il primo blob e F2 per il secondo blob. Ciascuno di questi avrà una sua funzione di trasferimento, però a me interessa quello che è l'uscita, F1 ed F2. Nell'interazione con questa popolazione post-sinaptica, ci sarà una qualche matrice di connettività, che qui è uno a uno, nel senso che questi neuroni presinapti, questa popolazione presinaptica è connessa alla popolazione post-sinaptica, e c'è un peso, un'efficacia sinaptica media, che qui ho chiamato W1 e W2. Chiedo scusa che qui non si veda un granché. Se io semplicemente considero allo steady state, Quindi immaginando che beta sia molto grande, quindi 1 su beta che è la costante tau della dinamica sinaptica sia praticamente istantanea, posso in questo contesto specifico scrivere che la corrente sinaptica totale è la somma delle correnti. Cioè sto ignorando per questo esempio questa parte di dinamica. Essendo questa parte a zero perché sono già allo steady state, dico che, se questo lo porto al primo membro, dico che la corrente sinaptica è uguale a parte nCW, è uguale, è proporzionale alla frequenza. Se ho due popolazioni avrò un altro termine più nCWF, un F1 e l'altro F2. Uno potrebbe essere W1, l'altro potrebbe essere W2. C1 e C2, n1 ed n2. se faccio così? Sì? Non ho capito questo è come se stessimo eliminando la parte legata a beta e sinistra Allora, menzionando il percettrone nel percettrone c'è questa descrizione della corrente sinistra che non è dinamica è identicamente la corrente sinistra che è identicamente uguale alla somma pesata delle frequenze delle popolazioni presinaptiche. Quindi, nella speranza di farvi capire che questa alla fine è la stessa cosa, volevo, e non l'ho detto in modo molto corretto, che questa espressione qui è di fatto la stessa espressione che abbiamo visto qui, Tuttavia, assumendo che i termini con la derivata non ci fossero più, che l'espressione fosse identicamente allo steady state, la cosa diversa che vedete qua è che qui c'è solamente un termine, ncwf, nel caso di due popolazioni che insistono qui, il neurone generico di questa popolazione sperimenta un termine di corrente dovuta a una popolazione e un termine di corrente dovuta a un'altra popolazione. ma il tipo di riduzione fondamentalmente è sempre la stessa. E qui è molto semplice perché ce ne stiamo infissiando della varianza, quindi stiamo parlando soltanto della nebbia. Quindi è la stessa cosa, però nel linguaggio dei percentroni questa relazione è diventata una relazione algebrica. In effetti nel machine learning utilizzare una dinamica per le correnti sinaptiche non è chiaro quale sia il vantaggio oppure no però quello è un contesto molto particolare in cui voi sapete c'è una fase di adestramento ma soprattutto una fase di inferenza che è un termine che non amo moltissimo ma oggi si chiama inferenza che è quello del calcolo quindi della propagazione degli input in un output quindi nel far funzionare questo questo schermino, questo circuitino in cui dato F1 ed F2 devo farne la media pesata, darla in pasto a questa unità qui e questa unità decide se l'uscita è 0 oppure non è 0. Però è esattamente la stessa formulazione che abbiamo fatto, fermo restando che queste unità rosse non sono singoli neuroni, nel nostro mondo sono sottopopolazioni. Non è un grosso problema, a parte perché nel cervello ci sono miliardi e miliardi di neuroni e quindi potrebbe essere verosimile che le proprietà computazionali tipo percettrone siano non legate a un unico neurone, ma siano legate a una sottopopolazione di neuroni, e di fatto quello che viene fuori da qui, che è una caratteristica di rappresentazione, rappresentabilità dell'informazione e anche di possibilità di classificazione, questo alla fine sta facendo una classificazione sulla base di una proprietà lineare, di separabilità lineare discende fondamentalmente alla fine soltanto da questa sovrapposizione che alla fine è la conservazione della carica. Sto cercando di mettere in bocca a Rosenblatt, a McCalloch e a Piz come alla fine le avevano parole di biofisica, parole di neurobiologia alla fine uno era psicologo e l'altro non ricordo che cosa fosse ma erano entrambi fortemente motivati dall'aspetto neurobiologico. Vi rammento che questo concetto in cui la somma degli input che questa unità ha e questa unità decide se sparare oppure no, quindi con questa curva frequenza corrente, ha a che fare con un piano, il piano F1 ed F2 che ho disegnato qua. In generale f1 e f2 potrebbero essere tutte e due nulli, o tutte e due a una frequenza massima, o uno dei due nullo e l'altro a frequenza massima, o viceversa. Al di là del fatto che potrebbero essere variabili analogiche, potrebbero non essere tutto o niente, come sto in effetti qui con questa funzione di trasferimento immaginato. Qui è talmente ripida questa sigmoide, satura praticamente subito, e la pendenza di questa curva è così ripida che praticamente è una popolazione che risponde in modo binario, o tutto o niente. E voi sapete che se è tutto o niente, questa equazione qui, in particolare W1F1 per W2F2 uguale a Y0, Yθ, scusate, che è la condizione per essere sopra o sotto, è la condizione per essere alla soglia. In questo spazio F1F2 è una retta, è una retta perché le funzioni, scusate, le variabili indipendenti sono F1 la variabile indipendente, F2 la variabile indipendente, Questa è la x e questa è la y, è l'equazione di una retta perché c'è il termine noto e il termine noto è dato dal valore della corrente θ in cui io dico che voglio capire qual è il luogo dei punti che ha F1 ed F2 stanno su questa retta. Si chiama termine noto perché questa soglia di eccitabilità è nota. e si può fare di più, non è soltanto l'equazione di un luogo di punti che stanno esattamente, che rendono i sinaptico uguale a i teta, ma posso anche chiedermi qual è il luogo dei punti per cui il sinaptico è stoppa i teta o sotto i teta, e graficamente questo è semplice, vuol dire che sta stoppa questa retta o sta sotto questa retta. E qui con il fatto di aver messo, per esempio, in meretto alcune di queste combinazioni, combinazioni di input, e avendo scritto qui questa retta data dai valori di W1, W1 e W2, che sono fissati e con i quali io posso determinare la pendenza. Se potessi cambiarle, cambierei la dipendenza. Nel gergo neurobiologico quelli sono pesi sinaptici, sono efficacia sinaptica che presumibilmente cambia con la plasticità sinaptica. Quindi la biologia in effetti ha ispirato il fatto che la slope di questa curva può cambiare e può quindi separare il piano in due porzioni e risolvere un problema di classificazione. Spero che sia una roba banale, detta in un modo appesantito da nozioni di neurobiologia, ma per farvi vedere che c'è un link diretto con parte delle basi, delle fondamenta del machine learning odierno. La cosa diversa è che adesso non utilizzeremo più, e che qui ho considerato un'espressione istantanea. Invece no, la corrente non risponde, la corrente sinaptica impiega un po' di tempo a cambiare, Tutto dovuto a questa latenza, a questa inerzia data da quella beta, da quella cinetica di dissociazione, di spegnimento dei recettori sinaptici. Non sono istantanei, possono essere anche molto veloci, ma non sono istantanei. Un'altra cosa che non è, e lo vedremo probabilmente domani, che sarà l'ultima lezione, è che anche la descrizione frequenza in uscita e corrente in ingresso, scritta così, fatta così, che è una relazione istantanea, potrebbe non essere adeguata, potrebbe non essere vera. E qui il percitrone riesce con questi due elementi, la sommazione degli effetti e il fatto che esiste una curva a frequenza corrente che ha una reo base, una soglia, riesce a diventare un classificatore. Da qui sapete tutta la questione per cui sì, ma qui non può classificare una configurazione di pattern che non sia linearmente separabile, quindi il problema dello XOR, dell'OR esclusivo, e quindi tutto il campo è una schifezza, il primo inverno dell'intelligenza artificiale, poi negli anni 80 c'è stato un ritorno. Alla fine, sì, questo è solamente un percettrone, ma esistono i multilayer perceptroni, neanche nel cervello le popolazioni non sono, non c'è un'unica popolazione, c'è una gerarchia di popolazioni, vedete il deep learning, deep networks e tutto quello che ne discende. Questa caratterizzazione, tornando alla biologia, in blob non è una novità, non è una cosa particolarmente originale. Già dagli anni 90, per la descrizione dell'attività dei neuroni della corteccia visiva, in questo caso, dei ricercatori come Douglas e Martin, avevano in qualche modo ancorpato neuroni che avessero proprietà omogenee, intrinseche e sinaptiche. Qui addirittura le chiamano, questa è la popolazione dello strato 2-3 della corteccia, questa è la popolazione dei neuroni inibitori di tutta la corteccia, questi sono neuroni piramidali dello strato 5 e 6. Quindi se volete, come se in questo blob e in questo blob ci fossero due sottopoporazioni di neuroni tutti eccitatori, in quest'altro blob ci fossero una sottopoporazione di neuroni tutti inibitori e in questo caso io li ho distinti in due ulteriori sottopoporazioni di eccitatori perché layer 2, 3 e layer 5, 6, quindi diversi strati, hanno un input distinto e quindi io dico, se tu hai una qualche configurazione, una qualche topologia sinaptica diversa, non ti preoccupare, non ti accorpo, non dico che sei omogeneo a tutti gli altri neuroni, riesco a ragionare mettendoti da parte. Adesso questa è una cosa più complicata di quella che noi esamineremo. Dovrebbe essere sufficiente per voi pensare che in un caso semplice io possa perlomeno pensare che ci siano tutti i neuroni, da una parte quelli citatori e da un'altra parte quelli inibitori. Con questo metodo, con questa notazione grafica, Sto di nuovo pensando a un blob che contiene quanti neuroni volete, i citatori, e sono tutti omogenei dal punto di vista delle proprietà intrinseche e anche dal fatto che quando loro emettono una afferenza sinaptica, sputacchiano glutammato. Quindi non li posso accorpare con altri neuroni che, al di là del fatto che potrebbero avere una curva frequenza corrente con una pendenza diversa, potrebbero avere una capacità diversa perché hanno una superficie più piccola, hanno che quando sparano, rilasciano glutammato. Per tutti questi motivi il modello più semplice di modulo corticale è quello di avere una popolazione di neuroni eccitatori, un blob e una popolazione di neuroni inibitori, un altro blob. tutte le possibili connessioni sono quelle in cui un neurone eccitatorio generico proietta non necessariamente a se stesso ma proietta ad altri neuroni dello stesso tipo quindi un neurone dello strato 5 un neurone piramidale ne abbiamo parlato l'anno scorso quando vi facevo vedere che nel caso della depressione sinaptica un neurone piramidale ha una probabilità del 10% di andare a che va a proiettare a stabilire una sinapsi con un altro neurone piramidale, però sempre della stessa sottopopolazione si tratta, e quindi in questa notazione un neurone generico qui riceve una frequenza di input dovuta a una popolazione presinaptica che è esattamente la popolazione stessa. Quindi qui c'è qualcosa di interessante in cui curva frequenta corrente e quell'equazione della descrizione della dinamica del campo medio sono in qualche modo accoppiate una all'altra in modo ricorrente perché le connessioni sono statisticamente ricorrenti. Visto che è una descrizione statistica, qui è diventato che la popolazione degli eccitatori si auto-eccita. Inoltre la popolazione degli eccitatori proietta eccitando la popolazione degli inibitori, quest'ultima proietta inibendo la popolazione degli eccitatori E quello che vedete che qui manca, e manca per semplicità, ma dovrebbe essere incluso, qui invece c'era che i GABA cells hanno anche una autoinibizione, e che la popolazione dei inibitori non ha questa connessione ricorrente a se stessa. Chiudo questo punto e facciamo una pausa. Quindi, se voglio scrivere il campo medio che un neurone di questa popolazione, questi campi medi saranno due, io devo pensare a quello che è la corrente totale sinattica che prende un neurone qui, che riceve un neurone qui in questa popolazione, e la stessa che riceve un altro neurone in quest'altra popolazione. Non lo faccio per più neuroni nella stessa popolazione perché la media è la stessa. Sì, le fluttuazioni saranno diverse se considero quello o quell'altro neurone, ma in media sperimenteranno lo stesso campo, campo medio. L'equazione è esattamente quella di prima. Sono stato più specifico nel dire che questa è la corrente sinaptica, E, quindi che un neurone della popolazione E sperimenta, nel membro di destra o meno beta E, perché immagino che se sono sinapsi glutamatergiche saranno recettori AMPO e NMDA, e quindi questa meta sarà l'inverso di 5 millisecondi, di 10 millisecondi, potrebbe essere diverso da quello invece della popolazione GABA, per cui i recettori GABA sono diversi. Scusate, non della corrente sinattica GABAergica. E qui ho due termini, uno col più e uno col meno, oltre ad avere un ulteriore termine che chiamo input esterno. Qui potrei essere io, che con metodi di optogenetica o di chemogenetica o di quello che è, ho un input sensoriale esterno, in più aggiungo un termine sinaptico che va a sommarsi al termine sinaptico totale. E vedete che qui c'è N, C, W, F, esattamente come prima, però sono due, perché se io mi siedo qui, e anche qui è come un giochino, come quello degli schemi cinetici marcoviani, io qui vedo entrare due freccette. Vedo entrare questa in alto e per convenzione il triangolino vuol dire che le sinapsi sono eccitatorie, la pallina, qui ovviamente non si vede nulla, questa pallina vuol dire che le sinapsi sono inibitorie. Potreste vederlo come se fosse un semaforo, uno verde, uno rosso, ma non importa. Quindi un neurone qui riceve input eccitatori da questa sinapsi, da questi bottoni sinaptici. Non è più un bottone, qui è un gran casino medio però, che io considero solo l'effetto medio, e anche un input dovuto a quest'altra popolazione di bottoni sinaptici. Quindi in un caso ho questa corrente sinaptica media che dipende da qual è la numerosità di neuroni presinaptici. Questi neuroni presinaptici, da dove vengono questa corrente sinaptica? Ok, viene esattamente dalla popolazione stessa, quindi NE, che è la numerosità di questa popolazione. CEE è la probabilità di connessione ricorrente della popolazione eccitatoria con loro stessi, con se stessi, WEE è l'efficacia sinaptica media della popolazione eccitatoria nelle sinapsi con se stessa e FE è la frequenza media a cui questa popolazione sta sparando. Ripeto, me ne accorgo perché io seguo questa curva, qui vedo il bottone sinaptico, vedo che è eccitatore e quindi avrà il più. Di nuovo, ho tolto già da tempo il contributo dovuto al potenziale di inversione dei recettori sinaptici a cui le specie ioniche sono sensibili. Qui abbiamo già deciso che le sinapsi non sono più conductance based ma sono current based, sono basate sulla corrente. E il termine di driving force, che vi ricordate era E-V, E-V, è costante, perché ho sostituito V, V medio. Per Yampa questo V medio tipicamente è sotto il potenziale di inversione di NERST, che è 0 millivolt per quelle sinapsi, per Yampa e NMDA. Per GABA il potenziale medio è sempre sopra invece il potenziale del GABA, che è attorno a meno 60-65. Quindi quel termine lì in un caso è positivo, qui alla fine non l'ho nemmeno messo, l'ho accorpato dentro questo W, mentre per le correnti gavergiche è negativo ed è per questo che qui compare un meno. Quindi ripeto, sono un neurone generico qui e vedo che ho un bottone sinaptico che entra qua e ne ho un altro che entra qua. ok, non è un bottone, è una popolazione di bottoni, vedo che questo è eccitatorio e quindi lo seguo, quindi avrà il più, lo seguo, vedo che l'efficacia sinaptica è WEE, ok, ne prendo atto, e vedo che parte in effetti dalla stessa popolazione in cui mi trovo io. quindi numerosità probabilità di connessione e sinaptica media sono quelle che sono sono date dipendono dall'anatomia, dalla struttura topologica ma la frequenza, la cosa importante è che questa frequenza è la frequenza di questa popolazione qui di cui io appartengo poi però vedo che non è l'unico input, ce n'è un altro che è questo EXT e lo metto qua è dato, non è dovuto a nessuna feed forward ed è dato invece vedo che questo qua viene fuori da una popolazione I inibitoria e quindi avrà una certa numerosità NI, quindi quanti neuroni sono qui dentro, quante afferenze in totale sono lì dentro, qual è la probabilità di connessione dalla popolazione I alla popolazione E, qual è l'efficacia sinaptica media dalla popolazione I alla popolazione E e qual è la frequenza presinaptica. E in questo caso la frequenza presinaptica è questa frequenza della popolazione I, e quindi qui scrivo F con I. Potete immaginare che questo è soltanto uno dei due termini che devo scrivere, perché avrò un neurone generico, può essere qui, ma può essere anche qui, in quell'altra popolazione. E in quell'altra popolazione avrò un'altra corrente media, che ho chiamato I sinaptica I, fra un po' ci togliamo dalle scatole questo I sinaptico, lo chiameremo H, per onore ai fisici del campo magnetico che chiamavano H, H-E e H-I. Questo nel secondo membro ha una beta che, di nuovo, dipende dalla costante di tempo di altri recettori. E vedete che in questa popolazione qui c'è solo un input che sta arrivando. Lo seguo, è un input eccitatorio perché viene dalla popolazione degli eccitatori, Lo seguo a ritroso e mi accorgo che c'è un'efficacia sinaptica media W dalla popolazione E alla popolazione I. Questa notazione IE e I è scambiata. Infatti vedete che questo è EI perché vuol dire che vada I ad E, mentre qui IE vuol dire che vada E a I. E se vado a ritroso e vedo da chi parte, vedo che devo mettere qui la numerosità della popolazione citatoria. la probabilità di connessione di questo ramo, di questa proiezione, CIE, l'efficacia sinaptica media di quel ramo, WIE, e la frequenza presinaptica è quella di questi neuroni che stanno... ...è sparito il puntatore per un ritardo... apparentemente così complessa che potrebbe richiedere una simulazione complicata, numerica, da cui per esempio scelta dei parametri o esplorazione di quelli che sono tutti i regimi di questa... Che cosa fa una popolazione di errori? Solo eccitatori o eccitatori inibitori? Per il momento non è possibile comprenderlo se non facendo una simulazione numerica e passando anni, come è stato per un sacco di tempo, cambiando i parametri per vedere, ah guarda, con questo set di parametri in cui ho reso le connessioni fra i neuroni eccitatori e quelli fra i citatori e i inibitori, deboli oppure no forti, uno il doppio dell'altro, vedo che questa rete è uscita, oppure no, guarda, questa rete ha dei punti di equilibrio. Qui, semplicemente in un modo, con una trattazione che vedete, è di una banalità sconvolgente, banalità matematica di una semplicità sconvolgente, qui avete due equazioni differenziali e due termini che vi dicono come ottengo FE da IE. E come ottengo FI da I sinattico I. Quindi ho fondamentalmente due questioni differenziali e due sigmoidi, due funzioni threshold linear. E vedrete fra un attimo, nell'ora successiva, dopo una pausa di dieci minuti, che cosa possiamo capire, capire senza dover fare una simulazione numerica e aspettare mezz'ora per vedere il risultato e poi dici, aspetta, prova a cambiare questo numero, vediamo un'altra mezz'ora di simulazione, oppure qualcosa che non è alla portata di un gruppo di ricerca, di uno studente, se non ha un supercalcolatore a portata di mano. Mi fermo per dieci minuti. Perdonate il casino tecnico, non è granché. Allora, riprendendo, queste sono le due equazioni differenziali in un caso relativamente semplice, ma altrimenti complicato dal punto di vista microscopico, e queste sono le formule che mi dicono come mappare corrente in frequenza per ciascuna delle due popolazioni. Per esempio, in questo caso posso pensare che i neuroni abbiano la stessa turma di frequenza corrente, Ma ovviamente devo gestirla in modo diverso, perché la corrente che un neurone eccitatorio sperimenta, in media, contribuisce al firing rate della popolazione eccitatoria, mentre la corrente sinaptica totale che sperimenta un neurone generico nella popolazione di inibitori contribuisce soltanto alla frequenza di sparo di quella popolazione. Qui ovviamente non si vede nulla, ma avete le slide. Qui è l'equazione differenziale di due o tre slide fa, di due o tre diapositive fa, in cui per semplicità, anziché chiamarlo valore medio, sì, comprendo che è il campo medio, che quindi è una descrizione approssimata, generica, di popolazione, uso come notazione quella di semplicemente il simbolo H. Magari sarà H, E, H, I, se ho due popolazioni E eccitatorie e I inibitoria. Se ho due popolazioni eccitatorie, E1 ed E2, ci saranno due equazioni differenziali, una che viene, diciamo, la cui soluzione è la variabile H, E1 e l'altra è H, E2. Qui ho scritto come tau quella che qui era rimasta indicata come beta, l'avevo lasciata indicata come beta esattamente per dirvi come discendeva dallo schema cinetico a due stati. Qui semplicemente ho diviso angoli membri per beta e a sinistra uno su beta l'ho identificato come ho fatto altre volte come tau, anche come fatto nella lezione online. anziché portarmi dietro N, C, W, con questo cambio di variabile, è semplicemente che sto dando un altro nome per semplicità, perché mi sono stancato di dover scrivere ogni volta N, C, tanto questo N, questo C e questo W, come pure F, dipendono dall'identità della popolazione presinaptica che sta sparando e contribuendo a questo campo di corrente sinaptica media. Quindi il fatto, se prima dicevo che era NE oppure CEE o CIE eccetera eccetera, se io questa quantità, a parte il beta che ho aggiunto, la chiamo J, perché storicamente nel caso dell'elettromagnetismo dei vetri di spine e dei spin magnetici, per motivi storici H è il campo magnetico che un elemento sperimenta, e l'accoppiamento fra due spin vicini. Quindi i fisici che hanno per primi applicato queste cose di meccanica statistica alle neuroscienze, alle neuroscienze computazionali, alla fine si sono portati dietro la stessa notazione. E onestamente scritta così è semplice, a parte essere la solita equazione differenziale lineare a coefficienti costanti, eccetera. L'unica cosa che vedete qui è che ho lasciato indicato E, mentre qui la chiamavo F, FE per esempio. Qui ho indicato come E la frequenza della popolazione a cui sto facendo riferimento. Quindi E, questa è la curva frequenza corrente, sarà di nuovo una funzione di quella che prima la chiamavo I sinaptica e adesso chiamo H. Quindi queste sono le due equazioni, i due termini su cui andiamo a giocare. vedrete tra un attimo la potenza di questo discorso il primo caso è il più semplice e considero in questa condizione di finding rate un unico blog una popolazione omogenea di neuroni eccitatori connessi in modo ricorrente ripeto, è il solito giochino quindi ho un'unica frequenza di sparo la frequenza della popolazione degli eccitatori che chiamo E prima l'avevo chiamata FE Quindi per semplicità la chiamo E. Quindi posso scrivere la corrente H, H E se volete, ma qui è solo questa, quindi la chiamerò H. Il termine, i contributi che la corrente media sperimenta. E di nuovo, vado a vedere questa popolazione, vedo che c'è un bottone presinaptico, una popolazione di bottoni presinaptici. Vedo che l'efficacia è J. J contiene anche N e C, oltre a questo W, oltre ad avere anche beta di mezzo. Quindi lo seguo e vedo che parte dalla stessa popolazione dove mi trovo. Quindi in modo molto semplice, adesso addirittura non scrivo più dH su dt, scrivo H punto. Quindi la notazione credo sia di Leibniz anziché di Newton, sempre la derivata vuol dire, sempre la derivata rispetto al tempo. Tau H punto uguale a meno H, questa è sempre la stessa storia, dovuta alla dissociazione del neurotrasmeditore e della chiusura dei recettori sinaptici. E in questa parte ho tutti i termini che contribuiscono, ho questo termine I-ext e l'ho messo tale quale, e questo su cui ho appena ragionato, che è più J per la frequenza della popolazione citatoria E. Quindi l'analisi di una popolazione di neuroni connessi in modo ricorrente, presumibilmente faranno qualcosa di interessante, adesso vediamo cosa, la posso scrivere con un'unica equazione differenziale molto molto semplice e la complemento con questa, che semplicemente la scrivo matematicamente un pochino meglio, e adesso dico che mi basta che sia una funzione di trasferimento threshold linear, Con questa notazione delle parentesi quadre col più, forse l'avete visto in altri corsi, forse no, si intende la parte positiva, vuol dire che questo parentesi quadra col più è uguale al contenuto delle parentesi quadre quanto il contenuto è positivo, altrimenti è zero, altrimenti clippa, si dice. Cioè quando il contenuto di questa parentesi è negativo, l'uscita è zero. Cioè prende solo la parte positiva, forse dovrei dire non negativa. comunque normalmente viene chiamata, viene detta parte positiva. E questa parte positiva è chiaramente una funzione di H, della corrente sinaptica, cioè, e scritta così, alfa è un coefficiente che mi dice la pendenza di questa retta, alfa per H è, quindi il termine della retta, alfa è il coefficiente angolare, meno teta è il termine noto, però se lo scrivete così si vede istantaneamente, occhio che quando h è minore di θ, questa parte qui è nulla, e quindi la funzione di trasferimento è zero. Quindi scritta così, soltanto quando h è maggiore di θ, e θ è un valore che ho introdotto per descrivere quando la curva inizia a crescere, quindi h deve essere sufficientemente intenso, altrimenti l'attività resta sotto soglia. Sto usando tutte le parole che abbiamo visto sia nella descrizione quantitativa di neuroni con duct and space, sia integra e spara e sia anche neuroni veri. Quello che potreste lamentare è che non ho saturazione qui, questo è qualcosa che cresce sempre. Non ho, se volete, sto ignorando in questo caso, il termine dovuto alla refertarità assoluta e anche ovviamente all'adattamento sinaptico, scusate, anche l'adattamento sinaptico, l'adattamento frequenza dipendente che per il momento non lo prendo in considerazione. La guardo un po' meglio e mi accorgo che è un'equazione in effetti differenziale non lineare perché qui dentro E io ho H, però H è all'interno di una funzione non lineare, questa funzione di H è una funzione che ha una non linearità, non è una retta, è una retta clippata, qui quello che è sotto teta è stato... c'è un'ipotesi su qual è il regime in cui mi trovo, H può essere sotto o può essere sopra. Posso fare alcune di queste ipotesi, è la stessa che è una cosa molto simile a quella che facevo quando studiavo lo steady state, dicevo, se c'è lo steady state, i termini di derivata temporale vanno a zero, mi chiedo quali sono le conseguenze, poi queste conseguenze sono consistenti con questo steady state, alla fine la risposta era sempre sì, perché andavo a trovare una soluzione dell'equazione differenziale che era costante. Se era costante, allora era consistente con l'ipotesi che avevo fatto. Comunque, non la faccio tanto complicata. Mi chiedo la cosa più semplice che posso chiedermi. Ok, questo è un sistema dinamico. Cambia, lo posso simulare. Per simularlo è uno scherzo, nel senso che numericamente è estremamente semplice rispetto anche all'integra spara esponenziale che vi ho detto che dovete prestare attenzione perché la salita è così rapida. per cui sì le quantità variano nel tempo ma non ci sono spike non ci sono dei dirac c'è solamente un'equazione differenziale e quindi la prima analisi che mi chiedo è esistono il sistema dinamico esistono dei punti di equilibrio esistono delle configurazioni di attività per cui se la rete raggiunge quell'attività si pianta lì qualunque cosa faccia qualunque cosa faccia per esempio la corrente esterna o that's it, alla fine è solo la corrente esterna e vi faccio vedere tre casi che sono molto interessanti e permettono con questi modelli di fine rate di averne una compressione molto profonda la prima è diciamo in effetti il primo esempio che faremo è quello dei punti di equilibrio sto cioè pensando che una rete di neuroni col fatto che ci sia un'attività ricorrente proprio come aveva ipotizzato Donald Hebb e come visto in esperimenti di elettrofisiologia in cui una scimmia, un animale o un uomo a questo animale viene presentato uno stimolo e anche dopo averlo rimosso lo stimolo l'attività in alcune parti della corteccia continua a persistere la presenta attività persistente quindi è possibile, è probabile che la dinamica proprio come la dinamica del moto di una pallina su un profilo, questo è una specie di profilo di potenziale, potenziale gravitazionale in questo caso, possa avere dei punti, delle configurazioni, delle posizioni in cui se io metto la pallina lì, la pallina resta. Se la metto qui dove è indicato qui, la pallina resta. E seppure la metto alla fine, al fondo di queste due valli, resta. Allora uno potrebbe chiedersi, ok, il passo successivo sarebbe dire, ok, ci sono dei punti di equilibrio, tre, sono tutti stabili, ci sono alcuni che sono instabili. Che cosa vuol dire stabilità o instabilità nel caso di una popolazione di neuroni? Cosa vuol dire un equilibrio? Un equilibrio non è così complicato da capire, perché vuol dire che se la rete raggiunge la frequenza di 12 spike al secondo, continua nel tempo a fare 12 spike al secondo, a persistere in quell'attività. Equilibrio stabile o instabile vuol dire che forse per una qualche fluttuazione, semplicemente perché il sistema è a temperatura corporea, oppure perché c'è un qualche distrattore, per caso questi 12 spike al secondo vengono cordati. L'attività invece cambia e ritorna verso un altro punto di equilibrio che è un'attività per esempio di uno spike al secondo, come se ci fosse un equilibrio a una frequenza elevata e un equilibrio a una frequenza bassa. Sto cercando di far venire in mente qualcuno di voi, se ha questa dimensienza, all'uso del termine up and down stage che ho usato qualche settimana fa. Questa cosa dell'esistenza di punti di equilibrio è solamente uno dei tre fenomeni che vi presento. Un altro è che la rete può diventare un sistema in grado di rispondere a un input, alla fine è un sistema dinamico, un ingegnere se lo immagina come una scatola nera, in cui presumibilmente ha un ingresso, questa corrente esterna, e potrebbe avere un'uscita. Cosa vuol dire reaction times? Vuol dire che sta filtrando, vuol dire che se cambio qualcosa, nella connettività, perché alla fine quello che posso fare qui è cambiare J, non ho granché sì potrei cambiare le proprietà intrinseche del neurone ma J, visto che J è probabilmente soggetto a plasticità sinaptica, mi fa pensare che se io imparo qualcosa se mi espongo a dell'attività questa attività può avere un cambiamento strutturale della mia rete oppure qualcosa che ha a che fare con una relazione ingresso-uscita questo è l'ingresso, l'uscita sarà il finding rate è di questa popolazione. Terzo, che è molto legato al secondo punto, l'amplificazione, cioè il fatto di poter amplificare come i transistori fanno, come gli amplificatori operazionali fanno, un segnale esterno. Quindi sotto quali condizioni una rete di neuroni eccitatori omogenei connessi in modo ricorrente, non vuol dire che tutti hanno una connessione ricorrente, ma è una statistica, infatti abbiamo applicato un operatore di valore atteso, quindi anche se quelle che la settimana scorsa vi avevo chiamato come Cij, ed erano O01 secondo se il neurone J era collegato, proiettava il neurone I, se anche non fossero tutti uni o tutti zeri, statisticamente vuol dire che una porzione delle connessioni sono ricorrenti, Il target è quello di o non connettere a nessuno o riconnettere a un neurone della stessa popolazione. E per farlo, per esempio, parto dall'amplificazione. Una menzione che volevo fare sull'amplificazione e sulla velocità di risposta. Può essere che qualcuno di voi che ha nella mente qualcosa di qualche cello di elettronica sa che gli amplificatori hanno a che fare con un trade off, un compromesso. Quanto più amplificate i suoni del vostro telefono, del vostro stereo, al caso, quello che è, tanto più avete una probabile compromissione su alcune frequenze. Il sistema non è capace più a rispondere allo stesso modo per tutte le frequenze. Frequenze sonore. Qui frequenze cosa vuol dire? frequenze, frequenze, frequenze spettrale di potenza di alcune componenti dei segnali in gioco, quindi diventa una specie di filtro. Lo stesso concetto che poi alla fine è quello del feedback positivo, gli amplificatori operazionali per chi li ha fatti hanno un filo che collega l'uscita a uno dei due ingressi, esattamente come questa popolazione che ha un filo medio, un bundle di fibre che connettono, creano un feedback positivo. È positivo perché la popolazione di non-eccitatori, quando loro sparano, chiunque riceve il loro astone, si eccita perché è glutamato che viene rilasciato. Quindi alla fine è qualcosa di molto simile, forse con esperienze che avete già. Faccio l'ipotesi di trovarmi come campo medio sopra la soglia richiesta per attivare la popolazione. Lo faccio perché se h è maggiore di teta, posso togliere questa parentesi quadra che mi dà fastidio perché non la so gestire matematicamente tanto bene, non posso scorporarla, è una funzione. Quando h è maggiore di teta, questa funzione collassa, diventa una retta, diventa un'equazione lineare. Quindi, anziché e, io qui nel secondo membro scrivo alfa moltiplicato h meno teta. Lo voglio fare perché sono intenzionato a fattorizzare h. Vedete, h compare qui e poi compare qui, ma prima compariva dentro una funzione non lineare. Con questa ipotesi, h maggiore di teta, che vuol dire tutti i neuroni di questa rete sono sopra soglia, allora posso scrivere questa equazione e posso banalmente fattorizzare h. E quindi a sinistra resta sempre tau h punto uguale. A destra, con il meno, vedete che qui c'era il meno qua, che c'è il più qui, è un feedback positivo alla fine delle fini, quindi non mi sorprende che ci sia un più. Voi sapete che io sono particolarmente sensibile se la variabile di stato di una solita equazione differenziale a coefficienti costanti, lineare, adesso senza il termine di lineare a tratti, di threshold linear, della parte positiva è diventata la solita equazione noiosissima. E qui devo fattorizzarla perché inizio a non sentirmi più a mio agio, fattorizzandola a 1 meno j per alfa. Qui c'è un segno meno, quindi un pochino sono a mio agio o non a mio agio, perché sapete che l'equazione dell'omogenea associata mette all'esponente dell'esponenziale, che è la soluzione, mette il termine che premoltiplica la variabile di stato qui nel secondo membro. L'ho fatto più volte per cercare di farlo e trarre nella testa, in modo drammatico, comico, tragicomico, dicendo se questa cosa qua è un termine che non è negativo, mi stresso perché vuol dire che ci sono esponenziali positivi e come è possibile che ci siano esponenziali positivi, non c'è nulla che amplifica, è un sistema dissipativo, alla fine è un sistema biologico con del metabolismo, non so perché le cose dovrebbero andare all'infinito, è un sistema reale. Qui vedete che sono leggerissimamente contento, ma resto preoccupato, perché sì, c'è qui un segno meno, ma questa quantità qua non è sempre positiva. Potrebbe diventare negativa, in particolare se J, che ha significato di efficacia sinaptica, dovesse per esempio particolarmente potenziarsi durante un esperimento di potenziamento sinaptico, io che studio intensamente per questo corso per prepararmi, Potrebbe in teoria essere tale se diventa maggiore di 1 su alfa, 1 meno j per alfa, questa quantità diventa automaticamente negativa. E quindi cancella questo segno meno. E quindi qui l'esponenzione inizia a essere un'esplosione. E cosa vuol dire? Che mi viene una crisi epilettica? Sì, qui prevederebbe una crisi epilettica. Non sto dicendo che se voi studiate questo corso avete una crisi epilettica, Sto dicendo che se l'efficacia sinattica eccitatoria, visto che ci sono connessioni ricorrenti, dovesse aumentare la dismisura, è chiaro che, viste le connessioni ricorrenti, la rete potrebbe andare in uno stato che si chiama run away excitation, che intuitivamente ha senso. Qui ha senso matematicamente. Matematicamente è in un'equazione che è la solita equazione del più semplice di così non si può. Quindi, mentre prima restava una storiella, adesso qui la vedo e in teoria posso dire, posso capire qual è il punto critico 1-Jα. Quando è che questa quantità inizia a diventare negativa? Quando è che si annulla? E J, adesso ho un termine di paragone, perché so che è questo α. α è un parametro che ho messo così per quantificare la pendenza della curva a frequenza corrente. Ma potrei guardare i neuroni sperimentalmente, vi ho fatto vedere che la curva a frequenza corrente è una cosa che si fa, è una steve di dosette, è una cosa che si fa sempre. Potrei cioè rendervi conto che se i neuroni hanno una curva di frequenza corrente parecchio ripida, potrebbe essere che, se per caso questa curva di frequenza corrente fosse legata a una condizione genetica di espressione di una predisposizione all'epilessia, potrebbe essere per quello che un qualunque cambiamento dell'efficacia sinaptica, viste le connessioni ricorrenti eccitatorie della corteccia, sono attorno al 70% in corteccia le connessioni ricorrenti, quindi sono predominanti. e sono 80% i neuroni eccitatori in corteccia. Quindi non è chiaro, io qui sto ignorando l'inibizione, però non è uno scenario così drammatico. Questa formulazione con l'atelier di Campomedio e questi blog mi permettono semplicemente, non ho fatto altro che fare un passaggio, di estrarre già un sacco di informazione. Comunque qui si parlava di amplificazione. Per l'amplificazione voglio comunque studiare lo steady state, oppure no, non studio lo steady state, perdono, non studio lo steady state. Riscrivo questo termine qui, perché in effetti l'amplificazione è qua. Quindi questo j per alfa ha premoltiplicato h, ma anche moltiplicato questo teta, diventando un termine composto, ixt meno j alfa diviso teta. Ok, però scusate, è sempre questo che la fa da padrone. La fa da padrone perché se io mettendo H a 0, quindi cercando di studiare lo steady state, posso in qualche modo caratterizzare H infinito, come per la cinetica dei canali voltaggio dipendenti, e anche ligando dipendenti avevo questa idea di trasformare tutte le equazioni in qualcosa che avesse a denominatore la scala temporale, E al numeratore qui un termine che chiamavo quello che sarebbe stato lo steady state. E vi avevo detto, questo l'anno scorso, che da praticoni potevate pensare che quando avevate un'equazione differenziale del genere, se H infinito è una quantità che varia molto lentamente, alla fine H insegue a H infinito, anche se H infinito non è stazionario, ma cambia nel tempo. Se invece H infinito varia più rapidamente e H lo insegue ma ha un comportamento filtrato, più lento, molto smooth, molto liscio, low past, filtrato che tende a smorzare i cambiamenti. Grazie, questa è l'equazione di un passo a basso. Se guardo H infinito adesso, è semplicemente il valore che si ottiene mettendo questo primo membro a zero e esplicitando per h, vedo che al denominatore ho 1 meno j per alfa, la quantità che abbiamo commentato pochi minuti fa. L'avevo commentata perché mi preoccupava che fosse legata all'esponente dell'esponente. Ma semplicemente qui per un input costante, se l'input fosse esterno, fosse costante, h infinito sarebbe il campo medio conseguente e la frequenza di uscita sarebbe una funzione di questo h infinito. Sarebbe α per h infinito meno θ. Vabbè, ok, io ho tolto una quantità e l'ho scalato. Però guardate cosa succede quando cambia j al denominatore. Questa quantità, 1 meno jα, anche se j non diventa enorme e genera una crisi epilettica, rendendo questa equazione un'equazione instabile, un'equazione alla cui soluzione non è stabile, che va all'infinito, questo termine mi figura al numeratore comunque, e anche quando j, purché j sia non nullo, appena j inizia ad essere un pochino positivo, vedete che qui il numeratore, il denominatore è 1 meno qualcosa. Se voi dividete per qualcosa che è più piccolo di 1, vuol dire che lo state moltiplicando per qualcosa che è più grande di 1. L'inverso, 1 diviso 0,1 è 10. 1 diviso 0,0001 è 1 è 1000 o 10.000. quindi se cambiate il guadagno di retroazione avete che H infinito ha un termine di scala visto che questo è il denominatore e pesa come un numero piccolo un guadagno sempre più grande avete creato un amplificatore biologico quindi gratis, ho capito, senza nemmeno fare una simulazione che probabilmente una popolazione di neuroni eccitatori a meno che non subentrino altre cose, fatica eccetera se l'input esterno è costante altrimenti sarebbe un pochino più complicato a ragionarci ma avrebbe lo stesso effetto al variare DJ quindi per esempio dovuto a classicità sinaptica quel parete si comporta come un amplificatore gli ingegneri elettronici nella stanza non dovrebbero essere particolarmente stupiti perché direbbero noi l'abbiamo inventato nel secolo scorso gli amplificatori a retroazione, tutti gli amplificatori operazionali hanno questa cosa qua. Ok, la biologia l'ha inventato molti milioni di anni prima. La cosa che notate anche, ed è l'aspetto duale, e non potete farne a meno, è che la costante di tempo qui, la scala temporale su cui questa amplificazione avviene, su cui questo inseguimento H, H infinito avviene, H infinito ok, ve lo amplifico tanto quanto più J è positivo, non troppo perché sennò l'equazione esplode, non segue più. Quindi la soluzione di questa equazione differenziale è un termine legato all'omogenea associata che è transitoria e sparisce subito. E poi resta l'integrale particolare. A meno che J non sia troppo grande, allora la soluzione dell'omogenea associata è un'esponenziale che diverge e quindi avete finito, quale che sia l'integrale particolare conta questa cosa che esplode. Ma in condizioni normali, chiamiamole fisiologiche, questo tau H, scritto così, è tau, la costante di tempo che avreste avuto nel caso J fosse stato a zero, cioè senza questa retrazione, e vedete che purtroppo compare sempre al denominatore. Quindi la costante di tempo diventa tanto più grande quanto più è grande J ripeto il ragionamento J è al denominatore appena diventa non è più zero diventa leggermente positivo il denominatore 1 meno qualcosa che tende a essere sempre più grande vuol dire che diventa più piccolo 1 meno qualcosa è un numero più piccolo di 1 ma è al denominatore quindi vuol dire che tau H è sempre maggiore di tau cioè vuol dire che la costante di tempo è più lenta, maggiore, più grande vuol dire che impiega tanto tempo ad arrivare a regime, vuol dire che se questo lo considero un filtro, l'uscita H, se volete H oppure E, alla fine sono la stessa cosa, sopra soglia, dove io sto pensando di trovarmi, E o H è una risposta copia all'ingresso, amplificandolo, eccetera, ma in modo sempre più scarso, sempre più incapace di seguirne i cambiamenti specifici. se ho un sistema che mi permette nel sistema visivo di accorgermi, quindi di amplificare il segnale visivo del movimento della tigre che dovesse al solito entrare in quest'aula improvvisamente, se questo meccanismo fosse troppo, l'amplificazione fosse troppo elevata, potrei averne un meccanismo che ha anche una tigre piccola che si muove molto, ok, movimento lento, veloce quindi supponete che sia una tigre piccola oppure una tigre molto grande la tigre piccola la riuscire ad amplificare che avete una stupidaggine però ma se questa tigre fosse rapidissima a entrare io me la perderei perché avrei un tempo di reazione tau-h molto lento quindi questo è un trade-off notevole ripeto, il fascino di questa descrizione è che alla fine senza fare nulla non potete dirmi che questa cosa è complicata dal punto di vista matematico, avete sviluppato, avete inserito delle informazioni sulla funzione, sulla computazione di questo modulo. Quindi questo è il motivo dei primi due punti. Qui è una simulazione numerica stupidissima, di cui se volete vi do il codice, ma lo potete fare a occhi chiusi, in cui la corrente esterna è uno step, in cui in rosso, all'aumentare di J, vedete le risposte. Quindi più grande è J, tanto più queste risposte sono grandi. Queste risposte sono noiose alla fine, perché è una speciella, e il solito gli archi di esponenziale, notate fra l'altro che, no, ok, non vi dico il fatto che le costanti di tempo potrebbero essere diverse, non importa. Notate che quindi all'aumentare di i questa amplificazione addirittura forse non è nemmeno proporzionale, e infatti j compare al denominatore, quindi la dipendenza non è lineare, è inversa. E' una cosa che posso fare per dimostrarvi che all'inizio, quando la trasduzione era, all'inizio intendo a valori bassi di j, la trasduzione era scarsa, la amplificazione non era granché, qui non si vede, però le curve di salita, e anche di discesa, sono più rapide dell'ultima, con J molto grande, per cui sì, J è molto grande, la risposta è molto grande, però sembra una curva di carica che ci sta impiegando un sacco di tempo ad alzarsi. Se divido ognuna di queste tracce per il valore di picco, quindi lo normalizzo vedete che qua all'aumentare di J l'ampiezza non può cambiare più perché l'ho normalizzata quello che cambia diventa sempre più lento questa curva di carica impiega sempre più tempo per arrivare allo steady state se ci arriva del tutto all'aumentare di J quindi questa è la dimostrazione semplicemente simulando questa equazione differenziale di cosa fa questo sistema quando aumentate l'efficacia sinaptica La cosa più interessante viene ora, questo è un altro esempio in cui la corrente non è più costante o costante a tratti e va su e giù arbitrariamente, questa è la somma di due o tre sinusoi, se mi ricordo bene, per fare al volo, per fare qualcosa che facesse qualche, che cambiasse nel tempo. Ovviamente questa corrente esterna deve essere tale per cui H deve essere maggiore di teta. Se la corrente è bassa, ricordate che comunque è sempre un sistema a soglia, quindi la corrente più bassa non fa sparare neppure un neurone, quindi siete fuori da un regime. Quindi quando J-U, anche se non avete retroazione, retroazione positiva, se non avete feedback positivo, se non avete queste connessioni sinaptiche eccitatori ricorrenti, l'uscita non è una copia fedele dell'ingresso. se l'ingresso è raramente sopra una qualche soglia, la famosa aero base. Quando cambiate J e la fate diventare sempre più grande, occhio a farla diventare troppo grande, perché se la fate diventare troppo grande, diventa un'esponenziale che diverge e non vedreste più nulla, vedreste qui la soluzione anche numericamente, andrebbe immediatamente a 10 alla 9, 10 alla 10, e la risposta all'integrale particolare mi metterebbe trascurabile, non lo vedreste più. Oltre al programma numerico che si interromperebbe e vi direbbe, sono andato in overflow, non riesco più a rappresentare i numeri che mi dici di rappresentare perché ho finito la risoluzione a 64 bit. Vedete la definizione della rappresentabilità di numeri floating point a 64 bit, o 32 bit o 16 bit, è quello che è la vostra risoluzione, 64 è quella attuale dei processori attuali. Quindi questo scritto è infinito, qui si vede chiaramente che c'è una dipendenza dalla soglia, e alla fine è sempre la stessa cosa che vi ho detto prima, è al denominatore, questa J cambia l'amplificazione. C'è un caso intermedio fra la stabilità e l'amplificazione e la instabilità che voglio raccontarvi ed è forse, anche se attualmente non è l'ipotesi maggiormente in voga, che è quella del sistema oculomotorio. Quindi per spiegare un fenomeno del sistema oculomotorio in cui alcuni neuroni del brainstem codificano i comandi dei movimenti saccadici dell'occhio con dei burst. Ogni volta che l'occhio deve essere mosso si fa una saccade, ci sono dei neuroni che danno una schicca a un burst concentrato nel tempo. E ci sono altri neuroni downstream, a valle, che sparano in modo tonico codificando la posizione degli occhi. È importantissimo che quando io do un comando e il mio attuatore si muove, io da qualche parte abbia la misura dello stato. Se non fosse anche... Voi sapete che i sistemi ad anello aperto, per quanto belli, sono difficili da controllare perché non sappiamo esattamente descriverli bene, quindi è meglio se avete un sistema ad anello chiuso in cui avete un feedback. Quindi anche il sistema nervoso non fa eccezione, ha dei neuroni che sparano e la loro attività è come se contasse, integrasse i burst di questi neuroni del brainstem e ogni volta la frequenza cambia. Vedete che qui c'è addirittura un pochino di adattamento in frequenza, però al primo movimento, questa è la posizione degli occhi, quindi fa una prima saccade, poi passa qualche secondo, o millisecondo, secondo, poi fa un'altra saccade, l'occhio si sposta, poi si sposta di nuovo, e alcuni neuroni, sperimentalmente, vedete, fanno un cambiamento repentino e poi che si adattano, però dopo che c'è un ulteriore movimento, il finding rate, vedete che qui persiste a un valore che è più alto, e poi di nuovo qui ancora è ancora più alto, e poi qui per esempio se il movimento è andato in una direzione opposta, è come se fosse stato sottratto. Una roba del genere, concettualmente è semplice da immaginare, c'è una specie di condensatore, il condensatore è quindi un integratore puro, un integratore temporale che conta gli spike, ogni volta che ci sono top spike, lui semplicemente aumenta il potenziale capito di quel condensatore e tiene così in memoria del passato. potreste dire che un'integrazione perfetta con perdita non è possibile, però qui il concetto non è che questo avvenga a livello di singola cellula, e se per caso questa architettura di cui vi ho fatto vedere poco fa, non la possa fare gratis. Arriviamo alle 13 e un quarto, se siete d'accordo, ok? A meno che voi non abbiate lezione alle due, ok, non voglio che voi stessi al dia del passo, eccetera. Quindi mi chiedo, non è che questa cosa qua di un integratore senza perdita ce l'ho con una popolazione di neuroni eccitatori? Quindi questo integratore neurale come popolazione, come fenomeno di singola cellula, ma si pensa che sia un fenomeno di popolazione, è stato ipotizzato per spiegare questa attività. Sì, io lo sto vedendo sul neurone, però può essere che quel neurone faccia parte di un blog. Io l'ho peciato, anzi qui è semplicemente, gli sono andato dentro la pancia con uno sharp electrode e sto vedendo la sua attività, ma la sua attività, se lui è indistinguibile da quelli vicini, probabilmente è rappresentativo di tutta la popolazione. Non è che lui di per sé isolato fa questo gioco, è un fatto di connessioni sinaptiche. Se considero esattamente lo stesso caso in cui ho la stessa popolazione con questo feedback positivo e considero il caso, e qui potreste storcere il naso, che l'evoluzione o l'ontogenesi o i processi metabolici hanno regolato l'efficacia sinaptica per assumere un particolare valore e tenerlo fisso. Potrebbe esserci qualche meccanismo di omeostasi per cui l'efficacia sinaptica cambia, però viene comunque mantenuta in un certo range, magari piccolo, con molta precisione. Questo range deve essere, lo dico io, è a 1 diviso alfa. Se J è uguale a 1 diviso alfa, che era il punto critico oltre il quale sarei diventato molto nervoso, oppure sarei abbandonato essere nervoso perché voleva dire che il sistema era epilettico, se mettete qui J uguale 1 su alfa, questo J per alfa diventa 1 e 1 e 1 si cancellano sparisce questo termine del secondo membro di questa equazione differenziale che se avete un minimo di familiarità con questa solita noiosa, solita equazione differenziale è il termine resistivo di un RC è il termine che viene chiamato perdita leak infatti se riscrivo l'equazione a sinistra continuo ad avere tau derivata nel tempo di H e a destra ho non ho più H ho la corrente esterna meno, quindi J alfa è diventato 1, meno teta. Quindi questa cosa qua è un integratore perfetto. Se io, per risolvere questa equazione differenziale, scrivere H uguale a qualcosa, posso integrare da voi membri, al di là del fatto che si veda occhio, e qui è un differenziale esatto e scrivo H. Ok, c'è la condizione iniziale, è H di T uguale. E qui è l'integrale di una costante, questo non varia nel tempo. O se varia nel tempo è ok, supponete che i ext non cambia il tempo questa è l'integrale di una costante e la costante qual è la sua primitiva? è t per quella costante infatti quando derivo la costante quando derivo t mi viene 1 se t moltiplicava una costante mi viene la costante stessa quindi però se anche i ext lo volete fare come una funzione arbitraria del tempo questa descrizione questa è la scrittura corretta Dice che H, la corrente sinaptica che un neurone di quella popolazione di neurone eccitatori collegati in modo ricorrente sta ricevendo, è l'integrale temporale della corrente. La critica che potete muovere è bellissima, molto elegante, l'unico problema è che la biologia fa schifo e non credo, dovreste essere dubbiosi, che l'efficacia sinaptica possa essere messa in modo tale da tenere un valore, cioè dell'ipotesi o la critica del fine tuning. Se in un sistema artificiale, questo forse è possibile, nella memoria di un computer, sapete anche dal punto di vista di una realizzazione elettronica o artificiale, avere il fine tuning di alcuni parametri è fuori dal mondo. Anche semplicemente dal punto di vista elettronico, se voi comprate dei componenti elettronici, non è che sono tutti identici, c'è un'enorme variabilità, tanto che le compagnie che producono componenti elettronici ne buttano un sacco e vi vendono quello che è in un certo range. Quindi anche quando comprate un amplificatore operazionale, non è che quello è il guadagno dell'amplificatore operazionale. Lo dovreste misurare e vedreste che è a meno del 5-10%-20% a seconda di quanto pagate. Quindi anche nel mondo della matematica lo faccio a occhi chiusi. Avevo un collega che diceva che ho gli occhi chiusi o con la mano sinistra, in un modo profondamente maschilista, diceva alla femminile, l'ho detto soltanto per ricordarlo e per penalizzarlo, non va bene, non è appropriato, lo dico perché penso, e questo non dico il nome, ma è uno dei più grandi teorici neuroscienziati alla Columbia University che ci siano. In questo mondo sì, nel mondo anche dell'implementazione biologica o elettronico-artificiale, forse scordatevelo, Terzo punto e ultimo, per 5 minuti rapidissimi. Se cambio J, cambio i punti di equilibrio. Vi voglio solo fare riflettere che se, l'esempio che ho fatto tante volte, se dovete tenere a mente qualcosa, che non sia qualcosa di cui avete una memoria, ha creato il memoria, se vi dovessi fare vedere un mazzo di carte, vi faccio vedere che è l'uscito, il masso di cuori, non sta sintetizzando, esprimendo geni o costruendo delle connessioni o spine dendritiche, questo richiede minuti o ore. Lo facevo l'anno scorso con lo Sergio Dempio per la cosiddetta working memory, memoria di lavoro, vi dicevo se io vado fuori dalla stanza e poi ricompaglio, credo che ve l'ho detto alla prima lezione, adesso spero sì, voi abbiate espresso dei geni, delle proteine con la mia faccia e mi riconoscete, spero ma un anno fa, uscito e rientravo voi mantenevate in mente sia la stessa persona che era prima se per caso io dovessi avere questa funzione di working memory di memoria di lavoro potrei pensare che questa riverberazione, questo tenere in mente ho fatto già l'esempio anche se è leggermente diverso perché ha a che fare con il linguaggio e il linguaggio è un'altra cosa se io vi do un numero di telefono ma non avete nulla da scrivere, continuate, almeno io continuo a ripeterlo, 3-3-8, questo è un modo, la stesso tipo di riverberazione potrebbe essere quella che capita, e capita, nella corteccia inferotemporale, in una popolazione di neuroni eccitatori, proprio per l'esistenza di queste connessioni ricorrenti. Se per caso ho un modo di cambiare le sinapsi, per apprendimento, perché vedo che quando, mi fate vedere l'asso di cuori, oppure l'asso di picchio, quello che è, io ogni volta ve lo faccio vedere, poi lo tolgo, poi ve lo rifaccio vedere dopo, vi ricompenso se mi dite se è uguale o se è diverso. La plasticità sinaptica potrebbe esprimersi e naturalmente dopo qualche sessione potreste immediatamente fare questo task riverberandovi in mente lo stimolo. Questa rete lo fa. Quindi la rete è tale per cui se uno stimolo viene presentato e poi viene tolto, l'attività della rete non torna a zero, quindi non fa come ho fatto vedere prima con quella traccia giggling nera, che quando la traccia andava giù, andava giù anche l'attività della rete, della risposta. Quanto più J aumentava, tanto più era un'amplificazione, però era una mappa dell'input. Questo avviene nelle aree sensoriali, nelle aree associative avviene qualcosa del genere, non in tutte però sia in prefrontale che in inferotemporale, avviene che quando lo stimolo non c'è l'attività è zero, quando lo stimolo c'è l'attività va su, amplifica, quando lo stimolo viene rimosso l'attività non torna giù, resta qui. E questa attività persistente può essere a un certo valore, qui è 5 spike al secondo o anche più piccola, qui probabilmente sarà 2 o 3 spike al secondo. è una specie di modo con cui metto una pallina in questo profilo del potenziale della valle la metto in un attrattore in un bacino di questa minimo di questo potenziale di questa pozza di potenziale e quando non mi serve più lo metto da un'altra parte è come se cioè qui a zero ci fosse un attrattore un equilibrio un po di equilibrio stabile qui in alto se io mi cilassi faccio portare quindi la pallina viene mossa e viene mossa sufficiente a destra per fargli passare quella barriera di che era il punto di stabile la pallina poi cade quando quando tolgo la mano la pallina cade e resta nell'altro punto di equilibrio, qui su. Questa è una simulazione microscopica di una rete di neuroni eccitatori di integra e spara, in cui quando ci sono le sinapsi ricorrenti e io inizio ad aumentare l'efficacia sinaptica, qui è zero, quindi quando, o è molto piccola, quando presento lo stimolo, che è dato da questa barra blu, questa barra, scusate, grigia, L'attività, vedete in questo raster plot che non si vede nulla, e qui in nero l'istogramma, quindi la frequenza totale complessiva, qui appena rimuovo lo stimolo torno giù. Qui la rete risponde amplificando, quando tolgo lo stimolo è come se la pallina restasse qui, però a un certo punto evidentemente scappa, non è sufficientemente stabile questo attrattore, questo punto di equilibrio. Qui invece, quando tolgo lo stimolo, l'attività della rete resta esattamente come nell'esperimento che avete visto voi. Qui ho preso soltanto dei neuroni e li ho connessi a caso in modo ricorrente. Con queste considerazioni che faccio adesso, so qual è il valore di J, nel caso microscopico di G barrato, oppure del Tmax del neurotrasmettitore, che devo utilizzare per avere un doppio punto fisso, si dice. cioè un punto fisso qui e un punto fisso sotto. Notate che i punti di equilibrio sono punti di equilibrio in un regime dinamico, perché non è che la rete sta zitta. Qui prima, in effetti la rete non è completamente silenziosa, ma comunque l'attività è più o meno statisticamente sempre la stessa. Anche qui l'attività flutua, ma è più o meno statisticamente sempre la stessa. Quindi punto di equilibrio non vuol dire che molto, che le cose non cambiano nel tempo, ma che la statistica non cambia nel tempo. Per fare questo ho bisogno di una cura frequenza corrente con saturazione, lo riprendiamo domani, ma semplicemente volevo farvi vedere quanto è relativamente banale farlo. Questa è la simulazione del modello di campo medio. Quanto più inizio ad aumentare il valore di J, a un certo punto questa coda, Se volete, questa è come se fosse la costante di tempo che diventa sempre più lenta, a un certo punto diventa infinitamente lenta, anche se non è la stessa cosa. Vedete che qui è simile al caso intermedio della simulazione microscopica che vi ho mostrato prima, e qui l'attività persistente è mantenuta. Devo inibire, devo iperpolarizzare tutti i neuroni per scogliermi da questo stato, è una specie di condizione vistiosa in cui mi sento bloccato per tornare nell'altro. L'unica differenza fra le risposte di queste tre reti è che quest'altra ha una j sufficientemente elevata, ma non deve essere troppo elevata. E domani prenderemo questa equazione, studieremo i punti di equilibrio, perché se è un punto di equilibrio vuol dire che h non cambia nel tempo, quindi lo chiamerò steady state, e in questo caso però non faccio alcuna ipotesi se sono sopra o sotto la soglia. Decido di spararmi, di affrontare questa non linearità, J per E. E quindi in effetti scrivo un'equazione che è un'equazione algebrica implicita. Io non so se so risolvere, se so come scrivere HSS, fattorizzarlo e portare a sinistra HSS e a destra tutti i membri in cui non c'è HSS. Forse sapete, forse ricordate, forse ricorderete che se devo risolvere un'equazione del genere ho due modi. il modo numerico, un metodo per esempio è quello di Newton-Raphson, a trovare gli zeri di un polinomio, per esempio, ma anche di una funzione qualsiasi. Quali sono i valori tali per cui una certa funzione ha degli zeri? Potrebbe averne più di uno. Un altro modo è un modo grafico, cioè a dire, e lo vediamo domani adesso finisco, Paragonare, questo l'avete fatto sicuramente in qualche reminiscenza di geometria analitica, alle medie o alle superiori, in cui avevate una situazione simile. A sinistra, dicevate, quindi le soluzioni sono soluzioni che soddisfano sia il termine di sinistra che il termine di destra. Soddisfare vuol dire che sono punti in un grafico a cui soddisfa il grafico di HSS e nel piano funzione di HSS, HSS è la misettrice del primo e terzo, quindi a sinistra è una cavolata. Qui è un'altra funzione nel piano funzione HSS, dove è una funzione di HSS che è una threshold linear, a parte J che ne cambierà la slope e a parte un offset. Quindi nel metodo grafico, forse avevo semplicemente questo disegno da farvi vedere, forse un tempo voi un'equazione del genere la scomponevate nel caso di un sistema di funzioni, due funzioni, due grafici, e dicevate quando questi due grafici si intersecano, Allora, visto che sono punti in comune, sono quelli i valori che soddisfano questa equazione, vuol dire a sinistra è uguale a destra. Quindi sono i punti di equilibrio e lo facciamo soltanto in modo grafico. Ci vediamo domani, se avete bisogno sapete sempre dove trovarmi.