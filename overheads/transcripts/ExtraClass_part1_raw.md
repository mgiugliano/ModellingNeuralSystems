Ok allora in questa lezione supplementare vorrei raccontarvi e darvi qualche elemento in più sulla parte di processi stocastici e su quella parte trattata e identificata come approssimazione di diffusione. Sarà chiaro nel prosiego di che cosa si tratta. Inizio con il semplicemente rinfrescarvi le idee sulla teoria delle probabilità. In particolare ricordo il contributo essenziale all'inizio del secolo scorso di Andrei Kolmogorov che l'ha sistematizzata ed è stato un campione da tanti punti di vista, in particolare anche nella definizione dei processi stocastici. In generale ricorderete che la teoria delle probabilità, come detto in classe, ha a che fare con la deduzione, quindi una teoria, un principio da cui si deduce qualcosa legato all'esperienza, non il viceversa. Non si parla dall'esperienza alla teoria, dal particolare al generale. Quella è la statistica, è l'inferenza. E quindi invece nel contesto della teoria delle probabilità fondamentalmente si parla di un'esistenza, di un esperimento. Questo esperimento ha delle uscite, queste uscite sono rappresentate con il linguaggio della teoria degli insiemi. In questo caso l'insieme di tutte le possibili uscite di un esperimento viene chiamato omega, qui sono semplicemente indicate con dei quadratini, non è tanto importante, e ciascun esperimento può avere una uscita dentro questo insieme. Per esempio, quando prendete una moneta cosiddetta buona, ma anche una moneta non buona, cioè a dire una moneta che non abbia la probabilità 50-50 di capitare testa o croce, avete comunque delle uscite, qualunque cosa sia la probabilità. E ora vediamo una definizione più rigorosa. Queste uscite sono testa o croce, head or tail. E se ne avete due, e l'esperimento è quello di allo stesso momento, o anche in momenti diversi non importa, ma quella è la definizione dell'esperimento. Tirate in aria le monete, queste monete cadono su un tavolo, è chiaro che l'insieme di tutte le possibili uscite di questo esperimento ha a che fare con non due ma quattro eventi, che entrambe siano testa, che una sia testa e l'altra croce, l'esatto contrario oppure che tutte e due siano croce. Mi è scappato nell'uso comune l'evento e un'uscita dell'esperimento, però è anche una cosa più generale, cioè può essere una qualunque collezione, un qualunque sotto insieme dell'insieme. io potrei dire l'evento, questo evento che voglio studiare, non è necessario che io li studi tutti, ma questo che voglio studiare è quello che ha la prima delle due monete uscita a testa, quindi di fatto sto considerando un sotto insieme composto da queste due uscite, bene questo sotto insieme lo chiamo pure evento, l'evento può essere l'insieme stesso oppure può essere l'insieme nullo. Vediamo poi perché questo ha una rilevanza. Questo è l'esempio che ho appena fatto, in cui due monete vengono lanciate in aria e la loro uscita viene accorpata e quindi l'evento e l'unione di questi due elementi dell'insieme Omega. Cerchiamo di fissare le idee. supponete che io abbia una scimmietta e a questa scimmietta faccia vedere una foto di un cane. La faccio vedere in modo molto molto breve e durante il periodo, durante la presentazione e immediatamente dopo, qualche millisecondo dopo, misuro nella corteccia inferotemporale di questa scimmietta e in particolare cerco di caratterizzare l'attività elettrica di un neurone che è vicino all'elettrodo. Questo neurone risponde con potenziale d'azione oppure no, rimane silenzioso. Quindi in questo contesto l'insieme delle possibili uscite di questo esperimento è il neurone spara oppure non spara. Qui vedete una simulazione che ho preso al volo, è una cosa che abbiamo fatto insieme durante il primo anno in cui il modello con interpretazione stocastica dell'eccitabilità ionica, l'eccitabilità neuronale, mi permetteva di generare delle risposte non deterministiche. Vedete qui che sono cinque realizzazioni, cinque simulazioni, ciascuna delle quali ha visto lo stesso stimolo, in questo caso è un stimolo di corrente, vedete che tre volte su cinque il neurone non ha sparato nonostante sia stato depolarizzato, in due occasioni il neurone ha sparato. Questo è un esempio al di là del fatto che la simulazione ha una componente non deterministica, aleatoria, casuale, è estremamente rappresentativo di una situazione che avviene in qualunque sistema complesso descritto con una descrizione stocastica. Questi eventi, per esempio l'evento che spara o non spara, sono chiaramente caratterizzati da questo esempio. Ovviamente a questo punto vi viene voglia di dire l'hai fatto cinque volte, hai ripetuto l'esperimento in momenti diversi, presumibilmente i momenti che non hanno una correlazione l'uno all'altro, magari sono indipendenti, l'esperimento però è sempre lo stesso, la scimia è sempre la stessa, la foto è sempre la stessa, sareste tentati di dire ma il fatto che qui due volte su cinque, questo due diviso cinque ha Qualche cosa a che fare con una probabilità, con una frequenza relativa? Effettivamente l'idea è, da un punto di vista assiomatico per Kolmogorov e per Bernoulli in un punto di vista più empirico, e vediamo quella assiomatica perché è più semplice, la probabilità è un qualche numero che noi associamo a un evento. Prendetela così per il momento. È vero che quello che siete abituati nell'esperienza comune è di rappresentare la probabilità con il concetto di frequenza relativa. Quindi effettivamente, in effetti qui è il limite su un numero enorme di tentativi in cui un certo evento si verifica rispetto al numero totale di trials, numero totale di prove ripetute. Questa è stata una definizione che è stata utilizzata per tanto tempo, forse per cento anni, e ovviamente, vedete, richiede un numero elevato di osservazioni. Il calcolo è semplice, è una frequenza relativa, ha una natura a posteriori, cioè derivata dall'esperienza, Io potrei volere nel caso di una moneta completamente simmetrica dal punto di vista geometrico, che non ha alcuna caratteristica ufficiale da una faccia o dall'altra. Quindi dal punto di vista, se io mettessi il taglio, non avrebbe il centro di massa leggermente spostato da un lato o leggermente spostato dall'altro. È perfetta, simmetrica da ambo le parti. Questo sarebbe invece a priori. Come faccio a calcolarlo a priori? Potrei farlo, in quel caso dico non c'è ragione per privilegiare una parte o l'altra, invece se una moneta fosse con la sterlina con la testa della regina, adesso del re, avrebbe magari più da un lato una certa quantità di massa, potenzialmente potrebbe essere ragionevole assumere a priori una questione diversa per il valore della probabilità. E sebbene sia utile invece il calcolo o l'utilizzo della frequenza relativa, nel caso di problemi reali le probabilità devono essere stimate dai dati. Per esempio una compagnia di assicurazione deve avere una qualche statistica di analisi degli incidenti delle macchine. se non ce l'ha come diamine fa? quindi seppure questa definizione porti a anche comprendere il fatto che se questa probabilità è 0, questa frequenza relativa è 0 questo vuol dire che un evento è impossibile o quasi impossibile perché ricordatevi qui è un processo di limite mi colpisce moltissimo quindi allo stesso tempo 1 è quasi certo il fatto che durante tutti i miliardi di anni che siamo su questo pianeta o forse un po' meno per la specie umana non possiamo stabilire con certezza comparabilità unitaria che domani sorge il sole perché il numero di volte in cui questo è stato osservato è sempre minore del numero dei giorni che sono stati verificati quindi questa definizione dei problemi non entro ci sono problemi più profondi Quindi questo processo di limite potrebbe matematicamente non esistere e inoltre dipende da avere una quantità di dati che sono notevoli. Se uno non ce l'ha o se vuole dedurre anziché indurre potrebbe questa definizione essere un problema. E quindi Kolmogorov ci dice che esiste una possibilità diversa, la probabilità è una funzione e assegna un numero a ogni evento. Quindi, dato un qualche esperimento, definite come volete i vari eventi. Ricordate che possono essere anche dei sottinsimi delle uscite, non è necessariamente detto che sia quella uscita dell'esperimento. Nel nostro caso il neurone spara e il neurone non spara. Voglio considerare questi due eventi, sono due eventi, sono mutuamente esclusivi, o capita uno o capita l'altro, questo è il mio evento, o evento spara o evento non spara, e io a priori assegno un certo numero a ogni evento. E questo numero deve essere un numero positivo o nullo, quindi l'assioma della non negatività, deve essere tale che quando viene riferito a un evento che comprende tutti gli elementi di un esperimento, quindi in effetti è applicato e associato all'evento che comprende tutto Omega, questo è unitario. Cioè a dire il fatto che io stia considerando un evento diverso, in particolare nel nostro caso l'evento è il loro non spara e il loro non spara, l'evento il loro non spara oppure non spara deve avere probabilità 1 per definizione. Capite che questo ha a che fare con l'insemistica, col fatto che voglio associare una specie di complementarietà a eventi mutualmente disgiunti, disgiunti dal punto di vista grafico, insemistico. Terzo assioma deve valere un'additività, di nuovo viene comodo l'interpretazione insemistica. Nota, questi sono assiomi, sono delle definizioni, non c'è nulla da capire. Se tu fai così, allora la probabilità è una quantità ben formata. e con questo simbolo di unione sto dicendo che A, B e C sono degli eventi all'interno di Omega e la probabilità che associo all'evento unione, che dal punto di vista logico vuol dire è una O A, O, B, O, C, è una unione, non è una sovrapposizione, non è un overlap come sarebbe se qui ci fosse il simbolo della intersezione non è il caso in questo caso la probabilità è la somma delle probabilità potete pensare al fatto che questa sia una specie di attribuzione del valore numerico per esempio dell'area sottesa da questi blob di insiemistica che io mi sto immaginando così questo è A, questo è B e questo è C ok che sono anche sovrapposti ma non me ne frega niente se io voglio capire qual è generare un nuovo evento e questo evento è l'unione di questi quindi di fatto è qualcosa che ricalca fedelmente questi tre blob lo vedo qui dal punto di vista insienistico che è la somma dei tre e probabilmente ho detto una fesseria con l'intersezione perché qui l'intersezione la conterai due volte quindi devono essere due eventi, devono essere tre sotto insiemi disgiunti quindi devono essere tre eventi disgiunti se è così allora vale che questa è una buona definizione per la probabilità infatti, pardon, deve essere mutually exclusive, devono essere eventi disgiunti se non vedete che da questa interpretazione vediamo che c'è la parte sovrapposta che deve essere rimossa da questa definizione segue, e questo è molto interessante perché ha a che fare di nuovo con l'insegnistica con questo simbolo indico il complementare cioè indico quello che è dato un evento quello che è il suo complementare se volete il negativo rispetto a una specie di fotografia in cui si vede l'insieme collettivo omega, l'insieme più grande che contiene A quello che resta quando tolgo A e per il terzo assioma e per il fatto che la probabilità che associo all'evento nullo è 0, perché se volete non ha un'area, non ha un'area sottesa, il complementare di un evento, la probabilità che si attribuisce al complementare di un evento è 1 meno la probabilità di A. Ho scritto male, devo correggere la slide. Quindi in questo caso, di nuovo, Sembrerebbe che in un caso come questo, se la moneta è buona o se la moneta non è buona, non importa, qualora io abbia la probabilità di un evento associato, la probabilità dell'altro evento è 1 meno la probabilità del primo, perché questo è nel complementare T e il complementare di H e viceversa. E infatti 1 meno un terzo è 3 terzi e 2 terzi. Funziona la matematica, però uno deve chiaramente fare le cose giuste. Ok, passiamo all'altro step. Sono step piccoli per semplicemente rinfrescarvi la memoria. Vi voglio andare a raccontare delle variabili aleatorie di nuovo. È una definizione molto utile perché permette di legare la definizione a esperimenti concreti in cui per ciascun esperimento io posso attribuire una quantità, che ovviamente la chiamo variabile, nel senso che può variare, Ed è il risultato dell'applicazione di una funzione che per ciascun evento assegna un numero, un numero reale. Potrebbe essere un numero intero, potrebbe essere un numero complesso, non importa, è una funzione. In questo caso immaginiamo che sia un numero reale. E se volete una specie di riassunto numerico di quello che è l'outcome di un esperimento. Se ogni volta che il neurone spara vuol dire che la scimmietta si vuole mangiare, non è così, mangiare il cagnolino, vuol dire che a me posso dire che ogni volta che il neurone spara a me costa di dover impedire alla scimmietta, costa energia, oppure mi costa di dover andare a comprare alla scimmietta un nuovo cagnolino da mangiare. È un esempio chiaramente stupido. Quindi per l'uscita aleatoria di un esperimento, l'uscita random in parte impredicibile di un esperimento, io posso attribuire un riassunto numerico. Non è particolarmente difficile la notazione, la variabile la chiamiamo e la denotiamo con un simbolo in maiuscolo, mentre in simbolo in minuscolo è il valore potenziale. se x è il costo dell'esperimento, x piccolo è un esempio orribile questo del cane che viene ucciso dalla scinietta, 1000 euro, è un cane bellissimo purtroppo di allevamento, 1000 euro oppure 0, Quindi questo x piccolo è il particolare valore, mentre x grande è il costo dell'esperimento. Quindi la realizzazione è diversa dalla variabile aleatoria. La variabile aleatoria è un concetto astratto, la realizzazione è quello che è effettivamente capitato in questo momento, a questa espressione dell'esperimento. E infatti questa funzione random variable, variable aleatoria, è una funzione che associa alle uscite di un esperimento a degli eventi dei valori, mentre x piccolo è il valore 1000 euro che mi costa un cagnolino di razza perché è una scimietta particolarmente viziata. Nel caso di una variabile aleatoria, dato che in qualche modo c'è un link con la probabilità che io ho assegnato pure, ho attribuito pure a ogni evento, posso definire una funzione e la chiamo di distribuzione cumulativa, anche detta CDF. Questa è puramente una definizione convenzionale, che però è utile, lo vedrete fra poco, in cui fondamentalmente attribuisco a un evento che adesso ha a che fare con il valore numerico della variabile aleatoria, che mi dice che se io fisso questo valore numerico, il numero di volte che la variabile aleatoria, per esempio, è minore o uguale a questo valore numerico, questa la chiamo funzione di distribuzione cumulativa. Vi faccio un esempio, in Python, Matlab, Julia, quello che è, avete la possibilità di generare dei random numbers, in realtà sono pseudo random numbers. e per esempio avete un comando in un qualche pseudocodice che si chiama r uguale RAND questo assegna a questa variabile un numero pseudocasuale compreso fra 0 e 1 allora vi potrebbe essere interessante chiedersi qual è la probabilità che r sia minore di 0,5 questo è in particolare una variabile uniforme cioè non c'è un particolare privilegio di questo intervallo 0,1 in cui questa variabile può capitare tutti i punti hanno la stessa probabilità questo ve lo sto raccontando, ve lo sto menzionando perché esattamente in questi termini abbiamo visto quando l'anno scorso abbiamo esaminato la necessità di simulare dal punto di vista numerico una descrizione stocastica per i canali di membrana. La probabilità che questo accada è, potete immaginare, per una variabile uniforme, è proprio 0,5. Se non ci credete potete provare a cambiare questo valore qui, anziché mettere 0,5, mettere 1. Quando è 1, qual è la probabilità che r sia minore o uguale a 1? Nota r è fra 0 e 1, quindi questa probabilità è 1. Viceversa, qual è la probabilità che questa quantità sia minore di 0? Ripeto, è fra 0 e 1, quindi la probabilità che sia minore o uguale a 0 è 0. Ora, al di là del fatto che c'è una specie di match fra quello che mettete dentro e quello che mettete fuori, e questo è una particolare condizione per il tipo di funzione cumulativa di distribuzione che è per l'appunto uniforme. Quindi in questo caso questa CDF era uniforme, ma in generale il concetto è che voi potete definire una funzione. Questa funzione è attribuita a delle caratteristiche elementari di quella variabile aleatoria. Facciamo un altro esempio. Di nuovo c'è la scimmietta, è terribile, è una scimmietta cannibale o perlomeno è feroce nei confronti dei cagnolini che non hanno fatto niente, però evidentemente gli piacciono. In questo caso la scimmia non mangia nulla, io fondamentalmente voglio monitorare, nello stesso esperimento in cui il neurone può rispondere o rimanere silenzioso, il valore numerico del potenziale di membrana a un particolare istante. 4 millisecondi dopo scusate 4 millisecondi dopo l'onset dello stimolo quindi questo è l'onset dello stimolo io potrei avere una qualche ragione per esempio comportamentale per aspettare un certo tempo e dopo questo tempo io voglio esaminare quello che faceva non solo se il neurone sparava oppure no in questo caso vedete che ho fatto credo 50 di questi esperimenti e in un numero notevole di volte vedete che non è stato emesso uno spike altre volte è stato emesso ed è stato emesso con una latenza molto diversa vedete qui ci sono lo si vede dai picchi gli spike possono avvenire a cavallo addirittura della fine dell'onset o comunque con un ritardo che è notevole 4 millisecondi comunque io prendo 4 mesi con il mio riferimento e mi chiedo qual è questa è una variabile rettore che posso definire ne potete definire quante volete questa è quella che voglio definire io perché potrebbe avere un interesse nel mio proseguo in cui dico qual è il valore numerico del potenziale di membrana a questo punto e quindi se io vedo questi puntini ogni puntino interseca una particolare realizzazione dell'esperimento e la cosa che vedo è che nella maggior parte delle volte questi puntini stanno qui, sono bassi supponete che questo valore qui probabilmente è meno 50 millivolt o giù di lì grosso modo qui invece questi valori qui sono attorno a più 20 millivolt è raro che stiano qui, sono molto più densi qui. Se calcolo qual è la probabilità per cui quel valore è sotto, quindi sotto per esempio è minore di più 40 mV, 40 mV addirittura ancora più in alto qui, più 40 mV la probabilità è un'italia, stanno tutti sotto questi puntini, sotto 40 mV non ce ne sono sopra infatti io vedo che qui praticamente è 1, è sempre così come abbasso questo valore, per esempio lo porto a meno 40 vedete che trovo, quindi sono per esempio qui, meno 40 mV ce ne sono sia sotto e sono la maggior parte, sia sopra e sono pochi. Quindi di fatto a questo punto qui questa è la probabilità, se volete il numero, la frazione di volte in cui i pallini sono stati al di sotto di questa quantità. Comunque è una probabilità molto alta perché, ripeto, dato questa soglia, Sì, alcuni stanno sopra, ma la maggior parte sta sotto, quindi è un numero elevato, una frazione elevata, l'80% se volete, o la probabilità 0,8. Vedete poi che la curva tende a decrescere e la cosa interessante ed è una conseguenza della definizione, e ve la rammento, f di x è la probabilità che x grande sia minore o uguale di un particolare valore, questo dovrebbe essere x piccolo, questo è lo stesso x piccolo, quindi questo è lo stesso di questo e questo invece è grande, ma è solo una notazione, una convenzione. per come è stata definita questa è una funzione monotona crescente, sempre positiva, che è facile da dimostrare quando l'argomento è molto molto piccolo questa funzione tende ad essere zero, quando il valore è molto molto grande questa funzione tende ad essere unitaria. quindi questa è una caratteristica molto importante in cui, la ripeto con questa definizione innanzitutto è una quantità sempre positiva beh perché la probabilità è una quantità sempre positiva più piccola di 1 perché al massimo questa quantità non può essere 1 per uno degli assiomi di Kolmogorov quando a sinistra il limite a sinistra e il limite a destra sono 0 e 1 a sinistra la coda deve andare a 0 e a destra l'asintoto deve essere quello 1 e un'altra proprietà interessante che viene fuori sempre dall'insemmistica è che se io considero la probabilità che x sia minore o uguale di b b lo rappresentati su un segmento questi sono i valori che x può assumere la probabilità che x sia sotto b ha a che fare con quella probabilità che io ho assegnato all'evento x minore uguale di b dal punto di vista insiemistico vuol dire che sto pensando a tutti i punti che possono stare qui e vedete che se a è strettamente minore di b io posso vedere che l'evento b l'evento x sotto b è dato dall'evento x fra b ed a più oppure unito con l'evento x sotto a e questo lo posso scrivere così ovviamente per il terzo assioma è l'unione di due termini quindi questo è l'unione di questi due eventi di questi due la proprietà di due eventi che sono disgiunti essere qui o essere qui è disgiunto Se vi permettete poi di scrivere, di portare al primo membro questa quantità, vedete che posso scrivere f di x, quindi scrivendo questa quantità come la differenza di due probabilità, quindi fondamentalmente se volete porto questo all'altro lato e quando scrivo così posso rendermi conto che la differenza delle funzioni di distribuzione cumulativa calcolate negli estremi di questo intervallo questo forse vi ricorda un pochino il rapporto incrementale ed è lì che andiamo a parare sempre Vado a parare lì perché mi farebbe più comodo, nella stragrande maggioranza dei casi, poter capire qual è. Sicuramente questa è una cosa utilissima ed è una utile definizione di partenza. Fra l'altro si usa anche comunemente nella descrizione dell'outcome, gli esperimenti veri, la descrizione cumulativa, particolarmente per le differenze di due variabili sperimentali che voi osservate in un esperimento, si rappresenta graficamente, si quantifica con la funzione di distribuzione cumulativa. Però mi farebbe più piacere dire ma qual è la probabilità di avere, se io discretizzassi questo intervallo, questo intervallo in cui x, che in questo caso il potenziale di membrana si può trovare. Quindi qual è la probabilità se io prendo questo intervallo oppure questo intervallo, questo intervallo, questo intervallo? La prima cosa che capisco è che se l'intervallo è molto molto molto piccolo la probabilità sarà nulla, perché questa è una variabile continua e la probabilità che quella proprio cada lì dove avete messo voi il vostro intervallino praticamente potrebbe essere zero se il vostro intervallo è un range di misura nulla e per passare dall'accumulativa a quest'altra descrizione in cui io di fatto sto pensando a questi bin a questi cestelli cestini in cui fondamentalmente mi chiedo conto le volte in cui il particolare pallino era capitato ed è capitato in questo bin di fatto sto cercando di svegliare nella vostra intuizione ricordo il concetto di histogramma che oggi tutti i linguaggi di programmazione spesso hanno come funzione di libreria incorporata matplotlib ce l'ha di fatto e per ogni intervallo conto quante volte qual è la probabilità, quindi qual è la frazione di cui le realizzazioni stanno fra un intervallo definito da due estremi A e B supponete questo sia A e questo sia B qui dentro questa non è altro che la descrizione con cui passo da questa cumulativa C di F a cui passo alla P di F densità di distribuzione di probabilità si parla di densità perché di fatto io sto parlando di un numero numero per unità della variabile x cioè sto dicendo che per un certo intervallo una certa misura per ogni millivolt ho una certa frequenza di occorrenza per millivolt, per decine di millivolt e ovviamente questo può cambiare nello spazio qui può essere più denso e in effetti vedete che questa l'istogramma, alla fine qui ho calcolato l'istogramma l'ho opportunamente normalizzato, adesso vi dico che relazione ha con questo, sembra avere un picco qui, come il picco che io vedo occhio qui. Quindi tutto questo ha senso. E mi rappresenta, come per la densità di una concentrazione ionica in un certo punto dello spazio, un fenomeno che può punto per punto cambiare, però comunque è definito rispetto all'unità, l'unità di spazio quindi se io devo tornare a questa definizione devo probabilmente dividere per un qualche delta x quindi ricapitolo cambiando leggerissimamente le variabili anziché chiamarli a e b lo chiamo x e x più delta x perché a un certo punto, come immaginate, faccio tendere dx a 0. Questo lo posso scrivere. Notate che, essendo una funzione cumulativa monotona crescente, per avere la probabilità, un termine positivo, anche se vi sbagliate, dovete mettere qui qualcosa, sottrarre da qualcosa che è sicuramente maggiore, visto che è una funzione che tende a crescere muovendosi per x, che si muove verso destra. e al massimo è 1 quando x è all'infinito, questo aiuta anche l'intuizione del fatto che ho fx più dx meno f dx. Se mi permettete di dividere ambo i membri per dx, posso fare il limite di dx che tende a 0, definisco la densità di distribuzione di probabilità, o pdf, come la derivata rispetto a x di questa quantità. Quindi se voi avete questa funzione f, f per esempio era una funzione che era nel caso di una variabile uniforme, era qualcosa del genere, questa è la cumulativa di una variabile uniforme fra 0 e 1, la sua derivata, quindi per passare alla pdf che prima già intuitivamente avevo disegnato è un rettangolo in cui l'ampiezza è 1 e un'italia è il supporto cioè laddove la funzione è diversa da 0 coincide proprio con il range 0 a 1 non è un grande esempio perché credo che anche voi per una variabile uniforme La parola uniforme vi dice che nel particolare processo di fare a pezzettini l'asse delle X, voi dite uniforme, qualunque sia il modo con cui contate, inferite o deducete, è sempre lo stesso numero, non c'è una prevalenza, non è una gaussiana che vediamo fra breve, anzi non la vediamo. Quindi in questo caso la densità di distribuzione di probabilità ha come significato quello di dirvi qual è la probabilità che una certa variabile, che la variabile elettorale che voi siete interessati sia in un certo intorno, in un certo intervallo infinitesimo, pesata da questo delta x. Ripeto, è una densità. Questo invece è un numero totale di particelle. qualcosa di simile alla fine l'abbiamo discusso quando ragionavamo sul passaggio fra concentrazioni, densità e descrizione stocastica in cui non era più un conto ma era una descrizione di una probabilità, in cui non era più una frequenza di occorrenze ma era la probabilità per l'unità di tempo che questo succedesse. Due proprietà di cui sicuramente siete al corrente. Se la cumulativa aveva come caratteristica il fatto che questa funzione cumulativa a un certo punto per il valore x che tende a più infinito avrebbe raggiunto 1, qui la stessa cosa si traduce per la definizione di derivata e di integrale, quindi se voi applicate qui l'integrale da voi membri riscoprite esattamente la stessa proprietà, qui deve valere che l'area sottesa è 1. Io la ricordo meglio pensare che qui l'area sottesa della gaussiana deve essere unitaria oppure l'area sottesa dalla densità di distribuzione di proprietà uniforme deve essere unitaria, questa è una cosa che è facile da stamparsi nella testa e un'altra caratteristica visto che questa è una funzione monotona crescente, beh allora la sua derivata non può essere altro che positiva, che è sempre positiva, questo torna ripeto con l'interpretazione per cui alla fine il significato di questo è la probabilità che una particolare variabile aleatoria sia il valore di questa variabile sia in un certo intervallo e questa probabilità è una quantità positiva. Quindi qui avete la pdf. Un brevissimo escluso sulle variabili aleatorie a valori discreti è che sono funzioni che prendono soltanto un numero finito di valori, potrebbe anche essere infinito ma deve essere countable, non deve avere la cardinalità del continuo, quindi purché siano quantità che vanno con un mapping con l'insieme degli interi. E in questo caso le probabilità prendono ovviamente la forma di probabilità che la variabili assuma un particolare valore, un altro particolare valore, un ennesimo particolare valore e ovviamente per le proprietà che derivano dagli assiomi la somma di queste probabilità è unitaria. Quindi se prima io non avevo a che fare con pi, poco fa nel caso della variabile invece a variabili continui, avevo a che fare con dx per fx grande per x piccolo, questa quantità e questa sono alla fine la stessa cosa e questa somma, che somma 1, è il match della definizione assiomatica della teoria delle probabilità e ha a che fare con il fatto che qui è la somma e nel caso continuo è l'integrale di tutto questo essere unitario, quindi somma con i e qui è l'integrale su tutto il dominio di definizione, per esempio da meno infinito a più infinito, di questa variabile. Qui c'è una corrispondenza facile ricordandosi il significato di derivata, di integrale, come percorso al limite rispetto a quello della sommatoria. Una cosa interessante è che per varie vere discrete la destra di distribuzione di probabilità è una step, una funzione a scaletta con valori o nulli o dei salti che sono esattamente dati dalle probabilità. ora prima di fare una pausa e interrompere volevo sottolineare il perché ci stiamo imbarcando in questa cosa in parte l'ho menzionato durante le scorse lezioni e in parte è dovuto in questo caso sto riproponendovi una slide che vi avevo fatto vedere l'anno scorso la caratteristica di rumorosità o di descrizione aleatoria, stocastica, non deterministica, non prevedibile è qualcosa che avviene sempre in neuroscienze a tantissimi livelli dal punto di vista molecolare quando abbiamo visto nel nostro caso il rumore di membrana in cui la permeabilità di membrana è un processo stocastico ed è fluttuo, ha delle fluttuazioni ed è rumoroso ma questo avviene anche a livello di trasduzione subcellulare, molecolare in cui per esempio tutte le reazioni biochimiche di cui avete visto, sto pensando in particolare alle reazioni che involgono le G-proteins oppure che coinvolgono i recettori sensoriali, per esempio nella retina, le upsine, oppure viceversa nel bulbo olfattivo, oppure i meccanorecettori. In tutti i casi non è un processo rigorosamente deterministico, è quasi irriproducibile o solamente descritto in termini statistici. Questo avviene anche a livello di eccitabilità neuronale, vi ho fatto vedere adesso poco fa, sebbene sia una simulazione a calcolatore, come il firing di un neurone possa avvenire con uno, failure o non failure, quindi sparo oppure non sparo, anche se le condizioni sono identiche, e anche con la latenza, la latenza può cambiare, di nuovo anche la latenza può essere descritta come una variabile aleatoria. Tutto questo avviene anche nel momento in cui i neuroni comunicano, il rilascio sinaptico è un processo stocastico sia per il fatto che i canali ionici, per esempio calcio, dal punto di vista inerenti, intrinseco, sono potenzialmente stocastici per il discorso del rumore di canale, ma anche perché la diffusione di neurotosvetitore nel cleft sinaptico è qualcosa di aleatorio. e tutto questo continua quindi non solo a livello di percezione, elaborazione ma anche di attuazione in cui l'attuazione motoria con il rilascio di neurotransettitore da parte del cosiddetto raggiunzione neuromuscolare è di nuovo una quantità aleatoria Questo è uno degli articoli pionieristici di quasi 100 anni fa, in cui Katz, premio Nobel, riporta che registrando l'attività nei muscoli di quello che è l'effetto dell'innervazione, l'effetto dell'attivazione di un nervo nella cosiddetta aggiunzione neuromuscolare, lui descriveva una serie di segnali elettrici, elettrofisiologici, aleatori li chiamava miniature end plate potential noi li chiameremmo post synaptic potential qui lui li chiama end plate potential perché questa struttura qui viene chiamata end plate di fatto sono eventi in miniatura rispetto agli eventi sinaptici in cui una attivazione in questo caso del nervo per esempio con una stimolazione elettrica o un atto volontario quindi questo è uno stimolatore elettrico galvanometrico perché sto immaginando che ci sia una specie di accoppiamento induttivo per disaccoppiare i due circuiti ma per stimolare con una corrente il nervo nel caso di uno spike dicevo questo è per esempio un evento che abbiamo descritto ho imparato a descrivere anche matematicamente con un'ampiezza anche dal punto di vista della grandezza sto pensando adesso alla corteccia dell'ordine di qualche millivolt qui in questo caso è una frazione di millivolt per questo vengono chiamati miniature e quello che lui ha fatto ha dato un'occhiata alle ampiezze, ampiezza qui, ampiezza qui, ampiezza qui, e ha calcolato l'istogramma, la densità di distribuzione di probabilità. Vedete che non è un unico valore, cambia, cambia su qualcosa che è impredicibile, viene descritto meglio come una variabile aleatoria. In questo caso credo che questi siano il numero di osservazioni a partire dagli intervalli fra le scariche. quindi ha preso questo intervallo, questo intervallo, questo intervallo, questo intervallo, questo più lungo e ha chiesto qual è la densità di distribuzione di probabilità, la pdf degli intervalli, chiamiamoli inter event intervals o inter spike interval, qui non sono spike, sono potenziali in miniatura, miniature synaptic potential. Anche qui ha una caratteristica che è tipica delle variabili aleatorie, tipica di una descrizione stocastica. Quello che voglio in qualche modo inquadrare è trattare la descrizione che è stata da tanti studiosi messa in luce in cui intrinsecamente tutte queste caratteristiche di stocasticità portano a una variabilità e una impredicibilità sotto certe condizioni addirittura di quello che è la scarica, l'emissione di potenzializzazione, in questo caso di neuroni corticali. Questo è un ulteriore articolo pioneristico del 98 in cui i due ricercatori ancora in vita, Sheldon e Newsom, hanno per la prima volta in modo sistematico portato la comunità all'attenzione del fatto che la quantità su una serie ripetuta di esperimenti e la stessa scimietta a cui viene mostrato la stessa figura, lo stesso stimolo, Gli spike non sono per niente riproducibili. Se qui considerate gli spike al secondo rispetto a una finestra temporale vedete che su esperimenti successivi, indipendenti, ripetuti, c'è una dispersione notevole, una impredicibilità. la frequenza degli spike interval di nuovo è una funzione che ricorda una densità di distribuzione esponenziale addirittura se uno va a considerare qui questa densità di distribuzione e considera la media e la varianza ottiene una quantità che sembra essere una quantità proporzionale all'altra tutte cose che non sono caratteristiche di un processo deterministico questo è un esperimento invece che abbiamo già discusso assieme in cui intrinsecamente la risposta di un neurone in una fettina di cervello affettato separato dalla corteccia intatta a paragone con la stessa risposta del neurone al perdono lo stesso stimolo l'iniezione di una corrente a partire dal da una pipetta che è messa nella pancia dello stesso neurone in questo caso è uno step di corrente da da un treno di spike completamente diverso, irregolare nel caso in vivo, regolarissimo e assolutamente praticamente realistico nel caso in vitro, da luogo a queste fluttuazioni nel potenziale di membrana quasi che sia un random walk, un processo stocastico, in parte descritto qui a che fare con la questione dei marinai ubriachi se avete letto qualcosa, non ci soffermiamo più di tanto su questo. e dal punto di vista intrinseco una risposta ha invece uno stimolo visivo, quindi qui è la scimietta che guarda invece il cagnolino e in questo caso l'attività è molto simile a questa, è assincrona, irregolare con il potenziale sottossogna che varia in modo casuale. Questo lo abbiamo già discusso, quindi non mi soffermo, avete anche un'altra descrizione in cui al variare dell'anestetico barbiturico anziché ketamina xilazina oppure in condizioni di sveglia oppure in condizioni in vitro, l'attività elettrica di un neurone sembra essere profondamente alterata da quello che è l'attività sinattica, l'attività di rete e con l'esperimento fatto e discusso un'altra volta vedete che quando io metto TTX dopo aver messo TTX che blocca le condottanze sodio-voltaggio-dipendenti di fatto ho un qualcosa che è indistinguibile da quello che è l'attività di una slice Ho ammazzato la possibilità che tutte le afferenze mi producessero degli spike nel neurone. Mi fermo qui e anticipo quello che sarà l'altra parte, la parte successiva di questa lezione online. l'idea è quella di mettere, inquadrare rapidissimamente i processi stocastici, raccontarvi di due processi stocastici, uno si chiama Holstein-Unebeck e l'altro si chiama processo di Stein, e l'idea è di dirvi che fondamentalmente questa storia qua di questo Holstein-Unebeck di fatto è l'integra e spara, Questo è l'integra e spara, mentre questo ha a che fare con l'attività sinaptica, con la storia del mio conto corrente bancario che va su e va giù, mentre questo ha a che fare con l'equazione di bilancio della carica. L'osservazione di corrispondenza fra processi stocastici e componenti essenziali nella discrezione neurobiologica delle caratteristiche elettriche dei neuroni porta a poter spiegare bene, almeno per una volta, l'approssimazione di diffusione, che ve lo dico forse per la seconda o terza volta ha a che fare con il progressivo cambiamento di quello che è un processo che sembra essere impulsivo e ha a che fare con l'attivazione delle sinapsi è vero queste sinapsi si attivano in modo casuale in modo irregolare ma non appena queste sinapsi si sommano perché dal punto di vista della membrana postsinattica il comportamento di tante sinapsi è di fatto integrato perché integrale è il comportamento di questa equazione differenziale che fa letteralmente la somma, cioè v, se io applico l'integrale ad ambo i membri, v è circa l'integrale di tutte le correnti sinaptiche e quando questo avviene con un numero che non è spaventosamente elevato, 100, 200, 500, sembra essere diventare un processo che è continuo, un processo cosiddetto di diffusione anziché un processo che ha a che fare con attività puntiforme, point process rispetto a diffusion process mi fermo qui