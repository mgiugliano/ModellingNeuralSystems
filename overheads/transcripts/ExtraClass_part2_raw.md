Ok, let's continue and let's see the plan for the rest of this lecture. So I will briefly review some stochastic process or the definition of stochastic process. And then I will specifically move to two stochastic processes. As I told you yesterday, both the Ornstein-Unenberg process as well as the Stein stochastic process non solo ha intriguing similarities ma formali sembra la exacta matematica formula di alcune di expressions che abbiamo visto e analizzato in termini di ultimi classi in termini di integrative fire e di synaptic current e abbiamo basically examinato la diffusione è e come come about ops, scusatemi, stavo... scusatemi, continuo in italiano, perdonatemi, perdonatemi ok, ok, ok, sono esaurito allora, l'appassionazione di diffusione di fatto ci porterà a stabilire qual è la relazione fra la media e la deviazione standard pensate alla media e varianza se questo sigma fosse al quadrato del processo stocastico gaussiano continuo cosiddetto diffusivo si parla di diffusivo perché richiama quello che in un contesto invece fisico non di teoria della probabilità è qualche cosa, un fenomeno che varia con continuità come quello della diffusione oltre ad esserci altre similitudini come questi parametri media e varianza di queste gaussianine, se volete, e si lega ai parametri del processo sottostante, in particolare della ampiezza del salto, che qui abbiamo chiamato j, della costante di tempo di decay. se io zoom qui, no, non posso zoomare, se io zoomassi qui avrei questa costante di tempo esponenziale, questa è la tau, ed è per esempio 1-2 millisecondi per i recettori AMP, 20-50 millisecondi per i recettori NMDA, altrettanti 10 per i recettori GABA-A, più lento per i recettori GABA-B e metabotropici, e più in generale l'abbiamo descritto con uno schema cinetico marcoviano a due stati dove avevamo l'inverso di beta, se non ricordo male, come rate di transizione fra gli stati, fra lo stato aperto e lo stato chiuso. L'ultimo paratro è chiamato lambda ed è la frequenza di questi eventi. Ovviamente se gli eventi passano da 10 a 20, a 100, a 200, per tutti i motivi che abbiamo brevemente discusso già la settimana scorsa, è come se, in questo caso questi numeri si riferiscono a una quantità di afferenti. Quindi non c'è un unico afferente che ha uno spike train, ma in realtà ce ne sono 10, 20, 50, 100 eccetera. E questa situazione si può di fatto dal punto di vista statistico approssimare a una situazione in cui il neurone abbia un unico afferente con una frequenza molto maggiore. Vi ricordate che avevo utilizzato durante l'altra lezione i colori e quindi fondamentalmente mi stavo riferendo, viste le proprietà dei treni di Delta Idirac, la loro sovrapposizione algebrica risulta in una sovrapposizione temporale, visto che le Delta Idirac sono definite come zero dappertutto tranne nel punto in cui sono definite. per esempio questa è delta t meno t di 0, quindi se io ne voglio rappresentare una messa qui e un'altra messa qua, a t0 e a t1, di fatto qui ho sovrapposto i grafici, senza curarmi delle famose code che abbiamo discusso in altri contesti, ma le cito qui per analogia, perché tanto qui il cosiddetto supporto, il dominio di definizione della funzione dove la funzione assume valori non nulli, praticamente 0, è 0 dappertutto, è nullo, a misura nulla. In questo caso questa particolare, questa funzione rappresentata a 2 delta di Dirac è la somma algebrica del primo più il secondo del delta di Dirac sommati algebricamente. Quindi la cosa interessante ovviamente è che la media sembra avere una dipendenza proporzionale da j, lambda e tau, la deviazione standard o se volete la varianza che diventa j quadro lambda tau mezzi, pure dipende da lambda. Questo parametro è al quadrato, ok? Questo parametro è lo stesso parametro che compare qui, qui c'è un termine, un mezzo, di cui ovviamente uno deve prestare attenzione. Quindi ci approcciamo a dimostrare questa equivalenza, e a capire quando vale, che cosa vuol dire che valga questa equivalenza. Allora, come detto, una variabile aleatoria è una variabile in cui il valore è legato a un evento, quindi più legato alla fisica possiamo dire che il valore è soggetto a qualche variazione dovute al caso, quindi per esempio il potenziale di membrana a un certo momento nel tempo, questa è una variabile aleatoria, perché è una quantità di fatto impredicibile quando il neurone per esempio sia soggetto a un bombardamento sinaptico, oppure dove questi trend di spike sono in qualche modo descritti con una statistica irregolare, come abbiamo visto essere il caso in vivo, quindi come per esempio questi siano dei processi di Poisson, Poisson Point Processes. E in altri casi l'abbiamo visto che il potenziale di membrana fluttuava, era una quantità che era di fatto impredicibile nel caso del rumore di canale, quello che abbiamo chiamato Channel Noise, dovuto al flickering fra lo stato aperto e lo stato chiuso. Nel caso dei processi stocastici di fatto si parla di una collezione di variabili aleatori, una per ogni istante temporale. Se il processo stocastico è a tempo continuo, come potete pensare il potenziale di membrana per ogni istante di osservazione, allora si dice che è un processo stocastico a tempo continuo. Se invece è un processo stocastico che avviene rigorosamente ogni delta, ogni qualche delta T, come una specie di campionamento, allora si parlerà di processo discreto. C'è anche una distinzione, ma qui non la facciamo, l'abbiamo velocissimamente vista nel caso delle variabili aleatorie, di processi stocastici a valori continui. Il potenziale di membrana è una quantità fisica, un potenziale elettrico che varia con continuità. Ci sono altri casi in cui il potenziale è, scusate, un processo stocastico si dice valori discreti, assume cioè soltanto dei valori discreti. Potete pensare al famoso segnale telegrafico, cioè a dire qualcosa che ha due livelli e i cambiamenti di questi livelli sono stocastici. Alla fine qualcosa di simile l'abbiamo visto nelle transizioni di nuovo nel rumore di canale. solo per dirvi che in questo caso il canale era aperto o chiuso e una qualche variabile associata adesso poteva assumere soltanto il valore 0 oppure il valore 1, in questo caso convenzionalmente è per dire il canale è aperto o chiuso, quindi questa era una variabile aleatoria che avevamo associato. Quindi per ogni istante t, x di t è una variabile aleatoria e parlo di realizzazione come di una certa traiettoria che è specifica e è riavvenuta adesso, come per il caso della distinzione fra variabile aleatoria e il suo valore che viene in una particolare istanza, in una particolare realizzazione, così si parla di realizzazione dei processi stocastici. Se faccio una registrazione sperimentale del potenziale di membrana di un neurone, quello sarà una realizzazione. Non è detto che quella realizzazione sia rappresentativa completamente di tutto quello che può essere il processo stocastico. Alla fine il processo stocastico è una potenzialità, le realizzazioni sono quelle che osserviamo. Allora, inizio con il ricordarvi quello che è il concetto di rumore gaussiano bianco. Lo trattiamo dal punto di vista un pochino ingegneristico, quindi in parte abuserò di una notazione matematica che a rigore non potrei utilizzare. Quindi di fatto lo chiamo rumore, in realtà il rumore ha un'accezione negativa nel caso del segnale, rumore c'è una specie di contrasto. Io qui semplicemente dico che lo chiamo rumore perché è un processo stocastico, dico che è gaussiano, quindi lo chiamo ξ con i e quindi di fatto sto assumendo che a ogni istante questa ξ sia una variabile aleatoria distribuita con una distribuzione gaussiana e quindi avrà una certa media e una certa varianza. Poi parlo anche che è bianco. Bianco si riferisce non alle variabili aleatorie, ma al processo stocastico, cioè a dire alla dipendenza nel tempo. Se io prendo bianco, ha a che fare con l'aspetto spettrale, cioè in un dominio trasformato, nel dominio delle frequenze. sapete che il bianco è per definizione delle scale cromatiche additive contiene tutti i colori questo in qualche modo vuol dire che contiene tutte le frequenze quindi in un dominio trasformato è come se, dominio di Fourier o Laplace o quello che volete, Fourier vuol dire che lo spettro o la densità spettrale di potenza nel caso di un processo stocastico è in teoria qualcosa che ha tutte le frequenze, come se avesse tutti i colori. Nel tempo vuol dire che le sue fluttuazioni del tempo sono tali per cui se voi prendete due punti vicini a piacere, t1 e t2, tali che t2 meno t1 sia uguale a un qualche epsilon piccolo quanto volete, scusate, non minore di 0, ma intendevo dire minore di 1, molto minore di 1, lo potete prendere quanto piccolo volete, al limite lo potete prendere anche tendente a 0, se lo prendete a 0 sono esattamente lo stesso istante, ebbene in questa condizione i valori corrispondenti, quindi il valore che ha il processo ξ in quel punto t1 in questa realizzazione e il processo Xi che ha all'istante T2 in questa realizzazione, questi due valori che se mi permettete di chiamarli Xi1 e Xi2 sono corrispondenti, sono variabili aleatorie indipendenti, cioè non hanno alcuna correlazione. Qui nel tratto che ho utilizzato qui in nero vedete che c'è una correlazione, io nonostante questa sia una penna digitale, ma nella pratica comunque non lo potrei fare neppure con una penna fisica, una penna qualunque, non posso muovere, fluttuare, fare un jiggling della punta della penna arbitrariamente veloce. Invece di cui mi parla questo spettro di potenza, questo mi dice che ci sono frequenze, cioè energia a tutte le frequenze, anche frequenze altissime qui, dove vuol dire che il segnale varia, è come se avesse delle componenti in frequenza di Fourier con frequenze arbitrariamente alte. Quindi per ogni istante t è una verbina di lettura gaussiana, questo vuol dire che la sua densità di distribuzione di probabilità, che sapete essere una gaussiana, la continua a scrivere come f piccolo, come p di f, probability density function, e il famoso e alla meno x al quadrato diviso 2, ora qui in questo caso sto ragionando che la media sia nulla e la varianza sia unitaria, è preceduto da questo termine 1 diviso radice di 2 pi greco. Nota, se non ci fosse questo termine qui, l'integrale di questa quantità da meno infinito a più infinito non sarebbe unitario, mentre ovviamente le proprietà di una PDF sono che, per definizione legata agli assiomi di Kolmogorov, ha l'area sottesa unitaria. E questo è ok, sto parlando della solita situazione in cui la densità di distribuzione di probabilità, l'istogramma se volete, ma l'istogramma è qualcosa che viene dai dati, è statistica, non è teoria delle probabilità, è un'osservazione da cui io faccio un'inferenza, mentre qui è a priori. La forma della PDF è una gaussiana e l'area sottesa è unitaria. Fatemi cancellare questa cosa per non apisentire il grafico, perché non voglio fare adesso necessariamente l'integrale. Qui mi sto riferendo al caso semplice della cosetta, una variabile normale, in cui la media è 0 e la varianza è unitaria. Se non fosse così, anziché scrivere qui x, avrei dovuto scrivere x meno mu al quadrato diviso 2 e al denominatore avrei dovuto scrivere sigma al quadrato. E qui avrei dovuto pure mettere sigma al quadrato o sigma. Non mi ricordo. non mi ricordo, devo guardare, forse sigma, non sigma al quadrato. Se mi aiutate a guardare, ancora meglio. Detto questo, la cosa della caratteristica della correlazione o dell'assenza di correlazione viene tradotta quantitativamente nella cosiddetta funzione di autocorrelazione. La funzione di autocorrelazione mi dice che la similitudine fra i valori del processo a due istanti arbitrariamente vicini o arbitrariamente lontani è praticamente sempre zero, tranne che quando i due punti sono esattamente coincidenti. Questo matematicamente si scrive così, la funzione di autocorrelazione si scrive in questo modo, e il valore atteso del prodotto somiglia a quella che è l'espressione della varianza. Qui vedete che è la media del prodotto del quadrato, quindi del prodotto di x di t per x di t. Qui invece è x di t per x di t più t grande, dove t grande è l'intervallo fra t1 e t2, fra questi due istanti. Allora in teoria questa quantità potrebbe dipendere anche da t, cioè potrebbe essere tempo variante. Nel caso che stiamo considerando il processo è tempo invariante, cioè qualunque siano i punti t e t più t grande che prendete, questa media del prodotto, che ha come significato quello della correlazione, è sempre 0, fuorché quando t grande è 0, quindi di fatto questo torna a essere la definizione della varianza. visto che è una funzione di t la devo per forza esprimere al di là del fatto della natura matematica del fatto che la trasformata di Fourier di questa quantità dell'autocorrelazione questo è il teorema di Wiener-Kin-Kin non so se l'avete mai sentito la trasformata dell'autocorrelazione è la densità spettrale di potenza nota la densità spettrale di potenza si chiama in letteratura anche PSD E infatti il fatto che questo sia una costante nel dominio delle frequenze ha a che fare col fatto che questo sia una delta di Dirac nel dominio del tempo. Media nulla, varianza unitaria e direi che è tutto. E ovviamente, come detto prima, non esiste in natura, è solo una strazione. Anche il rumore biologico comunque ha una autocorrelazione, una scala temporale di autocorrelazione finita. Quindi se mi permettete di tornare qui e di nuovo commentare questa cosa, nella realtà la funzione di autocorrelazione, qui ho T grande, non è una delta di Dirac per i processi veri, ma è più simile a, come vedremo, a qualcosa che può essere colorato e quindi per esempio potrebbe essere una funzione che fa così. Questa è una funzione di un processo, del processo di Onsen-Hunelm, che vedremo fra poco. Potete pensare che passare da qui a qui ci sia di mezzo una qualche operazione di filtraggio, da dove escono questi esponenziali decrescenti. Ho capito che è una funzione di autocorrelazione, però l'intuito, l'intuizione che possa avere qualcosa a che fare con la dinamica di una qualche variabile dinamica che cambia quando è alimentata da un rumore gaussiano bianco potrebbe ispirarvi. In questo caso, quando la funzione di colorazione è così, ovviamente la densità spettrale di potenza non è bianca ma a un certo punto taglia e colorato, si dice un rumore colorato. Allora, adesso vi introduco quella che è la mia definizione di processo di Orson-Lunenbeck, la mia e lo capirete perché se andate, come spero, a guardare in letteratura, come spero, facciate per tutti i corsi, per tutte le vostre attività, troverete che la definizione può essere alle volte leggermente diversa, ma capirete a breve perché questa, la mia definizione, è quella che è più facile anche dal punto di vista didattico. Quindi anche questo è un processo a tempo continuo e a valori continui e definito qui abuso attraverso un'equazione differenziale ordinaria. Il problema di questo abuso è il fatto che io sto parlando di un'equazione differenziale ordinaria. non è per niente un'equazione differenziale ordinaria perché è un'equazione stocastica e come ho fatto tante volte in questo corso e nell'anno scorso, cercando ogni volta che avevo un'equazione differenziale, cercando di applicare, dando i membri l'integrale, c'è un problema matematico cruciale, quando ci sono processi stocastici il tipo di integrale, in particolare i rumori bianchi come quello che abbiamo visto, L'integrale non ha la stessa definizione, non è la definizione di Riemann o di Lebesgue che potete pensare, ha un'altra definizione, matematicamente si calcola in modo diverso, non c'è la regoletta della primitiva, è un'altra regola, ma non la vediamo perché non è importante, solo vi metto in guardia il fatto che questo è un abuso fatto da me che sono un ingegnere. Ok, riprendo dopo questa pausa. Allora, la definizione che ne do è quella di una uscita, quindi una funzione del tempo, e questo è sbagliato perché non è una funzione normale del tempo, che soddisfa questa equazione differenziale, in cui è la stessa solita, usuale, noiosa equazione differenziale del primo ordine a coefficienti costanti, dove però l'ingresso è un rumore bianco. Questo lo faccio perché sono ingegnere. I matematici si schiferebbero, fra virgolette, di questa notazione perché dire che questo processo è differenziabile è un abuso perché dovrei capire o dovrei dire rigorosamente qual è la mia definizione di differenziabilità, visto che questa quantità non lo è. Quindi, però, tutte queste difficoltà, diciamo, le lascio inespresse. Quello che qualche volta trovate in letteratura è una espressione in cui questo Δt non c'è e anziché scrivere ξ di t si scrive de ξ di t. E ovviamente questa è una notazione a cui non siamo abituati. Di fatto qui si parla di un differenziale e qui si parla di un processo stocastico che ha a che fare con i delta, ma non ne parliamo di questo. Se da ingegneri praticoni e smalettoni osserviamo questa equazione potremmo dire che è un'equazione a coefficienti costanti con un input additivo. lasciate perdere che questo è un processo socastico addirittura bianco, che ci sono le delta di ira che gli escono dagli occhi, non importa. Quindi in teoria qui c'è il segno meno che mi rende molto tranquillo, perché evidentemente almeno la soluzione dell'omogeneo associata è un'esponenziale decrescente, ho la mia condizione iniziale, dal punto di vista deterministico, se questa fosse una funzione normale, io potrei dire so scrivere la soluzione. La soluzione è data da due termini, un termine che è la soluzione dell'omogenea associata più l'integrale particolare. L'integrale particolare è l'integrale di convoluzione fra la risposta all'impulso, che è un'esponenziale decrescente per questa classe di funzioni, e l'input. Tuttavia, quindi come detto, io sto abusando di questo. Le cose comunque continuano a funzionicchiare per quanto ci riguarda. In particolare se voi voleste cercare di scrivere, e ve lo suggerisco, di derivare queste stesse informazioni che vi voglio fornire io. Le definizioni diverse in letteratura a cui mi riferisco hanno a che fare con questo termine qui, la radice di 2 tau. Perché Diamin dovrei scrivere qui una roba con la radice di 2 tau. Posso immaginare che Ψ di t sia un rumore gaussiano bianco media nulla, varianza unitaria, quindi se io ho questo Ψ di t e voglio mettere che ha a destra, nel membro di destra di questa equazione, metto un rumore che ha una certa media, una certa varianza, per le proprietà delle variabili alle letture gaussiane, quindi per estensione ai processi gaussiani, posso prendere questo e moltiplicarlo per σ e questa quantità qui adesso ha varianza sigma quadro. E poi posso aggiungergli mu. Così facendo, questa quantità qua ha, è un rumore, gaussiano bianco, a media mu e varianza sigma quadro. Quindi, io non sono necessariamente tenuto a farlo, purché sia consistente con le altre scelte. Potrei dire, guarda, io penso che sia più conveniente definirlo così. Opla. perché le proprietà che avrà x, statistiche di x che avrà, quindi adesso vorrei capire qual è la sua media, qual è la sua varianza, qual è la sua funzione di autocorrelazione, non parliamo della densità spettare di potenza che ne è la trasformata di Fourier. Per avere queste tre grandezze, di fatto, mi viene meglio che qui sia, ok, mu, come avrei fatto sempre, qui sia sigma radice di due tau. Ma se voi non avete qui scritto radice di due tau, ma avete solo sigma, potete semplicemente fare un cambio di variabili, cioè in realtà voi vi state riferendo a un sigma primo, che rispetto al mio sigma, quindi sigma primo è tutta questa pizza qui. laddove nelle mie espressioni seguenti vedrete comparire questo sigma e se voi avete usato un'altra definizione di sigma per queste e queste, semplicemente dovete fare il cambio di variabili, quindi dovete tener conto che sigma primo è per la vostra definizione sigma diviso radice di due tau. Nulla di male, quindi da uno ottenete l'altro e dall'altro ottenete uno. Niente di particolarmente complicato. Allora, questa parte è apparsa in basso prima del tempo. Questa è l'equazione con cui definisco il processo di Olsten-Ullenberg. Questo spesso si abbrevia con OU, come Olsten-Ullenberg in letteratura. E' tale per cui la media, che se volete in qualche senso potete pensare che sia ottenuta, questa è l'espressione della varianza, ma torniamo un attimo dietro alla media. Potete pensare che l'espressione della media sia ottenuta risolvendo un'equazione differenziale che si ottiene applicando il valore atteso da ambo i membri qui, qui, qui, qui. E questo va bene, lo potete fare, in particolare lo potete fare perché l'operatore di valore atteso e l'operatore di derivata li potete scambiare per la linearità dell'operatore atteso, del valore atteso. Quindi di fatto voi inizierete a scrivere un'equazione differenziale in cui non avete il valore medio della derivata ma avete la derivata del valore medio che è m, che è questa m che volete calcolare. Poi qui avete una somma di termini, anche qui applicate rigorosamente la proprietà di linearità del valore atteso che dice che il valore atteso della somma è la somma dei valori attesi. In questo caso qui ho il valore atteso di una costante, che quindi è la costante stessa, qui mi diventa il valore atteso di x, che è la variabile della nuova equazione differenziale, la cui soluzione sarà m, e qui avete un termine che è una costante, lo portate fuori dal valore atteso, una costante deterministica intendo, e qui avete una quantità che per definizione, quando gli applicate il valore atteso, avete 0, perché xi è un valore, un processo stocastico a media nulla. Se fate così, avete molto banalmente che dm su dt è uguale a mu meno m, punto. Avete anche la condizione iniziale e potete dimostrare che la soluzione è la somma di due termini, la soluzione dell'omogenea associata più l'integrale particolare. Vi faccio notare che è giusto per controllare quando, se sono interessato alla soluzione, soltanto lo steady state, vuol dire m costante rispetto al tempo, vuol dire che questo lo rendo nullo, o che m, se volete lo potrei chiamare m infinito, comunque m tende a mu, e infatti questo transitorio si esaurisce e anche questo transitorio si esaurisce, quindi torna con l'intuizione e con questo controllo rapido. Per quanto riguarda la varianza, questo gioco non è banalissimo farlo perché la definizione di varianza è il valore atteso della differenza quadratica, del quadrato della differenza fra il processo e la media. Non riuscite a scrivere facilmente la derivata di S, non riuscite a scrivere quindi un'equazione differenziale in questo caso. Non è troppo difficile e anzi sarebbe propedeutico per capire quella che è l'espressione della covarianza, che è il valore atteso. sto usando la covarianza perché è più completa rispetto all'autocorrelazione che era priva nel caso del processo stocastico gossiano bianco per il fatto che avesse media nulla le due coincidono, qui la media in generale non nulla quindi voglio descrivere una misura di similarità fra punti successivi spaziati a una certa distanza t grande e voglio togliere un offset che è legato alla media visto che la media è non nulla perché non mi interessa che ci sia una specie di residuo di correlazione dovuto al fatto che c'è un offset continuo, visto che il processo X-osonomic ha media non nulla. Per trovare questa quantità, di cui voglio solo farvi vedere che l'espressione matematica, al di là del fatto che varia nel tempo, quindi in effetti è tempo variante, ma dopo un tempo paragonabile con tau, e se tau è come sarà quello legato alla dinamica sinattica 1, 5, 10 millisecondi, dopo pochi millisecondi il processo va direttamente allo steady state, dal punto di vista statistico, cioè m è mu, s quadro è sigma quadro, e la covarianza diventa, questo termine si esaurisce, diventa questo esponenziale decrescente simmetrico che vi ho detto sarebbe potuto essere la funzione di autocorrelazione o una funzione di autocovarianza di un processo più realistico, più ragionevole, più fisicamente realistico. Se volete fare per esercizio questa derivazione è una cavolata, dovete semplicemente fare attenzione e per farlo vi do l'imbeccata, se riesco a farlo, quindi non così. Voglio aggiungere una maledetta slide, ok, voglio aggiungere una slide vuota e con grande tecnologia su questa slide vuota volevo semplicemente dirvi che ogni volta che avete dx su dt, ovviamente mi sono scordato la forma, quindi ok con la tau prima non mi ricordavo questa tau, va bene. La guarderò altre 25 volte, anzi aspetta, faccio così, così utilizzo queste fantastiche risorse tecnologiche. Quindi fondamentalmente qui io ho che l'omogenea associata di questa la scrivo come tau dx su dt meno x, ok? Questa quantità qui ha come soluzione x di t con 0 per e alla meno t su tau. Quindi ho portato questo qui sotto, mi sono compiaciuto del fatto che ci fosse il segno meno e ho applicato la condizione iniziale i x di t0 uguale a quello che è x0, se volete. Quindi ho sostituito per identificare quella costante. Poi c'è un altro termine, che è quello mu, ed è più questa quantità qua, e di fatto lo accorpo, se me lo permettete, in una qualche funzione arbitraria, non la chiamo g, ma la chiamo h, no, non la chiamo h, la chiamo, boh, la chiamo whatever, g di t. Questa g di t è mu più sigma radice di 2 tau xi di t. Ma la chiamo g di t perché volevo semplicemente ricordarvi che x di t, la soluzione analitica di questa equazione differenziale, di questa pizza, è la somma di due termini, la soluzione dell'equazione omogenea associata più l'integrale di convoluzione da meno infinito a più infinito di questa quantità qua. e alla meno t su tau per g di t meno, la chiamo eta, in d eta, la variabile dammi. Questa cosa qua è, se h di t è e alla meno t su tau, dove questa è la risposta all'impulso, Allora questa quantità qua è h di t integrale di convoluzione con la funzione g di t. Sapete che questa cosa qua era l'integrale da meno infinito a più infinito. C'è un altro modo di scriverlo con gli estremi di integrazione da meno infinito a t e nel caso di... Ok, questo non è corretto perché ci va anche una funzione gradino, non è per la causalità che stavo cercando di invocare. Questa è la risposta all'impulso, se questo è t. e nel caso in cui questa sia una funzione causale, cioè per t minore di 0, per t minore di t0 in effetti, è nulla, allora l'estremo di questa integrazione si può rimpiazzare con t, però questo nel caso generale è h di t per t men eta in d eta. E ricordatevi che questa è un'operazione commutativa, quindi potete tranquillamente fare h di t meno eta per g di... Scusate, questo è eta. Se la scrivo così, questo è eta. C'è solo una t, non ce ne sono due. Ok? In questo caso avete quindi l'equazione differenziale. La chiave di tutto per calcolare la varianza e per calcolare la funzione di covarianza è quella di scrivere il prodotto x di t, in un caso per x di t, in questo caso x di t al quadrato, e di applicare il valore atteso. Lo applicate qui ed è una quantità deterministica. Lo applicate qui e scambiate il valore atteso con l'integrale. Scambiate l'ordine. Quindi avete l'integrale di bla bla, di un valore atteso, che va a cambiare qualcosa che è relativo a sigma. Però, attenzione, qui è un prodotto, e la stessa cosa avete quando considerate t più t grande. Cioè avete due integrali, avete questa pizza, questo x di t, se volete, è un pezzo a più un pezzo b. Quindi quando fate il prodotto, x per x, adesso faccio solamente nel caso al quadrato, quindi senza cambiare la variabile, qui il tempo è lo stesso, qui invece no, nella covarianza è diverso, ho i doppi prodotti, quindi ho a quadro più b quadro più 2a per b. In altri termini, se prendo seriamente l'idea di fare questo prodotto e devo farlo bene, questa è la somma di due termini, quindi il prodotto fra due somme, in questo caso sono somme identiche, in questo caso no, ok? Quindi richiede attenzione, ogni volta che avete il termine questo con l'integrale al quadrato oppure un integrale per l'altro integrale ovviamente dovete cambiare la variabile di integrazione ed è la stessa cosa con la quale quando avevate due sommatorie e le moltiplicavate insieme cambiavate l'indice delle sommatorie. Questo è più facile a scriversi che a dirsi, avete un integrale in d eta moltiplicato, lo stesso identico integrale a parte avere traslato di t grande, vedete che qui t compare, quindi se è calcolato in t più t grande dovete cambiare qui t, ma dovete cambiare la variabile danni, dammi di integrazione, che ne so, la chiamate epsilon, la chiamate pippo, la chiamate come volete. Se fate così e riuscite a non fare degli errori di calcolo, ottenete l'espressione della slide precedente. E avete un termine di transitorio che di fatto proviene da quella componente deterministica che è la parte legata alla soluzione dell'omogenea associata. avete un termine che ha a che fare, fa uscire fuori la varianza in questo caso, è la delta di Dirac nell'altro, immaginatevi che avete una delta di Dirac sotto l'integrale, in realtà avete una delta di Dirac perché avete un integrale doppio del prodotto di 2, quindi Xi di T e Xi di T più T grande, di cui sapete che sotto l'operatore di valore atteso quella e la funzione di autocorrelazione o di covarianza del processo di questo input. Quindi utilizzando solamente strumenti dell'analisi normale, deterministica, non l'integrale di Ito, che è quello che del signor Ito, che è quello che ho menzionato prima, che in effetti richiede attenzione, anche senza quello in questo contesto in qualche modo ve la cavate, riuscite a derivare queste quantità. La chiave è che definita così, con mu qui e sigma soltanto qui, questo processo ha media mu e ha varianza sigma quadro e la funzione di autocorrelazione è di autocovarianza sigma quadro per un'esponenzione decrescente col modulo perché è simmetrica. Ok, non è un caso che il processo di Onestrion-Hunenberg e il Leaky Integrate and Fire siano molto molto simili, in particolare questo termine qua che voi direste o è l'input che uno sperimentatore inietta e se questo sperimentatore mi chiede Giuliano e mi ha detto che inietta un processo stocastico, una realizzazione del processo stocastico, Ah, posso immaginare che avere una descrizione di cosa fa questo processo X voglia dire avere una descrizione di cosa fa il processo V. Nell'altro caso questa non è la corrente che Michele Giuliano inietta, ma è la corrente che Leonore riceve per i fatti suoi, una corrente sinaptica. Tuttavia le correnti sinaptiche che abbiamo visto finora sono, ricordatevi la storia del mio conto corrente bancario, sono il risultato dell'attivazione di recettori post-sinaptici, famosi schemi cinetici, che è un qualcosa che va su e giù, le famose code. quindi non è un processo diffusivo, continuo, è un processo a salti, quello che fra poco chiameremo processo di Steyn, mentre questo è un processo gaussiano. Quando i due sono simili, nel piccolo sketch qualche slide fa vi ho fatto capire che fondamentalmente quando fate una somma di tanti tanti termini alla fine vi esce fuori qualcosa di gaussiano, invocando quello che in teoria rigorosamente è il teorema del limite centrale. in questo caso ci sono alcune considerazioni che sono degne di attenzione quindi per rendere piena corrispondenza fra quello che è qui un rumore bianco che vuol dire che è un rumore bianco? forse questo rumore bianco è più legato a questa parte qui al fatto che qui ci sia un treno di delta di Dirac se vi ricordate era questa la descrizione cioè a dire forse la corrispondenza potrebbe non essere con v, ma con l'equazione differenziale a cui soddisfa la corrente sinaptica totale, che era tale quale aveva un beta corrente sinaptico, questo beta alla fine è una tau, alla fine ha lo stesso significato di quello, e poi aveva qualcosa qui che era una sommatoria di delta e dirac. Quindi forse la corrispondenza non è tanto con i lichi integrati in FHIR quanto con l'espressione matematica a cui la corrente sinaptica soddisfa e questa corrente sinaptica poi viene messa nello stomaco all'integra e spara. Diventerà più chiaro fra poco, ma prima voglio che mettiate in pausa questo video e proviate a dire come faccio a simulare questo processo stocastico, mettetelo in pausa e provate a rispondere. Io invece continuo dicendo che la possibilità di discretizzarlo viene fuori da una considerazione che è simile a quella della discretizzazione di un'equazione differenziale ordinaria, però richiede molta attenzione. Questa descrizione con il metodo di Euler richiederebbe che il tempo venisse discretizzato in bin temporali t e poi che la derivata venisse scritta prima di fare il limite del rapporto incrementale. Quindi qualcosa del tipo x di t più delta t meno x calcolato in t diviso delta t. Questo rimpiazza questa quantità qui. La fregatura è che questo è una brutta bestia, non potete dire come invece fate per questa quantità X che lo state campionando. Io qui sto fondamentalmente sostenendo che se lo voglio simulare al calcolatore devo trovare una sequenza di un altro, in questo caso è un altro processo. Questo è a tempo discreto, anziché essere a tempo continuo, è un discrete time, ed è una roba diversa, si chiama x cappello, però la mia speranza è che x cappello in istanti multipli di delta t in qualche modo sia identico al processo che voglio simulare, x calcolato in t. Una roba del genere è quello con l'uguale o perlomeno è circa uguale a quello che faccio normalmente con un'ecosione differenziale. Il metodo di Euro sappiamo che è il peggiore, però vorrei al limite usare il delta T il più piccolo possibile affinché la soluzione discreta non si discosti tanto dalla soluzione vera. Qui però sono in un mondo di processi stocastici, quindi devo leggermente rifrasare e dire che il processo a tempo discreto che sto cercando voglio che sia simile, affine, analogo al processo continuo e non lo sarà mai perché potrebbero esserci delle difficoltà come in questo caso. Questo non è campionabile, non posso scrivere psi t con k, allora lo posso fare, questa è una variabile aleatoria, gaussiana, di cui sono media, sono varianza, però c'è questo problema della funzione di autocorrelazione che è una delta idirac. Quindi, in altre parole, devo trovare un qualche criterio che mi dica, in un caso a tempo discreto, qual è il mio criterio di equivalenza. Non è particolarmente difficile e funziona in questo modo. Quindi per caratterizzarlo di nuovo utilizzo quella che è la conoscenza della soluzione analitica di questa equazione differenziale interpretando questa quantità come una quantità deterministica, ma non la scrivo, la dovete scrivere in quel modo con l'integrale di convoluzione se volete provarlo. Ma anziché scrivere x di t uguale, io già scrivo x di t più una quantità delta t che in questo caso non dico che debba essere infinitesima, dico che sia una quantità che conosco, che è nota. Quindi ogni volta che qui ho dentro quell'integrale di convoluzione bruttissimo o e alla meno t, devo rimpiazzarlo con t più delta t, laddove ho la parte di soluzione, il pezzo di soluzione dell'equazione omogenea associata e dove ho un'esponenziale, devo calcolarlo in t più delta t. La speranza è che questa espressione porti a identificare x di t, cioè possa in modo iterativo esprimere x a t più delta t in funzione di quello che era x all'istante precedente. Nota, visto che x, questa è un'espressione, una soluzione esatta, esatta nel contesto in cui io considero questo xi una quantità deterministica, in parte sbagliato, questa equazione iterativa, delta t, può essere grande quanto volete, è un metodo di iterazione corretto. Lo abbiamo forse intuito, forse visto quando l'anno scorso, forse addirittura era solamente nel modulo online che qualcuno di voi ha guardato, beneficiato per un background, un refresh delle vostre competenze matematiche, avete visto che rigorosamente il metodo di Eulero è un limite, quando delta t è particolarmente piccolo, di un'espressione che alla fine è esattamente questa, è esattamente questa espressione qui. Infatti ogni volta che vedete un esponenziale e alla meno delta t su qualcosa lo potete scrivere, ricordando lo sviluppo in serie di Taylor, se delta t è piccolo come 1 meno delta t su tau. Potete vedere che se fate questo cambio ottenete Euler, però quando fate le cose, fra virgolette, correttamente per bene con questa espressione iterativa, vi accorgete che, e lo fate quindi non con quel metodo euristico che commentavo nella slide prima, cambio la derivata con il rapporto incrementale e poi metto Xi, No, se lo fate correttamente vi viene fuori questo termine qui con la radice quadrata e anche se adesso volete tornare con delta T, quindi volete avvicinarvi un po' a Eulero, è quello che viene chiamato metodo Eulero stocastico, vedete che ok, qui io lo posso anche cambiare, perdonatemi, sì, no è corretto, c'è non solo la radice quadrata ma c'è anche un 2. Il 2 proviene dal fatto che quando prendete x di t e x di t più t grande, da qualche parte a un certo punto c'è il prodotto di due esponenziali, quindi è al quadrato in qualche modo. Quindi se usate Euler, qui potreste approssimare come 1 meno, quindi più meno per meno, 2 delta t su tau. Scusate, non sto dicendo una cavolata. Quindi 1 meno 1 più 2 delta t su tau. 1 e 1 si semplificano, resta questa radice quadrata. E' interessante questa radice quadrata perché mentre qui tirereste fuori delta t su tau, e anche qui tirereste fuori 1 meno delta t su tau, Quindi tirate fuori Δt, esattamente quello che vi avrebbe portato l'approssimazione del segno di derivata con il rapporto incrementale. Qui non avete Δt, avete la radice di Δt. Questo mi si è stampato nella testa perché durante il lavoro della mia tesi di laurea ho come un farlocco, un pollo, simulato questa stessa equazione differenziale nello stesso identico contesto di rumore di membrana, di rumore sinaptico, di input che fluttuano, eulero. Ho fatto bello bello quello che in questa slide vi avevo proposto, cioè il fatto di dire uso eulero e utilizzo questa tecnica e campiono, e quindi scrivo questa espressione come x di t più delta t, porto dall'altro lato il termine, quindi questa diventa un'approssimazione, x di t più delta t diviso tau per mu meno delta t diviso tau per x più sigma radice di 2 tau per, questo è il mio problema, delta t su tau per, ok, ho messo esattamente la stessa cosa, x, sarà un numero casuale gaussiano generato da una stessa routine. Peccato, ed è facile da dimostrare, che se voi cambiate il delta t, le proprietà statistiche di questa x, del processo che state simulando, sono completamente diverse. Questa è una cosa molto interessante. Va bene, quindi seguendo questa strada dovete in qualche modo, vedete che qui sono addirittura molto cauto, qui addirittura lo sto scrivendo come un altro processo, questo è un processo a tempo discreto, gaussiano, media nulla, varianza unitaria e funzione di autocorrelazione che è una cosiddetta delta di Kronecker. non è delta id, perché non è una funzione del tempo, è una funzione dell'indice, soltanto quando l'indice è uguale a dove è centrata la delta, scusatemi, scusatemi, no no no, scusatemi, questo è un insieme di numeri, una catena bianca cosiddetta, cioè una sequenza di numeri discreti, di numeri generati da un algoritmo che tira fuori numeri pseudo casuali gaussiani, in cui la correlazione fra un numero e il successivo è zero, ogni volta è un processo di estrazione identico ma indipendente. E allora in questo caso l'approccio corretto è di dire x e x cappello hanno le stesse proprietà statistiche quando di nuovo qui metto una quantità che è gaussiana, ma la premoltiplico da qualcosa che non ha una varianza, qui è la direzione standard. La quantità che premoltiplica questa cosa qua va come la radice di Δt, ok, 2 è la radice di Δt, non importa, non come Δt. In questa circostanza state simulando il processo di un sistema in modo corretto. E quindi qui è scritto quello che ho menzionato. È una sequenza non correlata di variabili elettoriche e gaussiane con media varianza, nulla e varianza unitaria, quindi conta quello per cui io lo premoltiplico. E in questo caso, questo era in un articolo molto interessante, credo degli anni 2000 o degli anni 90, di un tizio che si chiama Gillespie, che è noto per essere stato quello che ha formulato un particolare algoritmo di simulazione delle reazioni chimiche stocastiche e per estensione degli schemi cinetici marcoviani stocastici che abbiamo visto l'anno scorso. Non ne parlo, ma semplicemente perché è un articoletto molto piccolo, sorprendente nella sua semplicità, e di fatto commenta questo tipo di metodo per la simulazione numerica. Quindi il metodo numerico di Eulero per la simulazione di Osten-Ulmerk non è questo. e in questo caso non avrebbero le stesse proprietà statistiche. E se uno cambiasse delta t, e non sto dicendo di prenderlo enorme o piccolo, sto dicendo che comunque è risultato grossomodo le proprietà statistiche, sto parlando di proprietà statistiche macroscopiche del processo. Io so che questo è il processo, deve avere una varianza mu, scusate, una media mu e una varianza sigma quadrato, E non devono cambiare questi valori se cambio delta T. Se fate così potete provarlo per esercizio, per esplorare la facciata che ho preso io da studente. Non ho sottomesso la tesi con quell'errore. Me ne sono accorto dopo qualche giorno. Sono andato alla ricerca di un tizio, di un professore a Genova che mi ha illuminato e mi ha detto no, hai visto che cambia con il delta T, questo non è possibile. Non mi ha venduto una spiegazione così semplice come quella che spero di essere riuscito a passarvi, cioè la derivazione di questa espressione con la soluzione analitica di questa equazione differenziale, immaginando che sia un'equazione deterministica. Mi ha semplicemente detto, quindi, occhio, perché questa cosa qua, qui, se vuoi utilizzare questa forma, qui devi mettere la radice quadrata di delta t. Non puoi scrivere delta t. E ovviamente la domanda è, ok, c'è un meme, quindi take my money, prendi i miei soldi e va bene, risolvi questo problema che non ho tempo, mi devo laureare. Però era intrigante del fatto che la varianza di questo processo invece a tempo discreto dovesse scalare con la radice di delta t. Sembrava una cosa, scusate, la delizione standard scala con la radice quadrata e la varianza con delta t. Questa è una cosa che sembra profonda. quindi ho anche scritto che l'abominazione di Eulero ovviamente quindi fa invece introduce questa dipendenza perdonate l'ilarità quindi e qui fondamentalmente vi sto descrivendo quello che vi ho fatto carta e penna nelle slide precedenti per convincervi di questa descrizione perché c'è una corrispondenza fra la soluzione analitica iterativa e il metodo di Oeolero invocando Taylor. Quindi questa è una ricapitolazione del fatto che se proprio proprio non vi piace utilizzare questa espressione qui per fare la simulazione, a me piace di più perché è esatta, perché delta t può essere preso anche non in... delta t può cambiare nel tempo, quindi la discretizzazione dell'asse del tempo può anche non essere uniforme. Quindi questo delta T potrebbe anche essere non uniforme, questo ha particolare impatto in approcci di simulazione in cui il delta T, la discretizzazione temporale non è uniforme e quindi si chiamano metodi di discretizzazione a passo adattivo, non è a passo fisso. Potreste però lamentare che se a voi non frega niente di queste tecniche a passo adattivo, calcolare migliaia di volte o milioni di volte al secondo questa equazione per poterla iterare, per poter generare una realizzazione di questo processo, vi richiede di calcolare un esponenziale. nota, questo esponenziale può essere calcolato una volta prima di iniziare qualunque ciclo, perché questo non dipende dall'iterazione, questo è un numero, è un numero compreso fra 0 e 1, che potete fare, che potete preventivamente calcolare, lo so che dipende da tau e da delta t, quindi se il vostro delta t non cambia, quindi non è un metodo adattivo, lo potete calcolare pre-calcolare, anche questa quantità la potete calcolare e anche questa pizza la potete calcolare, Quindi avete semplicemente un prodotto, una somma, un altro prodotto e un'altra somma. Però se proprio siete scettici, vi piace invece la discretizzazione, quindi non utilizzare l'esponenziale, non utilizzare solamente il delta t, tenete conto di Taylor che in questo caso genera la radice delta t. Vi sto soffermando forse a lungo su questa cosa, è una cosa che probabilmente è molto chiara per voi. Allora, quindi qui è un richiamo, un altro modo per convincervi delle proprietà statistiche del processo di Onsen-Unebeck, in cui il primo metodo è quello che vi ho spiegato e secondo me è il più intuitivo, il più semplice. Il secondo è interessante, lo lascio qui indicato, non ne parlo estensivamente, in cui con un trucco che forse addirittura credo che qualcuno di voi all'esame mi avesse o forse non eravate voi, era qualcuno a Trieste, è tipico dei matematici quando vogliono, è un approccio dei matematici che viene comodo anche per risolvere questo tipo di equazione. Potete vedere cosa succede se moltiplicate ambo i membri per e alla t su tau e moltiplicandola qui e moltiplicandola qui e moltiplicandola qui eccetera eccetera, potete, se fate le cose per bene, qui è l'esponenziale che moltiplica la derivata. Non vi venga lo schieribizzo di invertire, di fare che l'esponenziale per la derivata è la derivata dell'esponenziale per x, no, però potreste pensare che questo è il risultato di quello che era la derivata di un prodotto. La derivata di un prodotto è il primo fattore per la derivata del secondo più la derivata del primo per il secondo fattore. Quindi se fate le cose esattamente come sono scritte qui, con un pochino di attenzione, trovate un modo conciso per scrivere di botto questa equazione qui. E questa equazione qui potreste a questa applicare ad ambo i membri il valore atteso. Vedete di fatto che è qualcosa che ha già, quindi moltiplicare per l'esponenziale e poi applicare l'integrale fra 0 e t. Di nuovo questo vale se per t minore di 0 x era nulla, quindi se è un sistema causale, non anticipativo. E ovviamente riscoprite qualcosa che alla fine è simile all'integrale, o molto simile all'integrale di convoluzione. devo pensare qui perché non c'è t- non c'è una perdono questo non c'è entra niente sì no no è un mio problema qui non vedo una similitudine immediata con l'integrale di convoluzione devo pensarci un po' ma alla fine è un'espressione che in qualche modo va in quella direzione e niente quindi in questo caso vi invito a provare a guardare questo Si può utilizzare questa espressione, e qui è uscita fuori l'integrale di convoluzione, di fatto è un modo per tirar fuori la soluzione analitica, quindi senza ricordare che è la somma di due termini. Questo è un metodo che richiede di ricordare meno prova, però di lavorare un po' di più. In questo caso questa espressione può sostituire esattamente quella che vi ho cercato di vendere prima e potete utilizzarla per valutare la media, la varianza, dovete chiaramente fare la media del valore atteso del prodotto e dovete fare, vi ricordo che la definizione di varianza è la media di x-m, il valore atteso del quadrato di x-m. è facile dimostrare che vale sempre, che questo è il valore atteso di x al quadrato, meno m al quadrato. Se volete provare basta sviluppare questo quadrato di un binomio e vedete che alcuni pezzi contengono x, altri non lo contengono e sono deterministici. Quindi potete provare a fare. In questo caso è molto più facile, per questo che io sono ossessionato da il quadrato di x, però a rigore, in teoria, il modo più elegante sarebbe x-m, ma comunque non è cruciale. Ok, qui ci sono raccomandazioni sul fatto di come procedere con l'operatore lineare. Alla fine questo è quello che vi ho raccontato nella mezz'ora precedente. Vediamo la definizione del processo di Steyn. È un processo continuo nel tempo, a valori continui, ma viene anche chiamato un processo puntiforme. Io lo definisco come la soluzione, come ho fatto prima per Austin-Unebeck, la soluzione di un'occasione differenziale che però è stocastica. In questo caso la stocasticità è data dai tempi di occorrenza di questi impulsi, di questi delta i dirac. Ma per il resto, qui nel primo membro a sinistra, qui è molto simile al secondo membro per la parte che è meno y, è identica al processo di un'astrona di mecca. Quello che è diverso è che manca mu e manca quella quantità che era sigma per la radice di 2 tau bla bla bla bla bla. Qui ho scritto tau j per la sommatoria di questa delta di Dirac. Nota che ho messo tau qui perché voglio alludere con j il famoso salto. Se immaginate di applicare l'integrale di ambo i membri qui, qui e qui, c'è quel discorso che abbiamo fatto già diverse volte in cui qui ho un integrale esatto, un differenziale esatto. Qui ho l'integrale di una quantità continua integrato su un intervallo di misura nulla, quindi è zero. Qui ho per definizione l'integrale di una delta idirac in quell'intorno, vi ricordate fra t0- e t0+, 0-0+, a seconda di dove è centrata quella delta idirac, qui vi resta tau qui e tau qui che si semplificano. Quindi la regoletta iterativa è che y è uguale a y più qualcosa, questo qualcosa prende solo la forma di j e non di tau. E vabbè, ha una condizione iniziale che è quella che è. Potrei pensare di cercare esattamente uguale a quella che è la condizione iniziale di x, per esempio che al tempo 0 è 0. Al tempo 0, per esempio, potrebbe essere 0, y 0 potrebbe essere a riposo. Nota, questo oggetto qui è esattamente la storia dell'università che mi paga lo stipendio, l'unica differenza è che qui i tempi sono stocastici, sono generati da un processo poassoniano, vuol dire i tempi T con K sono tali per cui le loro differenze, i loro intervalli, uno rispetto a quello che viene immediatamente dopo, è una variabile aleatoria distribuita con una distribuzione esponenziale. quindi la condizione iniziale è la deterministica dal punto di vista deterministico e di nuovo questo è anche considerato il caso in cui il cosiddetto shot noise questo viene integrato quindi alla fine questo è y è 0 ogni volta che arriva un evento c'è un salto e poi y tende a decadere, a meno che non arrivi un altro evento, un altro evento, un altro evento, e poi decade se non ci sono più eventi. E questo è quello che ho detto, con questa specifica definizione, con tau qui e tau qui, è facile, un attimo si vede a occhio, ma si fa facile dimostrare che il singolo salto ha proprio ampiezza j. Mi interessa perché voglio, se io misuro che una corrente sinaptica eccitatoria o inibitoria è quello che ha un'ampiezza di 20 pA, io voglio poter scrivere qui la quantità 20 pA. Al di là del fatto che questa y potrebbe essere o meno rilevante il fatto di avere le dimensioni di una corrente, ma ce l'ha perché questo che potrebbe confondervi che è Ampere per un tempo, dovete confrontarlo col fatto che il termine di ampiezza di una delta di Dirac è l'inverso di un tempo, quindi dimensionalmente comunque ci siamo. Questa cosa che la delta idirac ha come ampiezza, come unità di misura, non è una quantità dimensionale ma è l'inverso dell'unità di misura della variabile invece indipendente, si capisce bene dal limite della delta idirac inteso come il limite della funzione rettangolo. La funzione rettangolo è definita per esempio da meno delta, meno delta mezzi a delta mezzi e ha come ampiezza 1 su delta. Sempre per qualunque valore di delta l'area è unitaria e quando uno fa il limite per delta che tende a 0 di questa funzione che spesso si chiama π greco grande, questo diventa delta di t. Anche questa dipende da t. Quindi come questa funzione qui vedete che aveva una ampiezza che aveva le dimensioni di 1 diviso delta, così anche questa ce l'ha e quindi non è in contraddizione che voi abbiate tau qui. Quindi se j è p1 per anche y sarà p1 per questo è un tempo, questo è un tempo si cancellano, qui è p1 per quindi le cose funzionano dal punto di vista dimensionale. Quindi i valori, come detto, degli istanti di attivazione, che per noi alla fine sono gli spike train sovrapposti di tante afferenze, che io li ho sovrapposti e li ho messi in un'unica afferenza. sto pensando a questa situazione qua in cui sono messi tutti assieme, ovviamente la frequenza è sempre un processo stocastico, se gli input sono indipendenti continuano ad avere la stessa caratteristica di essere poissoniano, e ha semplicemente la frequenza che è il multiplo del, se ho n afferenze avrò n per lambda, se lambda era la frequenza del verificarsi di questi eventi. In questo caso sto implicitamente invocando la cosiddetta proprietà di renewal, vuol dire che ogni evento è indipendente dalla storia precedente, quando si verifica la sua probabilità di occorrenza dipende solo dal momento, non c'è per esempio una rifrattarietà o non c'è per esempio una caratteristica di adattamento frequenza dipendente. Quindi a rigore potreste storcere il naso perché potreste dire i singoli spike train qui hanno una certa struttura temporale, se non altro per il fatto che, per esempio, potrebbero venire fuori da neuroni piramidali in cui gli ente spike interno tendono nel tempo ad aumentare, abbiamo visto l'adattamento frequenza dipendente. ma più matematicamente è molto simile a quello che abbiamo fatto altre volte per il rumore di canale l'anno scorso, si scrive che questa proprietà implica o è equivalente a dire che il fatto di avere almeno un evento e uno solo in un intervallo piccolo quanto volete è una funzione che posso scrivere con Taylor ed è una funzione ovviamente che dipende da delta T. Qual è la probabilità che il mio telefono, che sulla mia scrivania in questo momento, squilli in questo momento, fra adesso e fra un secondo, ok, non ha squillato, cresce ovviamente con l'aumentare di questo intervallo. Se dico qual è la probabilità fra adesso e stasera, diverse ore, ovviamente che questa probabilità cresce. Il fatto che qui ci sia la scrittura dei termini infinitesimi di ordine superiore è semplicemente per poter scrivere qui uguale. Questo è effettivamente l'integrale, ma mi basta, scusate, l'approssimazione di Taylor al primo ordine, ma mi basta, di una quantità che quando l'intervallo è 0 è 0. Questo perché è una variabile a valori continui e su un intervallo di misura nulla la sua probabilità, la probabilità associata, vi ricordate la definizione insiennistica che ho dato nel video precedente, è nulla, la probabilità è nulla. La probabilità di una variabile continua è sempre definita con un intervallo. Questo è Taylor al primordine e di fatto dico che quale che sia questa funzione complicatissima io alludo a questo lambda come il coefficiente dell'espansione di Taylor al primordine che interpreto come la frequenza media, che interpreto come frequenza istantanea anche detta in letteratura. è una frequenza perché è una dimensione di 1 rispetto al tempo, la probabilità è dimensionale, quindi lambda per delta t devono cancellarsi e quindi è il tasso di occorrenza di questi eventi. In questo caso assumiamo che non cambi rispetto al tempo ed è quello che viene chiamato un processo di Poisson puntuale omogeneo. Se cambiasse nel tempo, per esempio in modo sinusoidale, oppure viceversa si rallentasse o accelerasse, allora sarebbe un processo non omogeneo. E come detto, un'altra variabile aleatoria definita come l'interspike interval alla fine, cioè la variabile che si ottiene prendendo due tempi di occorrenza di questi eventi successivi, è una variabile aleatoria che ha una densità di distribuzione di probabilità esponenziale con questa particolare espressione in cui quindi lambda se t grande è l'intervallo fondamentalmente mi dice che quando t grande è molto molto grande la densità di distribuzione di probabilità è praticamente zero e piccola è molto difficile cioè se ho un fenomeno che è il telefono mi squilla in media una volta all'ora se dico ma qual è la probabilità di avere nessuna telefonata con un intervallo di 10 giorni è praticamente nulla perché questo esponenziale va giù rapidamente e va giù con questa scala temporale, con questa scala dettata dalla frequenza. Il fatto che abbiate lambda qui e che quindi sia dimensionale vi invita a riguardare la definizione di pdf, densità di distribuzione di probabilità che sapete essere per l'unità di, in questo caso, di tempo, essendo la variabile allenatoria un tempo. Quindi nel caso di questa equazione che definisce il processo di Stein, che per il momento non l'ho manipolata un granché, e l'equazione che abbiamo visto per la descrizione dell'input sinattico, ci sono delle enormi somiglianze. Ora, il fatto che beta sia qui a sinistra non importa, diciamo io ho ridefinito 1 su tau beta o viceversa, beta è 1 su tau e l'ho portato dall'altro lato, qui il fatto che ci sia questo termine in cui l'ampiezza, qui l'ampiezza tau e j non dipendono dai singoli istanti di occorrenza, Ok, le cose potrebbero essere, queste sono un pochino più semplici, ma di fatto la struttura è identica. Anche qui ho una sovrapposizione di delta e di irac, qui rappresentate da un'unica afferenza, e queste le posso in qualche modo considerare. Perché questo è interessante? Perché se integro ambo i membri questa equazione, e lo posso fare, vedete che le cose diventano molto semplici, ottengo, quindi non sto integrando a cavallo di una delta di Dirac, sto integrando tra 0 e t, ok? Se lo faccio qui a sinistra è un differenziale esatto ed è esattamente la primitiva calcolata in t meno la primitiva calcolata in 0. Vedete yt meno y0, y0 l'ho portato a destra dell'uguale. Qui ho una quantità che è l'integrale tra 0 e t di questa y, che non conosco perché è la soluzione che sto integrando, però non posso più dire che è un termine nullo, perché qui non è più un intervallo a misura nulla. La cosa interessante è che l'integrale di questa sommatoria diventa un processo che per ogni istante è diventato un numero. Se ogni volta che io ho una delta id irac, di fatto, quindi è un integrale con parametro, cioè t sta variando nel tempo, a questo valore di t, l'integrale è da 0, che supponete essere un punto molto a sinistra, fino a questo punto, e non ce ne sono, quindi in questo punto qua il valore di questo integrale è 0, anche in questo punto qua è 0, è 0, è 0, fin tanto che non trova queste delta di Dirac, Quindi a un certo punto qui lui salta e salta di J, perdono, salta di 1 perché J l'ho buttata fuori, alla fine qui l'area è unitaria. Quindi trovo un altro, salta un'altra volta, salta un'altra volta, scusate il grafico non è in scala, questi salti dovrebbero essere tutti della stessa quantità. ok, perdonatemi, dovevo controllare una cosa quindi siamo passati da un treno di delta id irac a un altro processo stocastico che è un numero intero per ogni istante t ed è una variable aleatoria distribuita secondo una distribuzione poissoniana non è un poisson point process è una variabile discreta perché infatti prende solo dei valori discreti e a tempo continuo perché queste delte di dirac queste transizioni possono assumere possono arrivare in qualunque momento e nella letteratura questo processo è un processo di conto si chiama processo di conto possono e conta quanti eventi ci sono stati fino a quel momento. E' qualcosa di più dolce, se volete, di un terreno di delta di Iraq, nonostante abbia delle caratteristiche comunque complesse. Noi non scendiamo troppo nel dettaglio, però avete nelle slide tutta la derivazione. E per studiare questo mostro lo voglio studiare perché mi chiedo, guardando questa slide, se voi riprendeste il processo di Onsen-Nunenberg e applicaste anche lì l'integrale da voi membri, la parte sinistra praticamente sarebbe uguale. Ok, lo chiamate x anziché y. Questo pezzo qui di nuovo sarebbe uguale. Ok, ci sarebbe x anziché y. Il processo di un studio Nurebeck ha qui un altro termine, un termine continuo, e poi ha la mu, ha mu più qualcosa. Mi chiedo se quella pizza lì integrata non abbia una qualche speranza di essere equivalente a questa pizza qui integrata. potreste dirmi ma perché passi dall'integrale e non fai una corrispondenza bionivoca? Questo x, questo x, questa cosa qua, sì. Non lo faccio perché è più complicato. Con l'integrale, con questo integrale, io qui mi sono portato a una condizione in cui non ho più le delta i dirac. Nota, le delta i dirac sono brutte bestie, vanno all'infinito, sono molto molto discontinue. Invece questo processo qua, benché sia discontinuo di prima specie, cioè salta, quindi ha questi salti, da sinistra a destra la derivata, scusate, il valore della funzione a destra a sinistra non è lo stesso, quindi c'è una discontinuità di prima specie, è più dolce rispetto al delta di Dirac. Quindi mi chiedo se e per quali condizioni Steyn e Onstenhofer sono uguali. uguali nella parte destra, nella parte di input, o perlomeno quando, in questa definizione di una descrizione integrale, in cui ho y uguale e ho x uguale, ho una quantità che è quella che è e poi ho questo termine forzante. Mi sono, cioè, ho trasformato l'equazione differenziale in un'equazione integrale. Per capire questo mostro, che non è così brutto poi per la verità, devo considerare una discretizzazione dell'asse dei tempi. Quindi prendo un particolare Δt e dico che in un certo intervallo avrò un certo numero di bin che è dato da m. m uguale t, in questo intervallo t, diviso delta t. Questa è la probabilità degli eventi e se discretizzo, perché se lo lascio in tempo continuo questo non lo riesco a fare, Mi rendo conto che la probabilità di avere un evento a un certo bin oppure no, a un certo intervallo discreto oppure no, è una variabile di Bernoulli. O c'è o non c'è. Ed è quello che viene chiamato esperimento di Bernoulli, ripetuto identicamente a se stesso ma con estrazioni indipendenti. C'è una teoria che dice che se volete conoscere il numero di eventi fra 0 fino a quel momento, però nel contesto discreto, nel continuo non si sa così a botto, su questi m bins la soluzione che in parte è semplice, al di là del fatto di questo coefficiente binomiale, è molto semplice perché mi dice la probabilità che ci siano state n occorrenze su m bin, su m step discreti che sono occorsi, e la probabilità di averne 1 elevata alla n, è una congiunzione logica, quindi è questa p, è p per p per p n volte, moltiplicato, quindi anche un'ulteriore condizione end logica che non si sia verificato allo stesso evento, per il complementare delle volte, quindi m meno n, per la probabilità che non ci sia un evento, quindi se questo era p, il complementare è 1 meno p, 1 meno p alla m meno n. C'è il coefficiente binomiale perché se io sono interessato a, in generale, avere n eventi, qual è la probabilità di averne n? Supponete che siano 2 o 1, è più facile con 1 o 2, e comprendo che sarebbe p alla 2 moltiplicato 1 meno p alla m meno 2, ok? Però questi due potrebbero essere qui e qui, oppure potrebbe essere il primo qui e il secondo a metà, o il primo qui e l'ultimo alla fine e il secondo alla fine, cioè esiste un numero di combinazioni senza ripetizione di due elementi in classe M. Non so se l'ho detto correttamente, ma se non avete avuto incubi durante, l'avrete visto il calcolo combinatorico, sapete che questa cosa si scrive con un rapporto di fattoriali, m fattoriale diviso m meno n fattoriale al denominatore, e si scrive in modo conciso con il coefficiente binomiale. Comunque, a parte questo, questa è una probabilità, una funzione di distribuzione binomiale che mi dice qual è la media e la varianza di questa n. Notate, sto vincendo perché io questo mostro qui, almeno nel tempo discreto, lo sto iniziando a gestire, posso capire qual è la media e qual è la varianza. Ok, il tempo discreto. Qui se prendo i libri e dico qual è una variabile binomiale n, la sua media è il numero di bin m per p, però m per delta t, per come l'ho scelto, era t, quindi è una variabile la cui media tende a crescere nel tempo. Vedete che va linearmente con t e la varianza assume questa forma qui, che non commento, che con lo stesso identico cambiamento di variabile m per Δt, qui lo faccio però solamente una volta perché mi resta il Δt dentro, è una varianza che dipende dalla scelta di Δt, ma anche questa varianza aumenta nel tempo. devo prima o poi tornare verso il tempo discreto. Questo è leggermente fastidioso e non vi sto a stressare. Quando faccio il limite per Δt che tende a 0, m ovviamente tende ad essere infinito, diventano un'infinità di questi intervallini, di questi istanti discreti. E in termini delle probabilità si sa che in questo caso la distribuzione binomiale diventa una distribuzione di Poisson, che è quello che vi ho venduto prima. n grande è una variabile aleatoria distribuita con Poisson e nel caso in cui il numero n tende a diventare molto molto grande, cioè a dire quando la frequenza tende a diventare molto grande, questo può sembrare strano, posso dire ma aspetta cosa mi sta dicendo questo? Sto dicendo che se il numero di Dirac delta è molto molto elevato, sono molto affollati, la variabile n Poissoniana tende di fatto a diventare una gaussiana, una gaussiana non centrata nello zero, è ben inteso, shiftata a destra con una media che è una quantità positiva e anche una varianza che è una quantità non nulla ovviamente. Media e varianza di questa variabile gaussiana, che si trova come il limite di una Poissoniana per la gaussiana, alla fine la gaussiana, se avete fatto un corso di teoria delle probabilità, vi è stata venduta come il processo limite di una distribuzione di Poisson, che a sua volta è il processo limite di una distribuzione binomiale. In questo frangente io so scrivere media e varianza di questo processo. Se lo faccio per il processo di Onsen-Hunenbeck, non entro particolarmente nei dettagli, mi accorgo che al di là del fatto che qui ho x come avevo y qui, qui ho x0 come avevo y0, magari questi sono esattamente uguali, qui ho uno su tau, uno su tau, l'integrale è integrale, esattamente uguale. E qui ho una pizza, vedete fra parentesi questo è un termine che se questo ha media nulla, questo è un termine che tende, è la media perché lo somma qualcosa a media nulla e anche questo tende ad aumentare linearmente nel tempo. Questo è qualcosa che è l'integrale di un rumore bianco che si chiama processo di Wiener. Questa è una cosa che non vi dico, essendo Ψ gaussiano, anche l'applicazione di un operatore lineare come l'integrale adesso, alla fine è una somma, mi fa uscire qualcosa di gaussiano. Perché? Perché la somma di verevoli gaussiane è gaussiana. Quindi questo processo che è l'integrale di Ψ, W, lo sto in qualche modo paragonando con quello che è l'integrale della somma di Dirac, di Δ Dirac, n, è un processo di cui io so tutto, in letteratura si sa tutto, è un processo gaussiano, la cosa importante, è continuo nel tempo, è un processo diffusivo, quindi, ha valori continui, e ha media nulla e varianza che scala come t. Qui gli aggiungo una media che scala pure come t, la varianza, questo è semplicemente un numero, dà il fattore di scala corretto per la varianza, perché questo di suo non ha varianza unitaria, ha varianza che scala come t. Me lo aspettavo perché questo è un integrale di un rumore, mentre il rumore per esempio è una fluttuazione che è, mentre il rumore gaussiano bianco è una roba che è a media nulla, se io faccio l'area sottesa, ok, l'area sottesa potrebbe ancora avere media nulla, ma la varianza potrebbe avere, ok è difficile sviluppare un'intuizione da questo punto di vista, la varianza potrebbe aumentare, cioè potrebbe avere una notevole incertezza di dove trovare il processo integrato, quindi è una roba che Wiener cresce nell'ampiezza delle fluttuazioni. Detto questo, non mi resta che paragonare Wiener a Poisson, Poisson nel caso continuo, strecciato, in cui Poisson diventa una gaussiana. In questo particolare caso quella corrispondenza fra mu e sigma e j, lambda e tau mi è spiegata paragonando le proprietà statistiche di questa cosa qua. Qui la media è j perché premoltiplicava, j, t, lambda. La varianza, se faccio le cose per bene, posso dimostrare che j quadro, t, lambda. Questa cosa qua, la media è mu diviso tau per t. O T qui e O T qui, eh? E la varianza è 2 sigma quadro diviso tau, O T qui e O T qui. Quindi potrei identificare J lambda con mu diviso tau e qui J quadro lambda con 2 sigma quadro su tau. Di fatto sto ottenuto la ricetta per dire, guarda che puoi emulare Stein, puoi comprendere Stein se usi un Stein Hulenbeck, purché tu utilizzi per media varianza di quel processo, di quelle quantità che comparivano qui dentro al secondo membro dell'equazione differenziale che ho utilizzato per definire il processo di un Stein Hulenbeck, purché ci siano queste definizioni. mu deve essere j lambda tau, sigma quadro deve essere un mezzo j quadro lambda tau. Però attenzione, questo ve lo ricordo ha solo senso quando Poisson tende a essere gaussiano, se no questo non è gaussiano, quindi sì magari avrà media varianza simile, ma resta qualcosa che ha gradini. Da un lato in neuroscienze computazionali questa è una cosa che si può gestire, ma non lo facciamo perché è più complicato. Resta da ricordarsi che vuol dire che lambda, che il numero di eventi deve essere molto elevato, la frequenza deve essere molto elevata. E ovviamente se io sto richiedendo che λ sia infinito, notate che io qua ho λ infinito, che cosa vuol dire? Io mu e σ, qui in questa equazione qua, devono restare finiti. Sono fortunato che ho un prodotto j e λ, j e λ. Quindi l'unica possibilità che questo sia valido è quando, chiaramente, il numero di eventi è elevato, ma se così non è non posso fare queste considerazioni, l'ampiezza dei salti, l'ampiezza delle singole sinapsi, che vi ho ossessionato col fatto che sono molto molto molto piccole, è piccolo, è molto piccolo, praticamente infinitesimale. In questo modo il termine j, il salto per quante volte succede, è basso e di nuovo qui non ci vuole uno scienziato per pensare che se questa quantità è molto piccola allora effettivamente c'è una specie di continuità che posso invocare. Vedete questa continuità che c'è qui è evidentemente perché qui io facevo uno zoom out, quindi se ho più di 10, 20, 50, 100 ovviamente questi salti e le code si sommano, l'ampiezza diventa molto grande, ma io qui per un trucco grafico ho scalato, ho fatto zoom out, oppure in altri termini vuol dire che ho considerato questi salti J piccoli o molto piccoli, o limite infinitesimali e vedete che effettivamente ho trovato un processo diffusivo. Questo conclude questa parte che è una parte a latere che vuol darvi lo strumento per dire ma perché diamine tu stai mettendo dentro un integre spara o dentro un neurone stai parlando di processi stocastici continui, quando ci sono in verità dei processi assalti. Qui ce la avete.